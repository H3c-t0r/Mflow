{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Started with Keras 3.0 + MLflow\n",
    "\n",
    "This tutorial is an end-to-end tutorial on training a MINST classifier with **Keras 3.0** and logging results with **MLflow**. It will demonstrate the use of `mlflow.keras_core.MLflowCallback`, and how to subclass it to implement custom logging logic.\n",
    "\n",
    "**Keras** is a high-level api that is designed to be simple, flexible, and powerful - allowing everyone from beginners to advanced users to quickly build, train, and evaluate models. **Keras 3.0**, or Keras Core, is a full rewrite of the Keras codebase that rebases it on top of a modular backend architecture. It makes it possible to run Keras workflows on top of arbitrary frameworks â€” starting with TensorFlow, JAX, and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df7eac27-132c-4541-830a-19dec603607b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Install Packages\n",
    "\n",
    "`pip install -q keras-core mlflow jax jaxlib torch tensorflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f570ad7-049f-48e5-818a-5cbbe3ed9cc2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import Packages / Configure Backend\n",
    "Keras 3.0 is inherently multi-backend, so you will need to set the backend environment variable **before** importing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ece8d16-2e9d-46ca-80bd-8e6e3cb0c421",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# You can use 'tensorflow', 'torch' or 'jax' as backend. Make sure to set the environment variable before importing.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_core\n",
    "import mlflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a612819-6a17-4595-9364-edabe1757740",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Dataset\n",
    "We will use the MNIST dataset. This is a dataset of handwritten digits and will be used for an image classification task. There are 10 classes corresponding to the 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b086538-7005-46c4-8f9f-08ff2aa76516",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras_core.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f3b13f7-a89c-47ac-9f0b-17a10cfae89a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid = 3\n",
    "fig, axes = plt.subplots(grid, grid, figsize=(6, 6))\n",
    "for i in range(grid):\n",
    "    for j in range(grid):\n",
    "        axes[i][j].imshow(x_train[i * grid + j])\n",
    "        axes[i][j].set_title(f\"label={y_train[i * grid + j]}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17333838-480c-4410-ae87-73df09f0c4df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Build Model\n",
    "We will use the Keras 3.0 sequential API to build a simple CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f76fdaf-68c4-41b7-88e2-19d2f3ad7a13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "    model = keras_core.Sequential(\n",
    "        [\n",
    "            keras_core.Input(shape=INPUT_SHAPE),\n",
    "            keras_core.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            keras_core.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            keras_core.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            keras_core.layers.GlobalAveragePooling2D(),\n",
    "            keras_core.layers.Dense(NUM_CLASSES, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7148f17-f552-4f7f-8c17-3c21ebbd087f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train Model (Default Callback)\n",
    "We will fit the model on the dataset, using MLflow's `mlflow.keras_core.MLflowCallback` to log metrics during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76ff9994-3941-4bd9-a539-a456794657b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64  # adjust this based on the memory of your machine\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb1f6aa4-821f-4dd0-af56-e24c335eebb9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Log Per Epoch\n",
    "An epoch defined as one pass through the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f7b4f98-a891-4013-9ddd-2ae1521441c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras_core.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras_core.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[mlflow.keras_core.MLflowCallback(run)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25d92e69-b1a0-4fc0-a415-13f8e6c6e9a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Log Results\n",
    "The callback for the run would log **parameters**, **metrics** and **artifacts** to MLflow dashboard.\n",
    "\n",
    "![run page](https://i.imgur.com/YLGFDJEl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa0942b-34d3-4523-a9f5-e6894f160a95",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Log Per Batch\n",
    "Within each epoch, the training dataset is broken down to batches based on the defined `BATCH_SIZE`. If we set the callback to not log based on epochs with `log_every_epoch=False`, and to log every 5 batches with `log_every_n_steps=5`, we can adjust the logging to be based on the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "949d472e-1d3d-4136-bd6f-e3bd8ca36e9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras_core.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras_core.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[\n",
    "            mlflow.keras_core.MLflowCallback(run, log_every_epoch=False, log_every_n_steps=5)\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eba06fc-d317-4eeb-922b-98b7fb344848",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Log Results\n",
    "\n",
    "If we **log per epoch**, we will only have three datapoints, since there are only 3 epochs:\n",
    "\n",
    "![log per epoch](https://i.imgur.com/rFDj8SHl.png)\n",
    "\n",
    "By **logging per batch**, we can get more datapoints, but they can be noisier:\n",
    "\n",
    "![log per batch](https://i.imgur.com/ZCYXLqll.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2123d86f-2e36-4d9d-a941-1f878eeb5553",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train Model (Custom Callback)\n",
    "Let's train the model again, for the purpose of demonstrating how to use subclass and customize MLflow's `mlflow.keras_core.MLflowCallback` for logging. \n",
    "\n",
    "The pre-defined `MLflowCallback` allows us to adjust whether we want to log every epoch or every batch through parameters `log_every_epoch` and `log_every_n_steps`. However, currently each time the callback logs is defined as a `step`, so if we log every 5 batches, it will just be 1 step. What if we want the steps to correspond exactly to the batches seen?\n",
    "\n",
    "Notice that the logging that happens every 5 batches is logged as one step along the x-axis:\n",
    "\n",
    "![5 Batches Per Step](https://i.imgur.com/RK1HotHl.png?1)\n",
    "\n",
    "The method we will look at is `on_batch_end()`. This method is a callback that is called at the end of every batch. `self._log_step` counts the logging steps and is shown as one of the x-axis on the graph.\n",
    "\n",
    "```\n",
    "def on_batch_end(self, batch, logs=None):\n",
    "  \"\"\"Log metrics at the end of each batch with user specified frequency.\"\"\"\n",
    "  if self.log_every_n_steps is None or logs is None:\n",
    "      return\n",
    "  if (batch + 1) % self.log_every_n_steps == 0:\n",
    "      self.metrics_logger.record_metrics(logs, self._log_step)\n",
    "      self._log_step += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eff0faf5-56e7-4300-a269-acdb2c73e825",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class MlflowCallbackLogPerBatch(mlflow.keras_core.MLflowCallback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if self.log_every_n_steps is None or logs is None:\n",
    "            return\n",
    "        if (batch + 1) % self.log_every_n_steps == 0:\n",
    "            self.metrics_logger.record_metrics(logs, self._log_step)\n",
    "            self._log_step += self.log_every_n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33606728-a58d-48e7-8fdc-e7cb0e74801d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "\n",
    "model.compile(\n",
    "    loss=keras_core.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras_core.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[MlflowCallbackLogPerBatch(run, log_every_epoch=False, log_every_n_steps=5)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfb2b823-ea5f-4c22-a7bf-30121d0d39c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Log Results\n",
    "\n",
    "Observe that with the customized callback, the steps correspond directly to the number of batches seen. 1 batch corresponds to 1 step.\n",
    "\n",
    "![1 batch per step](https://i.imgur.com/hhO178jl.png?1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a53a9ba-e80b-4774-9d20-01ee045f0d11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluation\n",
    "Similar to training, you can use the callback to log the evaluation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9071838a-b30a-4095-b108-b0e6eb5dcfd4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model.evaluate(x_test, y_test, callbacks=[mlflow.keras_core.MLflowCallback(run)])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Keras 3.0 MLflow Tutorial",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
