{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Sentence Transformers and MLflow\n",
    "\n",
    "Welcome to our tutorial on harnessing the capabilities of **Sentence Transformers** with **MLflow**. This tutorial targets those beginning their journey in advanced natural language processing and model management. We will guide you through a hands-on example showcasing the integration of the `sentence-transformers` library with MLflow, a tool that significantly streamlines the machine learning lifecycle.\n",
    "\n",
    "### What are Sentence Transformers?\n",
    "\n",
    "**Sentence Transformers** are a modification of the traditional transformers model, specifically optimized for generating meaningful and semantically rich sentence embeddings. Developed as an extension of the renowned Transformers library by ðŸ¤— Hugging Face, `sentence-transformers` facilitate an array of NLP tasks such as semantic search, text clustering, and similarity comparison. The library leverages models like BERT, RoBERTa, and DistilBERT, fine-tuned to produce high-quality sentence-level embeddings.\n",
    "\n",
    "### Benefits of Integrating MLflow with Sentence Transformers\n",
    "\n",
    "Merging MLflow with Sentence Transformers offers a suite of advantages for NLP projects:\n",
    "\n",
    "- **Efficient Experiment Management**: Streamline the process of tracking experiments, including logging model parameters, metrics, and embeddings.\n",
    "- **Enhanced Model Lifecycle Control**: Gain better control over your NLP models' versions, configurations, and performance.\n",
    "- **Reproducibility**: Facilitate the replication of results and model predictions with comprehensive record-keeping.\n",
    "- **Simplified Model Deployment**: Ease the deployment of your NLP models into production environments, supported by MLflow's robust tools.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "In this tutorial, you'll learn how to:\n",
    "\n",
    "- Set up a pipeline for generating sentence embeddings using the `sentence-transformers` library.\n",
    "- Log models and their configurations using MLflow.\n",
    "- Understand the concept of model signatures in MLflow and how they apply to `sentence-transformers`.\n",
    "- Deploy and utilize these models for inference using MLflow's capabilities.\n",
    "\n",
    "By the end of this tutorial, you'll have a deeper understanding of how MLflow can amplify your NLP projects, especially when working with sophisticated models like Sentence Transformers, empowering you to efficiently track, manage, and deploy your applications.\n",
    "\n",
    "Let's embark on this journey of integrating Sentence Transformers with MLflow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Environment for Sentence Embedding\n",
    "\n",
    "As we embark on this journey with Sentence Transformers and MLflow, our initial step is to establish our working environment. This involves importing the required libraries and setting up the Sentence Transformer model, which forms the core of our sentence embedding pipeline.\n",
    "\n",
    "#### Key Steps for Initialization:\n",
    "\n",
    "1. **Library Imports**:\n",
    "   - Import the `SentenceTransformer` class from the `sentence_transformers` library. This class is crucial for creating our sentence embedding model.\n",
    "   - Import `mlflow`. This will give us access to our run context and the `sentence_transformers` module, allowing us to log and load a model.\n",
    "\n",
    "2. **Model Initialization**:\n",
    "   - Initialize the Sentence Transformer model using the `SentenceTransformer` class. We will be using the `\"all-MiniLM-L6-v2\"` model for this tutorial, a compact yet powerful model known for its efficiency and effectiveness in generating sentence embeddings.\n",
    "\n",
    "   You can find additional models that are compatible with embedding tasks in the [Hugging Face Hub](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending) by selecting **\"Sentence Similarity\"** in the categorical selection pane.\n",
    "\n",
    "3. **Purpose of the Model**:\n",
    "   - The `\"all-MiniLM-L6-v2\"` model is designed to convert sentences into semantically meaningful embeddings. These embeddings can be used in a variety of NLP tasks, such as semantic search, clustering, and similarity comparisons.\n",
    "\n",
    "By setting up this environment, we lay the foundation for our exploration into the capabilities of Sentence Transformers in conjunction with MLflow. This setup not only simplifies our workflow but also enables us to delve into advanced NLP tasks with ease.\n",
    "\n",
    "Let's proceed to initialize our environment and the Sentence Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model Signature with MLflow\n",
    "\n",
    "Now that our Sentence Transformer model is set up, the next important step is to define the model signature. A model signature in MLflow is crucial for specifying the input and output formats of the model, ensuring consistent and expected behavior during inference.\n",
    "\n",
    "#### Steps for Signature Definition:\n",
    "\n",
    "1. **Prepare Example Sentences**:\n",
    "   - We start by defining a list of example sentences: `[\"This is a sentence.\", \"This is another sentence.\"]`. These sentences will be used to demonstrate the model's input and output formats.\n",
    "\n",
    "2. **Generate Model Signature**:\n",
    "   - Utilize the `mlflow.models.infer_signature` function to automatically infer and define the model signature.\n",
    "   - The `model_input` parameter is set to our example sentences.\n",
    "   - For the `model_output` parameter, we use the `encode` method of our Sentence Transformer model to transform the example sentences into embeddings. The output of this method represents the model's expected output format.\n",
    "\n",
    "#### Importance of the Model Signature:\n",
    "\n",
    "- **Clarity in Data Formats**: The signature provides clear documentation of the type and format of data the model expects and produces, which is essential for anyone using the model.\n",
    "- **Model Deployment and Usage**: Accurate model signatures are crucial when deploying models to production, as they ensure that the model receives inputs in the correct format and produces expected outputs.\n",
    "- **Error Prevention**: A well-defined signature helps prevent errors during model inference by enforcing consistent data formats.\n",
    "\n",
    "With the model signature defined, we gain a better understanding of how our Sentence Transformer model processes and transforms data, setting the stage for more advanced operations and deployment.\n",
    "\n",
    "**NOTE**: The `List[str]` input type is equivalent at inference time (for purposes of validation and signature enforcement) to `str`. This MLflow flavor uses a `ColSpec[str]` definition for the input type, which can accept either `str` or `List[str]`.\n",
    "\n",
    "Let's proceed to define the signature for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = [\"A sentence to encode.\", \"Another sentence to encode.\"]\n",
    "\n",
    "signature = mlflow.models.infer_signature(\n",
    "    model_input=example_sentences,\n",
    "    model_output=model.encode(example_sentences),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the tracking server and creating an experiment\n",
    "\n",
    "In order to view the results in our tracking server (for the purposes of this tutorial, weâ€™ve started a local tracking server at this url)\n",
    "\n",
    "We can start an instance of the MLflow server locally by running the following from a terminal to start the tracking server:\n",
    "\n",
    "``` bash\n",
    "mlflow server --host 127.0.0.1 --port 8080\n",
    "```\n",
    "\n",
    "With the server started, the following code will ensure that all experiments, runs, models, parameters, and metrics that we log are being tracked within that server instance (which also provides us with the MLflow UI when navigating to that url address in a browser).\n",
    "\n",
    "After setting the tracking url, we create a new MLflow Experiment to store the run weâ€™re about to create in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/711030387534394632', creation_time=1700232675282, experiment_id='711030387534394632', last_update_time=1700232675282, lifecycle_stage='active', name='Introduction to Sentence Transformers', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "mlflow.set_experiment(\"Introduction to Sentence Transformers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging the Sentence Transformer Model with MLflow\n",
    "\n",
    "With our Sentence Transformer model initialized and its signature defined, the next crucial step is to log the model in MLflow. This process involves registering the model along with its metadata, which includes the signature and an example of the input data. Logging the model in this way is essential for tracking, version control, and deployment.\n",
    "\n",
    "#### Steps for Logging the Model:\n",
    "\n",
    "1. **Start an MLflow Run**:\n",
    "   - Use `mlflow.start_run()` to initiate a new run. This MLflow run acts as a container for all the operations related to model logging, ensuring that they are grouped together for easy tracking.\n",
    "\n",
    "2. **Log the Model**:\n",
    "   - Call `mlflow.sentence_transformers.log_model` to log the Sentence Transformer model.\n",
    "   - Provide the `model` object itself, which is our Sentence Transformer model.\n",
    "   - Specify an `artifact_path`, which is the directory within the MLflow run where the model will be stored.\n",
    "   - Include the `signature` we defined earlier, which documents the model's input and output formats.\n",
    "   - Add an `input_example` to give a concrete example of the data the model expects.\n",
    "\n",
    "#### Importance of Model Logging:\n",
    "\n",
    "- **Model Management**: Logging the model in MLflow aids in managing the model's lifecycle, from training to deployment.\n",
    "- **Reproducibility and Tracking**: It allows for the tracking of model versions and ensures reproducibility of the model's performance.\n",
    "- **Ease of Deployment**: Logged models in MLflow can be easily deployed for inference, making the transition from training to production smoother.\n",
    "\n",
    "By logging our Sentence Transformer model in MLflow, we effectively create a record of the model's configuration and capabilities, paving the way for subsequent model analysis, sharing, and deployment.\n",
    "\n",
    "Let's log our model in MLflow and move forward in our machine learning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    logged_model = mlflow.sentence_transformers.log_model(\n",
    "        model=model,\n",
    "        artifact_path=\"sbert_model\",\n",
    "        signature=signature,\n",
    "        input_example=example_sentences,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model and Testing Inference\n",
    "\n",
    "After logging our Sentence Transformer model with MLflow, we will now demonstrate how to load the model for inference and test it with new input sentences. This step is crucial to understand how our model can be deployed for real-time inference in an application service layer.\n",
    "\n",
    "#### Loading the Model as a PyFunc:\n",
    "\n",
    "1. **Why PyFunc**:\n",
    "   - We load our logged model using `mlflow.pyfunc.load_model`. The `pyfunc` format is MLflow's way of abstracting models, enabling them to be used as regular Python functions. This is particularly useful for deployment scenarios where the model needs to seamlessly integrate into an existing Python-based service or application.\n",
    "   - Loading as a `pyfunc` allows for flexibility and simplicity, especially when the downstream processing or application logic is implemented in Python.\n",
    "\n",
    "2. **Model URI**: \n",
    "   - We use the `logged_model.model_uri` to load the model. This URI points to the location where the logged model's artifacts are stored in MLflow.\n",
    "\n",
    "#### Conducting Inference Tests:\n",
    "\n",
    "1. **Test Sentences**:\n",
    "   - We define a set of test sentences: `[\"I enjoy pies of both apple and cherry.\", \"I prefer cookies.\"]`. These sentences are used to test the model's ability to generate embeddings.\n",
    "\n",
    "2. **Performing Predictions**:\n",
    "   - We call the `predict` method on the loaded `pyfunc` model with our test sentences. This method returns the embeddings for each input sentence.\n",
    "\n",
    "3. **Printing Embedding Lengths**:\n",
    "   - We print the length of the returned embedding structures to verify that embeddings have been generated for each input sentence. This step confirms the model's functionality in producing embeddings and helps visualize the output structure.\n",
    "   - The length of each embedding array corresponds to the dimensionality of the vector representation of each sentence.\n",
    "\n",
    "#### Importance of Inference Testing:\n",
    "\n",
    "- **Model Validation**: This test confirms that our model, when loaded for inference, behaves as expected and successfully processes input data.\n",
    "- **Deployment Readiness**: Demonstrating inference with `pyfunc` is a key step in validating the model's readiness for integration into a service layer for real-time applications.\n",
    "\n",
    "Let's proceed to load the model and test its inference capabilities on our example sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4b0969105b4eab97c09a4fba988716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/20 12:09:44 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The return structure length is: 2\n",
      "The size of embedding 1 is: 384\n",
      "The size of embedding 2 is: 384\n"
     ]
    }
   ],
   "source": [
    "inference_test = [\"I enjoy pies of both apple and cherry.\", \"I prefer cookies.\"]\n",
    "\n",
    "loaded_model_pyfunc = mlflow.pyfunc.load_model(logged_model.model_uri)\n",
    "\n",
    "embeddings1 = loaded_model_pyfunc.predict(inference_test)\n",
    "\n",
    "print(f\"The return structure length is: {len(embeddings1)}\")\n",
    "\n",
    "for i, embedding in enumerate(embeddings1):\n",
    "    print(f\"The size of embedding {i + 1} is: {len(embeddings1[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Samples of Generated Embeddings\n",
    "\n",
    "Having confirmed that our Sentence Transformer model successfully generates embeddings for our input sentences, we now move to inspect the actual content of these embeddings. This step is crucial for understanding the nature of the output produced by our model and for verifying the quality of the embeddings.\n",
    "\n",
    "#### Inspecting the Embedding Samples:\n",
    "\n",
    "1. **Purpose of Sampling**:\n",
    "   - We examine a sample of the entries in each embedding to get a sense of what the model output looks like. This inspection is particularly important for understanding the kind of vector representations that the model generates for different sentences.\n",
    "\n",
    "2. **Printing Embedding Samples**:\n",
    "   - For each embedding, we print the first 10 entries of the vector. This subset provides a glimpse into the embedding without overwhelming us with the entire high-dimensional vector.\n",
    "   - The command `embedding[:10]` is used to slice the first 10 elements of each embedding vector.\n",
    "\n",
    "#### Why Sampling is Important:\n",
    "\n",
    "- **Quality Check**: Sampling the embeddings allows us to perform a quick quality check, ensuring that the embeddings are not degenerate (e.g., all zeros) and have meaningful values.\n",
    "- **Understanding Model Output**: Seeing a portion of the embedding vectors helps in gaining an intuitive understanding of the model's output, which can be important for debugging and further model development.\n",
    "\n",
    "This exploration of the embeddings is a key step in familiarizing ourselves with the model's output, setting the stage for further analysis or integration of these embeddings into downstream tasks.\n",
    "\n",
    "Let's inspect the samples from our generated embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample of the first 10 entries in embedding 1 is: [ 0.04866192 -0.03687946  0.02408808  0.03534171 -0.12739632  0.00999414\n",
      "  0.07135344 -0.01433522  0.04296691 -0.00654414]\n",
      "The sample of the first 10 entries in embedding 2 is: [-0.03879027 -0.02373698  0.01314073  0.03589077 -0.01641303 -0.0857707\n",
      "  0.08282158 -0.03173266  0.04507608  0.02777079]\n"
     ]
    }
   ],
   "source": [
    "for i, embedding in enumerate(embeddings1):\n",
    "    print(f\"The sample of the first 10 entries in embedding {i + 1} is: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Model Loading in MLflow for Extended Functionality\n",
    "\n",
    "In addition to loading our model as a generic Python function (`pyfunc`), MLflow also supports native loading of Sentence Transformer models. This approach allows us to utilize the full range of functionalities, methods, and attributes inherent to the Sentence Transformer model, which can be crucial for certain NLP tasks that extend beyond simple embedding generation.\n",
    "\n",
    "#### Why Support Native Loading?\n",
    "\n",
    "1. **Access to Native Functionalities**:\n",
    "   - By loading the model natively, we can access all the native functionalities of the Sentence Transformer model. This is particularly important for tasks that require specific methods or attributes not exposed through the generic `pyfunc` interface.\n",
    "   - Native loading is essential for scenarios where advanced model functionalities are needed, such as fine-tuning, further training, or using specific model methods for complex NLP tasks.\n",
    "\n",
    "2. **Loading the Model Natively**:\n",
    "   - We use `mlflow.sentence_transformers.load_model` to load the model natively. This method is specifically designed for models logged using the Sentence Transformers flavor in MLflow.\n",
    "   - The model is loaded using its unique model URI, ensuring that we retrieve the correct version of the model that we previously logged.\n",
    "\n",
    "#### Generating Embeddings Using Native Model:\n",
    "\n",
    "1. **Model Encoding**:\n",
    "   - After loading the model natively, we use the `encode` method of the Sentence Transformer model to generate embeddings for our test sentences.\n",
    "   - This `encode` method is part of the native Sentence Transformer model and provides optimized functionality for converting sentences into embeddings.\n",
    "\n",
    "2. **Importance of Native Encoding**:\n",
    "   - Using the native `encode` method ensures that we are leveraging the model's full capabilities in terms of embedding generation.\n",
    "   - It allows for a more flexible and potentially more efficient embedding process, especially for complex or large-scale NLP applications.\n",
    "\n",
    "By understanding the benefits of native model loading in MLflow, we can better utilize the full range of features offered by Sentence Transformers, tailoring our NLP projects to specific requirements and extending beyond basic embedding tasks.\n",
    "\n",
    "Let's proceed to load our model natively and generate embeddings using the model's `encode` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958706df03294da49ec8e8f328b15bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/20 12:09:46 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "2023/11/20 12:09:48 INFO mlflow.sentence_transformers: 'runs:/471300dac52f489cbc59a3c4013a995e/sbert_model' resolved as 'mlflow-artifacts:/711030387534394632/471300dac52f489cbc59a3c4013a995e/artifacts/sbert_model'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b35c64a7894512b5122ce3f0d28950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample of the native library encoding call for embedding 1 is: [ 0.04866192 -0.03687946  0.02408808  0.03534171 -0.12739632  0.00999414\n",
      "  0.07135344 -0.01433522  0.04296691 -0.00654414]\n",
      "The sample of the native library encoding call for embedding 2 is: [-0.03879027 -0.02373698  0.01314073  0.03589077 -0.01641303 -0.0857707\n",
      "  0.08282158 -0.03173266  0.04507608  0.02777079]\n"
     ]
    }
   ],
   "source": [
    "loaded_model_native = mlflow.sentence_transformers.load_model(logged_model.model_uri)\n",
    "\n",
    "embeddings2 = loaded_model_native.encode(inference_test)\n",
    "\n",
    "for i, embedding in enumerate(embeddings2):\n",
    "    print(f\"The sample of the native library encoding call for embedding {i + 1} is: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Embracing the Power of Sentence Transformers with MLflow\n",
    "\n",
    "As we reach the end of our Introduction to Sentence Transformers tutorial, we have successfully navigated the basics of integrating the Sentence Transformers library with MLflow. This foundational knowledge sets the stage for more advanced and specialized applications in the field of Natural Language Processing (NLP).\n",
    "\n",
    "### Recap of Key Learnings\n",
    "\n",
    "1. **Integration Basics**: We covered the essential steps of loading and logging a Sentence Transformer model using MLflow. This process demonstrated the simplicity and effectiveness of integrating cutting-edge NLP tools within MLflow's ecosystem.\n",
    "\n",
    "2. **Signature and Inference**: Through the creation of a model signature and the execution of inference tasks, we showcased how to operationalize the Sentence Transformer model, ensuring that it's ready for real-world applications.\n",
    "\n",
    "3. **Model Loading and Prediction**: We explored two ways of loading the model - as a PyFunc model and using the native Sentence Transformers loading mechanism. This dual approach highlighted the versatility of MLflow in accommodating different model interaction methods.\n",
    "\n",
    "4. **Embeddings Exploration**: By generating and examining sentence embeddings, we glimpsed the transformative potential of transformer models in capturing semantic information from text.\n",
    "\n",
    "### Looking Ahead\n",
    "\n",
    "- **Expanding Horizons**: While this tutorial focused on the foundational aspects of Sentence Transformers and MLflow, there's a whole world of advanced applications waiting to be explored. From semantic similarity analysis to paraphrase mining, the potential use cases are vast and varied.\n",
    "\n",
    "- **Continued Learning**: We strongly encourage you to delve into the other tutorials in this series, which dive deeper into more intriguing use cases like similarity analysis, semantic search, and paraphrase mining. These tutorials will provide you with a broader understanding and more practical applications of Sentence Transformers in various NLP tasks.\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "The journey into NLP with Sentence Transformers and MLflow is just beginning. With the skills and insights gained from this tutorial, you are well-equipped to explore more complex and exciting applications. The integration of advanced NLP models with MLflow's robust management and deployment capabilities opens up new avenues for innovation and exploration in the field of language understanding and beyond.\n",
    "\n",
    "Thank you for joining us on this introductory journey, and we look forward to seeing how you apply these tools and concepts in your NLP endeavors!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
