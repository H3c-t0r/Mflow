{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Semantic Search with Sentence Transformers and MLflow\n",
    "\n",
    "Welcome to this hands-on tutorial where we will be exploring **Advanced Semantic Search using Sentence Transformers** and **MLflow**. This guide is designed for those who are keen on diving deeper into the realms of Natural Language Processing (NLP), with a special focus on the practical integration of sophisticated NLP models with MLflow for robust model management.\n",
    "\n",
    "### Understanding Semantic Search\n",
    "\n",
    "Semantic search refers to the process of searching not just based on keywords, but by understanding the intent and contextual meaning of the search query. Unlike traditional search algorithms that rely on keyword matching, semantic search algorithms interpret the nuances and semantics of language to find results that are contextually relevant to the query. This approach mirrors how humans understand language, considering the varied and subtle meanings words can have in different contexts.\n",
    "\n",
    "### Harnessing Power of Sentence Transformers for Search\n",
    "\n",
    "**Sentence Transformers** are a unique offshoot of the transformer models, fine-tuned to generate **contextually rich** sentence embeddings. These embeddings are vector representations of sentences that capture their semantic meaning. Using Sentence Transformers, we can convert both our search queries and our database (or corpus) of text into these embeddings. By comparing the embeddings of the query with those in the corpus, we can identify the most semantically similar entries - a core principle of semantic search.\n",
    "\n",
    "Originating from the acclaimed Transformers library by ðŸ¤— Hugging Face, these models are adept at tasks like semantic search and clustering. In this tutorial, we'll see how `sentence-transformers` are employed not just for their technical prowess, but also for their ability to sift through a corpus sprinkled with humor and wit.\n",
    "\n",
    "### MLflow: A Vanguard in Model Management and Deployment\n",
    "\n",
    "MLflow's integration into this process is twofold. It not only streamlines our project management but also brings to the table a customizable environment for NLP models:\n",
    "\n",
    "- **Efficient Experiment Logging**: Track your NLP experiments with ease, logging intricate details like model parameters and embeddings using MLflow.\n",
    "- **Custom `PythonModel` in Action**: We'll delve into a bespoke `PythonModel` implementation that transcends standard outputs, returning results that are not only accurate but also humorously resonant.\n",
    "- **Lifecycle Management Made Simple**: Navigate through the complexities of NLP model development with MLflow's versioning and configuration control.\n",
    "- **Seamless Deployment and Reproducibility**: Ready your models for real-world application with the assurance of reproducibility and consistency, courtesy of MLflow.\n",
    "\n",
    "### What You Will Learn\n",
    "\n",
    "In this tutorial, you will:\n",
    "\n",
    "- Implement and manipulate the `sentence-transformers` library for advanced semantic search.\n",
    "- Explore and customize MLflowâ€™s `PythonModel` to meet unique project needs.\n",
    "- Manage and log models and configurations within the MLflow ecosystem.\n",
    "- Deploy sophisticated models for practical use, leveraging MLflow's robust deployment features.\n",
    "\n",
    "By the end of this tutorial, not only will you have a firmer grasp on conducting intricate semantic searches using Sentence Transformers, but you'll also gain invaluable insights into the versatility of MLflow for model deployment and management. Get ready to embark on a journey that combines the rigor of NLP with a useful application in document retrieval, enhancing your understanding of both the sentence transformers library and MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Semantic Search Model with MLflow and Sentence Transformers\n",
    "\n",
    "In this section, we delve into the technicalities of our `SemanticSearchModel`, a custom model leveraging MLflow and the Sentence Transformers library. This model is tailored for a semantic search use case, specifically designed for searching through blog posts based on user queries.\n",
    "\n",
    "### MLflow and Custom `pyfunc` Models\n",
    "\n",
    "MLflow is a versatile platform for managing the machine learning lifecycle, including experimentation, reproducibility, and deployment. One of its powerful features is the ability to define custom Python function (`pyfunc`) models. These models provide a flexible way to encapsulate your logic and can be easily deployed and managed within the MLflow ecosystem.\n",
    "\n",
    "In our example, we define the `SemanticSearchModel`, a subclass of `PythonModel`. This class encapsulates the entire logic needed for our semantic search application, making it a self-contained, deployable artifact. By leveraging MLflow's `pyfunc`, we gain the following advantages:\n",
    "\n",
    "- **Flexibility in Model Definition**: Custom logic for semantic search is neatly wrapped in a class, providing clear structure and readability.\n",
    "- **Ease of Deployment**: The model can be deployed as a standalone service or integrated into larger applications, with MLflow handling the complexities of deployment.\n",
    "- **Version Control and Experiment Tracking**: MLflow allows us to track different versions of our model and experiment with various parameters seamlessly.\n",
    "\n",
    "### The Model's Core Functionalities\n",
    "\n",
    "#### Context Loading\n",
    "\n",
    "The `load_context` method is responsible for loading the model and the corpus used for semantic search. This method:\n",
    "\n",
    "- Loads a pre-trained Sentence Transformer model, which is responsible for converting text into semantically meaningful embeddings.\n",
    "- Reads a corpus of blog posts from a file, providing the content against which user queries will be compared.\n",
    "\n",
    "#### Predict Method\n",
    "\n",
    "The `predict` method is the heart of our semantic search functionality. Here's a breakdown of its key components:\n",
    "\n",
    "- **Input Validation**: It ensures the input, whether in DataFrame or dictionary format, is valid and extracts the query sentence.\n",
    "- **Query Encoding**: The input query is encoded into an embedding using the Sentence Transformer model.\n",
    "- **Cosine Similarity Computation**: The method calculates the cosine similarity between the query embedding and the corpus embeddings. This similarity score determines how relevant each corpus entry is to the query.\n",
    "- **Top Results Extraction**: The `top_k` most similar entries are extracted. This parameter is flexible and can be adjusted without needing to redeploy the model.\n",
    "- **Relevancy Filtering**: A `minimum_relevancy` parameter is introduced, allowing the user to filter out results below a certain relevancy threshold. This enhances the model's usability by ensuring only sufficiently relevant results are returned.\n",
    "- **Warning Mechanism**: If all top results are below the `minimum_relevancy` threshold, a warning is issued, and the most relevant result is returned. This ensures the model always provides a result, enhancing user experience.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Through this implementation, we demonstrate how MLflow and Sentence Transformers can be combined to create a robust, flexible, and user-friendly semantic search model. This model showcases the power of NLP in practical applications and exemplifies how MLflow's framework can accommodate complex logic and user experience considerations, making it an invaluable tool in modern machine learning workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import warnings\n",
    "\n",
    "\n",
    "class SemanticSearchModel(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load the model context for inference, including the corpus from a file.\"\"\"\n",
    "        try:\n",
    "            # Load the pre-trained sentence transformer model\n",
    "            self.model = SentenceTransformer.load(context.artifacts[\"model_path\"])\n",
    "            \n",
    "            # Load the corpus from the specified file\n",
    "            corpus_file = context.artifacts[\"corpus_file\"]\n",
    "            with open(corpus_file, 'r') as file:\n",
    "                self.corpus = file.read().splitlines()\n",
    "            \n",
    "            # Encode the corpus and convert it to a tensor\n",
    "            self.corpus_embeddings = self.model.encode(self.corpus, convert_to_tensor=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading model and corpus: {e}\")\n",
    "\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        \"\"\"Predict method to perform semantic search over the corpus.\"\"\"\n",
    "        \n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            if model_input.shape[1] != 1:\n",
    "                raise ValueError(\"DataFrame input must have exactly one column.\")\n",
    "            model_input = model_input.iloc[0, 0]\n",
    "        elif isinstance(model_input, dict):\n",
    "            model_input = model_input.get(\"sentence\")\n",
    "            if model_input is None:\n",
    "                raise ValueError(\"The input dictionary must have a key named 'sentence'.\")\n",
    "        else:\n",
    "            raise TypeError(f\"Unexpected type for model_input: {type(model_input)}. Must be either a Dict or a DataFrame.\")\n",
    "\n",
    "        # Encode the query\n",
    "        query_embedding = self.model.encode(model_input, convert_to_tensor=True)\n",
    "\n",
    "        # Compute cosine similarity scores\n",
    "        cos_scores = util.cos_sim(query_embedding, self.corpus_embeddings)[0]\n",
    "\n",
    "        # Determine the number of top results to return\n",
    "        top_k = params.get(\"top_k\", 3) if params else 3  # Default to 3 if not specified\n",
    "\n",
    "        minimum_relevancy = params.get(\"minimum_relevancy\", 0.2) if params else 0.2  # Default to 0.2 if not specified\n",
    "\n",
    "        # Get the top_k most similar sentences from the corpus\n",
    "        top_results = np.argsort(cos_scores, axis=0)[-top_k:]\n",
    "\n",
    "        # Prepare the initial results list\n",
    "        initial_results = [(self.corpus[idx], cos_scores[idx].item()) for idx in reversed(top_results)]\n",
    "\n",
    "        # Filter the results based on the minimum relevancy threshold\n",
    "        filtered_results = [result for result in initial_results if result[1] >= minimum_relevancy]\n",
    "\n",
    "        # If all results are below the threshold, issue a warning and return the top result\n",
    "        if not filtered_results:\n",
    "            warnings.warn(\n",
    "                \"All top results are below the minimum relevancy threshold. \"\n",
    "                \"Returning the highest match instead.\",\n",
    "                UserWarning\n",
    "            )\n",
    "            return [initial_results[0]]\n",
    "        else:\n",
    "            return filtered_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Preparing the Semantic Search Corpus\n",
    "\n",
    "In this section of our tutorial, we focus on constructing and preparing the corpus for our semantic search model. The corpus forms the backbone of our search functionality, serving as the database against which user queries are compared.\n",
    "\n",
    "### Simulating a Real-World Use Case\n",
    "\n",
    "In a real-world scenario, a semantic search model might need to sift through tens of thousands of blog posts stored in a large database. For the purpose of this tutorial, we are using a simplified subset to demonstrate the core principles without the complexity of handling a massive dataset. Our corpus consists of synthetic blog post entries, each composed of a title and the first two sentences of the post.\n",
    "\n",
    "#### Key Steps in Corpus Preparation:\n",
    "\n",
    "1. **Corpus Creation**: We create a list named `corpus`, where each element is a string representing a blog post (title plus the first two sentences).\n",
    "2. **Writing to a File**: The corpus is then written to a file (`search_corpus.txt`). In a real application, this could represent extracting and preprocessing data from a larger database.\n",
    "\n",
    "### Efficient Data Handling for Scalability\n",
    "\n",
    "In our `SemanticSearchModel`, the corpus is encoded only once when the model is loaded for inference. This process converts the textual data into semantically meaningful embeddings using the Sentence Transformer model. These embeddings are stored in memory, which allows for efficient and rapid comparison with incoming search queries.\n",
    "\n",
    "#### Production Considerations:\n",
    "\n",
    "- **Storing Embeddings**: In a production environment, especially when dealing with large-scale data, storing these embeddings efficiently becomes crucial. Options include using a vector database or an in-memory database like [Redis](https://redis.com/) or [Elasticsearch](https://www.elastic.co/). These systems are optimized for handling high-dimensional data and can significantly speed up search operations.\n",
    "- **Scalability**: For a use case involving millions of embeddings, a vector database or in-memory database not only provides efficient storage but also offers scalability. These systems can handle large volumes of data and support complex queries, essential for real-time semantic search applications.\n",
    "- **Updating the Corpus**: In a dynamic application where new blog posts are continually added, the system would periodically update the corpus and its embeddings. This could be achieved through incremental updates or scheduled reprocessing of the entire dataset.\n",
    "\n",
    "### Realizing the Semantic Search Concept\n",
    "\n",
    "By setting up this corpus and discussing its practical implications, we lay the groundwork for realizing a semantic search system. The approach demonstrated here, while simplified for tutorial purposes, mirrors the foundational steps necessary in a large-scale, real-world application. It showcases how advanced NLP techniques, combined with efficient data handling and storage solutions, can be leveraged to create powerful and scalable semantic search platforms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Perfecting a Sourdough Bread Recipe: The Joy of Baking. Baking sourdough bread \"\n",
    "    \"requires patience, skill, and a good understanding of yeast fermentation. Each \"\n",
    "    \"loaf is unique, telling its own story of the baker's journey.\",\n",
    "    \n",
    "    \"The Mars Rover's Discoveries: Unveiling the Red Planet. NASA's Mars rover has \"\n",
    "    \"sent back stunning images and data, revealing the planet's secrets. These \"\n",
    "    \"discoveries may hold the key to understanding Mars' history.\",\n",
    "    \n",
    "    \"The Art of Growing Herbs: Enhancing Your Culinary Skills. Growing your own \"\n",
    "    \"herbs can transform your cooking, adding fresh and vibrant flavors. Whether it's \"\n",
    "    \"basil, thyme, or rosemary, each herb has its own unique characteristics.\",\n",
    "    \n",
    "    \"AI in Software Development: Transforming the Tech Landscape. The rapid \"\n",
    "    \"advancements in artificial intelligence are reshaping how we approach software \"\n",
    "    \"development. From automation to machine learning, the possibilities are endless.\",\n",
    "    \n",
    "    \"Backpacking Through Europe: A Journey of Discovery. Traveling across Europe by \"\n",
    "    \"backpack allows one to immerse in diverse cultures and landscapes. It's an \"\n",
    "    \"adventure that combines the thrill of exploration with personal growth.\",\n",
    "    \n",
    "    \"Shakespeare's Timeless Influence: Reshaping Modern Storytelling. The works of \"\n",
    "    \"William Shakespeare continue to inspire and influence contemporary literature. \"\n",
    "    \"His mastery of language and deep understanding of human nature are unparalleled.\",\n",
    "    \n",
    "    \"The Rise of Renewable Energy: A Sustainable Future. Embracing renewable energy \"\n",
    "    \"is crucial for achieving a sustainable and environmentally friendly lifestyle. \"\n",
    "    \"Solar, wind, and hydro power are leading the way in this green revolution.\",\n",
    "    \n",
    "    \"The Magic of Jazz: An Exploration of Sound and Harmony. Jazz music, known for \"\n",
    "    \"its improvisation and complex harmonies, has a rich and diverse history. It \"\n",
    "    \"evokes a range of emotions, often reflecting the soul of the musician.\",\n",
    "    \n",
    "    \"Yoga for Mind and Body: The Benefits of Regular Practice. Engaging in regular \"\n",
    "    \"yoga practice can significantly improve flexibility, strength, and mental \"\n",
    "    \"well-being. It's a holistic approach to health, combining physical and spiritual \"\n",
    "    \"aspects.\",\n",
    "    \n",
    "    \"The Egyptian Pyramids: Monuments of Ancient Majesty. The ancient Egyptian \"\n",
    "    \"pyramids, monumental tombs for pharaohs, are marvels of architectural \"\n",
    "    \"ingenuity. They stand as a testament to the advanced skills of ancient builders.\",\n",
    "    \n",
    "    \"Vegan Cuisine: A World of Flavor. Exploring vegan cuisine reveals a world of \"\n",
    "    \"nutritious and delicious possibilities. From hearty soups to delectable desserts, \"\n",
    "    \"plant-based dishes are diverse and satisfying.\",\n",
    "\n",
    "    \"Extraterrestrial Life: The Endless Search. The quest to find life beyond Earth \"\n",
    "    \"continues to captivate scientists and the public alike. Advances in space \"\n",
    "    \"technology are bringing us closer to answering this age-old question.\",\n",
    "\n",
    "    \"The Art of Plant Pruning: Promoting Healthy Growth. Regular pruning is essential \"\n",
    "    \"for maintaining healthy and vibrant plants. It's not just about cutting back, but \"\n",
    "    \"understanding each plant's growth patterns and needs.\",\n",
    "\n",
    "    \"Cybersecurity in the Digital Age: Protecting Our Data. With the rise of digital \"\n",
    "    \"technology, cybersecurity has become a critical concern. Protecting sensitive \"\n",
    "    \"information from cyber threats is an ongoing challenge for individuals and \"\n",
    "    \"businesses alike.\",\n",
    "\n",
    "    \"The Great Wall of China: A Historical Journey. Visiting the Great Wall offers \"\n",
    "    \"more than just breathtaking views; it's a journey through history. This ancient \"\n",
    "    \"structure tells stories of empires, invasions, and human resilience.\",\n",
    "\n",
    "    \"Mystery Novels: Crafting Suspense and Intrigue. A great mystery novel captivates \"\n",
    "    \"the reader with intricate plots and unexpected twists. It's a genre that combines \"\n",
    "    \"intellectual challenge with entertainment.\",\n",
    "\n",
    "    \"Conserving Endangered Species: A Global Effort. Protecting endangered species \"\n",
    "    \"is a critical task that requires international collaboration. From rainforests to \"\n",
    "    \"oceans, every effort counts in preserving our planet's biodiversity.\",\n",
    "\n",
    "    \"Emotions in Classical Music: A Symphony of Feelings. Classical music is not just \"\n",
    "    \"an auditory experience; it's an emotional journey. Each composition tells a story, \"\n",
    "    \"conveying feelings from joy to sorrow, tranquility to excitement.\",\n",
    "\n",
    "    \"CrossFit: A Test of Strength and Endurance. CrossFit is more than just a fitness \"\n",
    "    \"regimen; it's a lifestyle that challenges your physical and mental limits. It \"\n",
    "    \"combines various disciplines to create a comprehensive workout.\",\n",
    "\n",
    "    \"The Renaissance: An Era of Artistic Genius. The Renaissance marked a period of \"\n",
    "    \"extraordinary artistic and scientific achievements. It was a time when creativity \"\n",
    "    \"and innovation flourished, reshaping the course of history.\",\n",
    "\n",
    "    \"Exploring International Cuisines: A Culinary Adventure. Discovering international \"\n",
    "    \"cuisines is an adventure for the palate. Each dish offers a glimpse into the \"\n",
    "    \"culture and traditions of its origin.\",\n",
    "\n",
    "    \"Astronaut Training: Preparing for the Unknown. Becoming an astronaut involves \"\n",
    "    \"rigorous training to prepare for the extreme conditions of space. It's a journey \"\n",
    "    \"that tests both physical endurance and mental resilience.\",\n",
    "\n",
    "    \"Sustainable Gardening: Nurturing the Environment. Sustainable gardening is not \"\n",
    "    \"just about growing plants; it's about cultivating an ecosystem. By embracing \"\n",
    "    \"environmentally friendly practices, gardeners can have a positive impact on the \"\n",
    "    \"planet.\",\n",
    "\n",
    "    \"The Smartphone Revolution: Changing Communication. Smartphones have transformed \"\n",
    "    \"how we communicate, offering unprecedented connectivity and convenience. This \"\n",
    "    \"technology continues to evolve, shaping our daily interactions.\",\n",
    "\n",
    "    \"Experiencing African Safaris: Wildlife and Wilderness. An African safari is an \"\n",
    "    \"unforgettable experience that brings you face-to-face with the wonders of \"\n",
    "    \"wildlife. It's a journey that connects you with the raw beauty of nature.\",\n",
    "\n",
    "    \"Graphic Novels: A Blend of Art and Story. Graphic novels offer a unique medium \"\n",
    "    \"where art and narrative intertwine to tell compelling stories. They challenge \"\n",
    "    \"traditional forms of storytelling, offering visual and textual richness.\",\n",
    "\n",
    "    \"Addressing Ocean Pollution: A Call to Action. The increasing levels of pollution \"\n",
    "    \"in our oceans are a pressing environmental concern. Protecting marine life and \"\n",
    "    \"ecosystems requires concerted global efforts.\",\n",
    "\n",
    "    \"The Origins of Hip Hop: A Cultural Movement. Hip hop music, originating from the \"\n",
    "    \"streets of New York, has grown into a powerful cultural movement. Its beats and \"\n",
    "    \"lyrics reflect the experiences and voices of a community.\",\n",
    "\n",
    "    \"Swimming: A Comprehensive Workout. Swimming offers a full-body workout that is \"\n",
    "    \"both challenging and refreshing. It's an exercise that enhances cardiovascular \"\n",
    "    \"health, builds muscle, and improves endurance.\",\n",
    "\n",
    "    \"The Fall of the Berlin Wall: A Historical Turning Point. The fall of the Berlin \"\n",
    "    \"Wall was not just a physical demolition; it was a symbol of political and social \"\n",
    "    \"change. This historic event marked the end of an era and the beginning of a new \"\n",
    "    \"chapter in world history.\"\n",
    "]\n",
    "\n",
    "# Write the corpus to a file\n",
    "corpus_file = '/tmp/search_corpus.txt'\n",
    "with open(corpus_file, 'w') as file:\n",
    "    for sentence in corpus:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation and Configuration in MLflow\n",
    "\n",
    "In this section, we delve into the setup of our Sentence Transformer model and its integration with MLflow. This step is crucial for preparing the model for deployment and ensuring it can be used effectively in a practical setting.\n",
    "\n",
    "### Loading and Saving the Sentence Transformer Model\n",
    "\n",
    "1. **Model Initialization**: \n",
    "    - We begin by loading a pre-trained sentence transformer model using the `SentenceTransformer` class from the `sentence_transformers` library. \n",
    "    - The model chosen is `\"all-MiniLM-L6-v2\"`, which is a compact and efficient transformer model known for its balance between performance and speed, making it ideal for semantic search tasks.\n",
    "\n",
    "2. **Model Storage**:\n",
    "    - The model is then saved to a directory (`/tmp/search_model`). This step is essential for creating a portable version of the model that can be loaded by MLflow later for deployment. In production, the location to store the model would be to a permanent location that the production deployment service has access to.\n",
    "    - For the purposes of this tutorial, saving the model locally also allows for version control and easy management of the model artifact.\n",
    "\n",
    "### Preparing Model Artifacts and Signature\n",
    "\n",
    "1. **Artifacts Dictionary**:\n",
    "    - We create a dictionary named `artifacts`, which contains paths to the model and the corpus file. \n",
    "    - This dictionary is crucial as it tells MLflow where to find the necessary components for the model to function correctly during inference.\n",
    "\n",
    "2. **Input Example and Test Output**:\n",
    "    - An input example (`input_example`) is defined, simulating a typical query that the model is expected to process. This helps in understanding the model's input structure.\n",
    "    - Similarly, `test_output` provides a sample of the expected output format. In our case, it's a list of matched sentences.\n",
    "\n",
    "3. **Model Signature**:\n",
    "    - The `infer_signature` function from MLflow is used to automatically generate a model signature based on the provided input and output examples.\n",
    "    - The signature describes the model's input and output schema, providing valuable metadata about the types and shapes of data the model expects and produces.\n",
    "    - We also include parameters `top_k` and `minimum_relevancy` in the signature to explicitly define the model's expected behavior regarding the number of results and their relevancy threshold.\n",
    "\n",
    "### Importance of the Model Signature\n",
    "\n",
    "- The signature plays a vital role in model deployment and usage. It ensures consistency between the model training environment and the deployment environment, reducing the chances of errors due to mismatched data formats.\n",
    "- It also aids in the interpretability of the model, making it clear to users how to interact with the model and what kind of results to expect.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This setup process is a critical part of model preparation in MLflow. It involves not only loading from the Hugging Face Hub and locally saving the model but also meticulously preparing all associated artifacts and defining a clear and informative model signature. This comprehensive approach ensures that the model is ready for deployment, with all its dependencies and operational requirements clearly specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [string]\n",
       "outputs: \n",
       "  [string]\n",
       "params: \n",
       "  ['top_k': long (default: 3), 'minimum_relevancy': double (default: 0.2)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create an input example DataFrame\n",
    "input_example = [\"Something I want to find matches for.\"]\n",
    "\n",
    "# Save the model in the /tmp directory\n",
    "model_directory = \"/tmp/search_model\"\n",
    "model.save(model_directory)\n",
    "\n",
    "artifacts = {\n",
    "    \"model_path\": model_directory,\n",
    "    \"corpus_file\": corpus_file\n",
    "}\n",
    "\n",
    "# Generate test output for signature\n",
    "test_output = [\"match 1\", \"match 2\", \"match 3\"]\n",
    "\n",
    "# Define the signature associated with the model\n",
    "signature = infer_signature(input_example, test_output, params={\"top_k\": 3, \"minimum_relevancy\": 0.2})\n",
    "\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the tracking server and creating an experiment\n",
    "\n",
    "In order to view the results in our tracking server (for the purposes of this tutorial, weâ€™ve started a local tracking server at this url)\n",
    "\n",
    "We can start an instance of the MLflow server locally by running the following from a terminal to start the tracking server:\n",
    "\n",
    "``` bash\n",
    "mlflow server --host 127.0.0.1 --port 8080\n",
    "```\n",
    "\n",
    "With the server started, the following code will ensure that all experiments, runs, models, parameters, and metrics that we log are being tracked within that server instance (which also provides us with the MLflow UI when navigating to that url address in a browser).\n",
    "\n",
    "After setting the tracking url, we create a new MLflow Experiment to store the run weâ€™re about to create in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/413386080563320984', creation_time=1700272457800, experiment_id='413386080563320984', last_update_time=1700272457800, lifecycle_stage='active', name='Semantic Similarity', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "mlflow.set_experiment(\"Semantic Similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the Model with MLflow\n",
    "\n",
    "After setting up the model and its necessary components, the next critical step in our tutorial is to log the model using MLflow. This process registers the model in the MLflow tracking system, making it manageable and deployable through the MLflow framework.\n",
    "\n",
    "### Starting an MLflow Run\n",
    "\n",
    "1. **Context Management**: \n",
    "    - We use the `with mlflow.start_run() as run:` statement to initiate an MLflow run. This statement creates a new run in MLflow's tracking system, which will record metrics, parameters, and the model itself.\n",
    "    - Using `with` ensures that the run is properly closed after all operations within the block are completed, maintaining clean and consistent tracking.\n",
    "\n",
    "### Logging the Model\n",
    "\n",
    "2. **Model Logging**: \n",
    "    - The `mlflow.pyfunc.log_model` function is used to log our custom Python function model, `SemanticSearchModel`, in MLflow.\n",
    "    - Key arguments in `log_model` function:\n",
    "        - `\"semantic_search\"`: The name given to the logged model.\n",
    "        - `python_model=SemanticSearchModel()`: Specifies the instance of our custom model class.\n",
    "        - `input_example=input_example`: Provides a sample input for the model, used for documentation and to help MLflow understand the model's input format.\n",
    "        - `signature=signature`: The model signature, as previously defined, describing input and output schemas.\n",
    "        - `artifacts=artifacts`: The artifacts dictionary, which includes paths to the model and the corpus file.\n",
    "        - `pip_requirements=[\"sentence_transformers\", \"numpy\"]`: Specifies Python package requirements needed for the model to run. This ensures that the deployment environment is correctly set up with the necessary dependencies.\n",
    "\n",
    "### Outcome of Model Logging\n",
    "\n",
    "- **Model Registration**: The model, along with its artifacts, signature, and requirements, is now registered in MLflow. It is stored in a way that is easily accessible and deployable.\n",
    "- **Reproducibility and Traceability**: By logging the model in MLflow, we ensure reproducibility of results and maintain traceability of the model's version and its associated data.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Logging the model in MLflow is a crucial step that bridges the gap between model development and deployment. It encapsulates the model and its dependencies in a format that is ready for production use, ensuring that the model can be deployed consistently regardless of the deployment environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b2e7ad716c4882b9e4b4b42392434e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/20 11:59:40 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd3021a1bd2439da1d929c519bafc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        \"semantic_search\",\n",
    "        python_model=SemanticSearchModel(),\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        artifacts=artifacts,\n",
    "        pip_requirements=[\"sentence_transformers\", \"numpy\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference and Prediction Demonstration\n",
    "\n",
    "Having logged our semantic search model with MLflow, we now move to the crucial phase of loading and using the model for making predictions. This step demonstrates the model's practical application in responding to user queries.\n",
    "\n",
    "### Loading the Model for Inference\n",
    "\n",
    "1. **Model Loading**: \n",
    "    - We use `mlflow.pyfunc.load_model` to load the model for inference. This function takes the model's URI, which uniquely identifies the model in the MLflow tracking system.\n",
    "    - The loaded model, `loaded_dynamic`, is now an instance of our `SemanticSearchModel` and is ready to process queries.\n",
    "\n",
    "### Making a Prediction\n",
    "\n",
    "2. **Running a Query**:\n",
    "    - To demonstrate the model's functionality, we pass a sample query: `\"I'd like some ideas for a meal to cook.\"` This query is representative of the kind of user input the model is designed to handle.\n",
    "    - The `predict` method of `loaded_dynamic` is called with the query, triggering the semantic search process over the corpus.\n",
    "\n",
    "### Understanding the Prediction Output\n",
    "\n",
    "- **Output Format**:\n",
    "    - The output is a list of tuples, where each tuple contains a matched corpus entry and its corresponding cosine similarity score.\n",
    "    - The cosine similarity score represents how relevant each entry is to the query, with higher scores indicating greater relevance.\n",
    "\n",
    "3. **Example Results**:\n",
    "    - The model returns entries related to cooking and culinary skills, showcasing its ability to understand the semantic context of the query.\n",
    "    - The results include matches related to international cuisines, vegan cooking, and herb gardening, each with a relevance score:\n",
    "        - International cuisines: 0.4385\n",
    "        - Vegan cuisine: 0.3469\n",
    "        - Growing herbs: 0.2269\n",
    "    - These scores indicate the model's assessment of how closely each blog post matches the user's query.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This demonstration highlights the model's capability to interpret a user's query semantically and return relevant blog post suggestions. The results show the effectiveness of the Sentence Transformers in encoding semantic meaning and the power of cosine similarity in matching queries to corpus entries. It exemplifies the potential of our semantic search model in real-world applications, such as recommendation systems or knowledge retrieval platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1fd993e49948cc9e56ba8cf615b53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/20 11:59:41 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Exploring International Cuisines: A Culinary Adventure. Discovering international cuisines is an adventure for the palate. Each dish offers a glimpse into the culture and traditions of its origin.',\n",
       "  0.43857115507125854),\n",
       " ('Vegan Cuisine: A World of Flavor. Exploring vegan cuisine reveals a world of nutritious and delicious possibilities. From hearty soups to delectable desserts, plant-based dishes are diverse and satisfying.',\n",
       "  0.34688490629196167),\n",
       " (\"The Art of Growing Herbs: Enhancing Your Culinary Skills. Growing your own herbs can transform your cooking, adding fresh and vibrant flavors. Whether it's basil, thyme, or rosemary, each herb has its own unique characteristics.\",\n",
       "  0.22686949372291565)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dynamic = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "loaded_dynamic.predict([\"I'd like some ideas for a meal to cook.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Query Handling with Customizable Parameters and Warning Mechanism\n",
    "\n",
    "Our semantic search model not only offers customizable search parameters but also incorporates a warning mechanism for cases where the results do not meet certain criteria. This feature enhances the model's robustness and usability, ensuring that users are informed about the quality of the search results.\n",
    "\n",
    "### Executing a Customized Prediction with Warnings\n",
    "\n",
    "1. **Customized Query with Challenging Parameters**:\n",
    "    - We issue a query: `\"Latest stories on computing\"` with specific parameters `{\"top_k\": 10, \"minimum_relevancy\": 0.4}`.\n",
    "    - This query, coupled with a high relevancy threshold, creates a challenging scenario for the model, testing its ability to discern highly relevant content.\n",
    "\n",
    "2. **Triggering the Warning**:\n",
    "    - Due to the high `minimum_relevancy` threshold (0.4), the model may not find enough results that meet this criterion.\n",
    "    - When this occurs, the model triggers a `UserWarning`, alerting that all top results are below the minimum relevancy threshold.\n",
    "    - This warning mechanism is vital for user feedback, indicating that the search criteria might be too restrictive or that the corpus may not contain sufficiently relevant content for the specific query.\n",
    "\n",
    "### Understanding the Model's Response\n",
    "\n",
    "- **Result in Challenging Scenarios**:\n",
    "    - Despite the stringent criteria, the model still provides the best available match. In our example, the highest relevant match relates to AI in software development, with a score of 0.2534.\n",
    "    - This result, although below the threshold, is the closest match to the query based on the available corpus data.\n",
    "\n",
    "### Implications and Best Practices\n",
    "\n",
    "- **Balancing Relevancy and Coverage**:\n",
    "    - The `minimum_relevancy` parameter should be set considering the nature of the corpus and the typical use cases. Setting it too high may lead to frequent warnings and fewer results.\n",
    "    - Understanding the balance between relevancy and the breadth of search results is crucial for optimizing user experience.\n",
    "\n",
    "- **User Feedback for Corpus Improvement**:\n",
    "    - Warnings can provide valuable feedback for refining the corpus. If certain queries consistently trigger warnings, it may indicate gaps in the corpus that need to be addressed.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This advanced demonstration with a warning mechanism highlights the model's capability to handle complex search scenarios and provide meaningful feedback. It underscores the importance of tuning search parameters appropriately and using user feedback to continually improve the search system. Such features make our semantic search model not just a tool for retrieval but also a dynamic system capable of adapting and improving over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_79034/2125590310.py:65: UserWarning: All top results are below the minimum relevancy threshold. Returning the highest match instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AI in Software Development: Transforming the Tech Landscape. The rapid advancements in artificial intelligence are reshaping how we approach software development. From automation to machine learning, the possibilities are endless.',\n",
       "  0.2533860206604004)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dynamic.predict([\"Latest stories on computing\"], params={\"top_k\": 10, \"minimum_relevancy\": 0.4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Crafting Custom Logic with MLflow's PythonModel\n",
    "\n",
    "As we wrap up this tutorial, let's reflect on the key learnings and the powerful capabilities of MLflow's `PythonModel` in crafting custom logic for real-world applications, particularly when integrating advanced libraries like `sentence-transformers`.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Flexibility of PythonModel**:\n",
    "    - The `PythonModel` in MLflow offers unparalleled flexibility in defining custom logic. Throughout this tutorial, we leveraged this to build a semantic search model tailored to our specific requirements.\n",
    "    - This flexibility proves invaluable when dealing with complex use cases that go beyond standard model implementations.\n",
    "\n",
    "2. **Integration with Sentence Transformers**:\n",
    "    - We seamlessly integrated the `sentence-transformers` library within our MLflow model. This demonstrated how advanced NLP capabilities can be embedded within custom models to handle sophisticated tasks like semantic search.\n",
    "    - The use of transformer models for generating embeddings showcased how cutting-edge NLP techniques could be applied in practical scenarios.\n",
    "\n",
    "3. **Customization and User Experience**:\n",
    "    - Our model not only performed the core task of semantic search but also allowed for customizable search parameters (`top_k` and `minimum_relevancy`). This level of customization is crucial for aligning the model's output with varying user needs.\n",
    "    - The inclusion of a warning mechanism further enriched the model by providing valuable feedback, enhancing the user experience.\n",
    "\n",
    "4. **Real-World Application and Scalability**:\n",
    "    - While our tutorial focused on a controlled dataset, the principles and methodologies apply to much larger, real-world datasets. The discussion around using vector databases and in-memory databases like Redis or Elasticsearch for scalability highlighted how the model could be adapted for large-scale applications.\n",
    "\n",
    "### Empowering Real-World Applications\n",
    "\n",
    "- The combination of MLflow's `PythonModel` and advanced libraries like `sentence-transformers` simplifies the creation of sophisticated, real-world applications. \n",
    "- The ability to encapsulate complex logic, manage dependencies, and ensure model portability makes MLflow an invaluable tool in the modern data scientist's toolkit.\n",
    "\n",
    "### Moving Forward\n",
    "\n",
    "- As we conclude, remember that the journey doesn't end here. The concepts and techniques explored in this tutorial lay the groundwork for further exploration and innovation in the field of NLP and beyond.\n",
    "- We encourage you to take these learnings, experiment with your datasets, and continue pushing the boundaries of what's possible with MLflow and advanced NLP technologies.\n",
    "\n",
    "Thank you for joining us on this enlightening journey through semantic search with Sentence Transformers and MLflow!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
