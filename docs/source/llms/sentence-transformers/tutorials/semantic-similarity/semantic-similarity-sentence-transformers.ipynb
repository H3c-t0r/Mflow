{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Advanced Semantic Similarity Analysis with Sentence Transformers and MLflow\n",
    "\n",
    "Welcome to our in-depth tutorial on Semantic Similarity Analysis using **Sentence Transformers** with an advanced twist in **MLflow**. This tutorial is tailored for individuals eager to explore sophisticated applications in natural language processing (NLP), with a particular focus on managing and deploying flexible NLP models. We will take you through an illustrative example, showcasing the integration of the `sentence-transformers` library with MLflow, and highlight a custom implementation that transcends typical usage.\n",
    "\n",
    "### Unveiling the Power of Sentence Transformers for NLP\n",
    "\n",
    "**Sentence Transformers** stand out as a specialized adaptation of traditional transformer models, meticulously optimized to produce semantically rich sentence embeddings. Stemming from the prominent Transformers library by ðŸ¤— Hugging Face, these models excel in NLP tasks such as semantic search, clustering, and most pertinently, similarity analysis. Leveraging advanced models like BERT and RoBERTa, `sentence-transformers` enable deep semantic understanding at the sentence level.\n",
    "\n",
    "### MLflow: Pioneering Flexible Model Management and Deployment\n",
    "\n",
    "Integrating MLflow with Sentence Transformers not only simplifies managing NLP projects but also introduces a realm of possibilities for custom model functionalities:\n",
    "\n",
    "- **Enhanced Experiment Tracking**: Effortlessly log detailed experiments, including unique model parameters and sentence embeddings, using MLflow.\n",
    "- **Custom `PythonModel` Implementation**: A key learning point in this tutorial is the custom `PythonModel` implementation within MLflow. While the native `sentence-transformers` model in MLflow returns pooled embeddings, our custom implementation creatively adapts this to return cosine similarity scores between pairs of texts, showcasing the versatility enabled by MLflow's `PythonModel` abstraction.\n",
    "- **Robust Model Lifecycle Management**: MLflow facilitates effective versioning and configuration control, vital for the iterative nature of NLP model development.\n",
    "- **Deployment Readiness and Reproducibility**: MLflow ensures that your NLP models are not only deployment-ready but also reproducible, allowing for consistent and reliable applications of your models in production environments.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "In this tutorial, you will:\n",
    "\n",
    "- Configure and utilize the `sentence-transformers` library for semantic similarity analysis.\n",
    "- Delve into MLflowâ€™s custom `PythonModel` implementation, understanding how to extend base model functionalities for bespoke requirements.\n",
    "- Master logging models, configurations, and leveraging model signatures in MLflow.\n",
    "- Deploy and apply these advanced models for inference, taking full advantage of MLflow's deployment capabilities.\n",
    "\n",
    "By the conclusion of this tutorial, you will have gained valuable insights into conducting advanced semantic similarity analyses using Sentence Transformers and exploiting MLflow's flexibility for custom model deployment. Whether you're deepening your NLP expertise or branching out into new territories of model management, this tutorial will empower you with the skills to innovatively track, manage, and deploy complex NLP models.\n",
    "\n",
    "Let's embark on this enlightening journey of semantic similarity exploration with Sentence Transformers and MLflow!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Custom SimilarityModel with MLflow\n",
    "\n",
    "In this section, we introduce a custom model class, `SimilarityModel`, derived from MLflow's `PythonModel`. This class is designed to compare the semantic similarity between two sentences using sentence embeddings.\n",
    "\n",
    "### Overview of SimilarityModel\n",
    "\n",
    "The `SimilarityModel` class is a bespoke implementation that allows us to extend the basic functionality of the Sentence Transformer model. It encapsulates the logic required for loading the model, preparing input data, and predicting the cosine similarity between sentence pairs.\n",
    "\n",
    "#### 1. Importing Necessary Libraries:\n",
    "\n",
    "- **MLflow Components**: We import `mlflow`, `infer_signature`, and `PythonModel` from MLflow to handle model logging, signature inference, and custom model creation.\n",
    "- **Data Handling Libraries**: `numpy` and `pandas` are imported for numerical operations and data manipulation.\n",
    "- **Sentence Transformer Components**: `SentenceTransformer` and `util` from the `sentence_transformers` library are used for model loading and utility functions.\n",
    "\n",
    "#### 2. Custom PythonModel - SimilarityModel:\n",
    "\n",
    "- **load_context Method**:\n",
    "  - The `load_context` method is crucial for loading the model context during inference. Instead of initializing the Sentence Transformer model directly within the class (which can cause serialization issues due to the complexity of the object), we load the model using the path provided in the context. This method ensures safe and efficient model loading, avoiding potential serialization errors.\n",
    "  - The `SentenceTransformer.load` function is used to load the model from the specified path in the `context.artifacts`.\n",
    "\n",
    "- **predict Method**:\n",
    "  - The `predict` method is the core of our custom model, designed to accept either a DataFrame or a dictionary as input.\n",
    "  - **Input Type Checking**: We implement checks to ensure the input is either a DataFrame with exactly two columns or a dictionary with two specific keys (`'sentence_1'` and `'sentence_2'`). This type checking is vital to ensure the model receives correctly formatted input, thereby protecting end-users from encountering unexpected errors.\n",
    "  - **Sentence Embeddings**: For both sentences provided as input, we generate embeddings using the Sentence Transformer model's `encode` method.\n",
    "  - **Cosine Similarity Calculation**: Utilizing the `util.cos_sim` function, we calculate the cosine similarity between the two sentence embeddings. This similarity score is a measure of how semantically similar the two sentences are.\n",
    "\n",
    "### Significance of Custom SimilarityModel\n",
    "\n",
    "- **Flexibility**: By defining our model within `PythonModel`, we gain the flexibility to specify how inputs are handled and how predictions are made, tailoring the model to our specific semantic analysis task.\n",
    "- **Robustness**: The input type checking and error handling ensure that the model behaves predictably and robustly, providing clear and informative error messages if incorrect input types are provided.\n",
    "- **Efficient Model Loading**: Using `load_context` for model loading helps in avoiding common serialization pitfalls associated with complex model objects like Sentence Transformers.\n",
    "- **Custom Functionality**: Implementing the `predict` method with Sentence Transformer's encoding and utility function for cosine similarity allows us to create a model that directly computes similarity scores, a more specialized application compared to standard sentence embedding models.\n",
    "\n",
    "This custom `SimilarityModel` demonstrates the power of MLflow's `PythonModel` for creating advanced, deployable NLP models that go beyond basic functionalities, providing a blueprint for similar custom implementations in various ML projects.\n",
    "\n",
    "Let's proceed to implement this custom model in our MLflow setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "class SimilarityModel(PythonModel):\n",
    "\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load the model context for inference.\"\"\"\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        try:\n",
    "            self.model = SentenceTransformer.load(context.artifacts[\"model_path\"])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading model: {e}\")\n",
    "\n",
    "    def predict(self, context, model_input, params):\n",
    "        \"\"\"Predict method for comparing similarity between two sentences.\"\"\"\n",
    "        from sentence_transformers import util\n",
    "\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            if model_input.shape[1] != 2:\n",
    "                raise ValueError(\"DataFrame input must have exactly two columns.\")\n",
    "            sentence_1, sentence_2 = model_input.iloc[0, 0], model_input.iloc[0, 1]\n",
    "        elif isinstance(model_input, dict):\n",
    "            sentence_1 = model_input.get(\"sentence_1\")\n",
    "            sentence_2 = model_input.get(\"sentence_2\")\n",
    "            if sentence_1 is None or sentence_2 is None:\n",
    "                raise ValueError(\"Both 'sentence_1' and 'sentence_2' must be provided in the input dictionary.\")\n",
    "        else:\n",
    "            raise TypeError(f\"Unexpected type for model_input: {type(model_input)}. Must be either a Dict or a DataFrame.\")\n",
    "\n",
    "        embedding_1 = self.model.encode(sentence_1)\n",
    "        embedding_2 = self.model.encode(sentence_2)\n",
    "\n",
    "        return np.array(util.cos_sim(embedding_1, embedding_2).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Sentence Transformer Model and Signature\n",
    "\n",
    "This part of the tutorial focuses on loading a pre-trained Sentence Transformer model, preparing an input example, saving the model, and defining its signature. These steps are essential for setting up the model for subsequent logging and deployment with MLflow.\n",
    "\n",
    "### Loading and Saving the Pre-trained Model\n",
    "\n",
    "1. **Model Initialization**:\n",
    "   - We load a pre-trained Sentence Transformer model using `SentenceTransformer(\"all-MiniLM-L6-v2\")`. The `\"all-MiniLM-L6-v2\"` model is known for its balance between performance and size, making it ideal for a variety of NLP tasks.\n",
    "\n",
    "2. **Model Saving**:\n",
    "   - After loading the model, we save it to a directory. In this case, we use `/tmp/sbert_model` as our saving location.\n",
    "   - Saving the model locally is a necessary step before we can log it with MLflow, as MLflow requires access to the model's file path.\n",
    "\n",
    "### Preparing Input Example and Artifacts\n",
    "\n",
    "1. **Input Example Creation**:\n",
    "   - We create a DataFrame `input_example` with two example sentences. This DataFrame mimics the format of the data that the model expects during inference.\n",
    "   - The example sentences chosen are `\"I like apples\"` and `\"I like oranges\"`.\n",
    "\n",
    "2. **Defining Artifacts**:\n",
    "   - Artifacts in MLflow are additional files, like models and data files, associated with ML runs. We define our model's path in the `artifacts` dictionary, using the key `\"model_path\"` and the path where we saved the model.\n",
    "\n",
    "### Generating Test Output for Signature\n",
    "\n",
    "1. **Test Output Calculation**:\n",
    "   - To generate a test output for the signature, we calculate the cosine similarity between the embeddings of our example sentences. This is done using `util.cos_sim`.\n",
    "   - The cosine similarity score gives us an insight into how similar the sentences are in terms of their semantic content.\n",
    "\n",
    "2. **Signature Inference**:\n",
    "   - The signature of a model in MLflow defines the input and output schema. We use `infer_signature` to automatically generate this signature based on our `input_example` and the generated `test_output`.\n",
    "   - The inferred signature will be used by MLflow to validate the input and output formats when the model is deployed and used for prediction.\n",
    "\n",
    "### Importance of These Steps\n",
    "\n",
    "- **Model Readiness**: Loading and saving the model ensure that it is ready for logging and deployment via MLflow.\n",
    "- **Input-Output Contract**: The signature acts as a contract that specifies what the model expects as input and what it produces as output, crucial for ensuring consistency and reliability in model deployment.\n",
    "\n",
    "By completing these steps, we have effectively prepared our Sentence Transformer model and defined its operational schema, setting the stage for its integration and management within the MLflow ecosystem.\n",
    "\n",
    "Let's move forward with preparing our model and its signature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create an input example DataFrame\n",
    "input_example = pd.DataFrame([{\"sentence_1\": \"I like apples\", \"sentence_2\": \"I like oranges\"}])\n",
    "\n",
    "# Save the model in the /tmp directory\n",
    "model_directory = \"/tmp/sbert_model\"\n",
    "model.save(model_directory)\n",
    "\n",
    "# Define artifacts with the absolute path\n",
    "artifacts = {\"model_path\": model_directory}\n",
    "\n",
    "# Generate test output for signature\n",
    "test_output = np.array(util.cos_sim(model.encode(input_example[\"sentence_1\"][0]), \n",
    "                                    model.encode(input_example[\"sentence_2\"][0])).tolist())\n",
    "\n",
    "# Define the signature associated with the model\n",
    "signature = infer_signature(input_example, test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the tracking server and creating an experiment\n",
    "\n",
    "In order to view the results in our tracking server (for the purposes of this tutorial, weâ€™ve started a local tracking server at this url)\n",
    "\n",
    "We can start an instance of the MLflow server locally by running the following from a terminal to start the tracking server:\n",
    "\n",
    "``` bash\n",
    "mlflow server --host 127.0.0.1 --port 8080\n",
    "```\n",
    "\n",
    "With the server started, the following code will ensure that all experiments, runs, models, parameters, and metrics that we log are being tracked within that server instance (which also provides us with the MLflow UI when navigating to that url address in a browser).\n",
    "\n",
    "After setting the tracking url, we create a new MLflow Experiment to store the run weâ€™re about to create in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/17 20:54:17 INFO mlflow.tracking.fluent: Experiment with name 'Semantic Similarity' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/413386080563320984', creation_time=1700272457800, experiment_id='413386080563320984', last_update_time=1700272457800, lifecycle_stage='active', name='Semantic Similarity', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "mlflow.set_experiment(\"Semantic Similarity\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the Custom Model with MLflow\n",
    "\n",
    "In this step, we log our custom `SimilarityModel` with MLflow. This process involves encapsulating the model within MLflow's logging mechanism, which allows for tracking, versioning, and later deployment.\n",
    "\n",
    "### Creating a Path for the PyFunc Model\n",
    "\n",
    "- **PyFunc Path**: We define a temporary path, `pyfunc_path`, where the model will be stored. This path is used by MLflow to save the serialized version of our Python model.\n",
    "\n",
    "### Logging the Model in MLflow\n",
    "\n",
    "- **Initiating MLflow Run**: We start an MLflow run using `with mlflow.start_run() as run:`. This run acts as a container for all the operations related to the model logging process.\n",
    "\n",
    "- **Model Logging Details**:\n",
    "  - **Model Name**: We specify `\"similarity\"` as the name for our logged model. This name can be used to reference the model in the MLflow tracking server.\n",
    "  - **Python Model**: The `python_model` parameter is provided with an instance of our `SimilarityModel`. This custom model class handles the loading of the Sentence Transformer model and the prediction logic for calculating cosine similarity.\n",
    "  - **Input Example**: We pass `input_example`, a DataFrame containing example sentences. This example helps users understand the format and type of data that the model expects.\n",
    "  - **Signature**: The `signature` that we previously inferred is included. It provides a schema for the model's input and output, ensuring that the model is used correctly.\n",
    "  - **Artifacts**: We include `artifacts`, which is a dictionary specifying the path to the saved Sentence Transformer model.\n",
    "  - **Python Dependencies**: The `pip_requirements` argument lists the necessary Python packages (`sentence_transformers` and `numpy`) for the model to function correctly when loaded in a different environment.\n",
    "\n",
    "### Significance of Model Logging\n",
    "\n",
    "- **Model Tracking and Versioning**: By logging the model in MLflow, we ensure that it is tracked and versioned, facilitating better model lifecycle management.\n",
    "- **Reproducibility and Deployment**: Logging the model with its input example, signature, and requirements ensures that it can be easily reproduced and deployed in different environments, maintaining consistency and reliability.\n",
    "\n",
    "Once the model is logged with MLflow, it is ready for further actions like model comparison, version tracking, and deployment for inference.\n",
    "\n",
    "Let's proceed to log our custom `SimilarityModel` with MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dec7732d3ab43028eef3149321332b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/17 20:54:18 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "pyfunc_path = \"/tmp/sbert_pyfunc\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        \"similarity\",\n",
    "        python_model=SimilarityModel(),\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        artifacts=artifacts,\n",
    "        pip_requirements=[\"sentence_transformers\", \"numpy\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference and Testing Similarity Prediction\n",
    "\n",
    "After logging our custom `SimilarityModel` with MLflow, we now proceed to load this model for inference. This step demonstrates how to use the model to compute the semantic similarity between two sentences.\n",
    "\n",
    "### Loading the Model for Inference\n",
    "\n",
    "- **Loading with MLflow**: We use `mlflow.pyfunc.load_model` to load our model. This function requires the model's URI, which we obtain from `model_info.model_uri`. The model URI is a unique identifier that MLflow uses to locate and load the model.\n",
    "- **Model Readiness**: The loaded model, `loaded_dynamic`, is now ready for inference. It encapsulates all the logic we defined in the `SimilarityModel`, including the Sentence Transformer model's loading and the cosine similarity calculation.\n",
    "\n",
    "### Preparing Data for Similarity Prediction\n",
    "\n",
    "- **Creating Input Data**: We create a DataFrame, `similarity_data`, containing a pair of sentences for which we want to compute the similarity. In this example, we use `\"I like apples\"` and `\"I like oranges\"` as our input sentences.\n",
    "- **Flexibility in Input Format**: This step demonstrates the flexibility of our custom model in accepting input data in a DataFrame format, which is intuitive and user-friendly.\n",
    "\n",
    "### Computing and Displaying Similarity Score\n",
    "\n",
    "- **Predicting Similarity**: We call the `predict` method on `loaded_dynamic` with our `similarity_data`. This method computes the cosine similarity between the embeddings of the two input sentences.\n",
    "- **Interpreting the Result**: The result, `similarity_score`, is a numerical representation of how similar the two sentences are in terms of their semantic content. A higher score indicates greater similarity.\n",
    "- **Output Display**: We print out the similarity score to provide a clear and immediate understanding of the model's output. For example, `The similarity between these sentences is: [similarity_score]`.\n",
    "\n",
    "### Importance of This Testing\n",
    "\n",
    "- **Model Validation**: This step is crucial for validating that our model behaves as expected when making predictions on new data.\n",
    "- **Practical Application**: Demonstrating the model's ability to compute sentence similarities showcases its practical application in real-world scenarios.\n",
    "\n",
    "By completing this inference test, we have successfully demonstrated the application of our custom `SimilarityModel` for semantic similarity analysis, highlighting the model's utility and effectiveness.\n",
    "\n",
    "Let's perform the inference test and observe the similarity score computed by our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27af986a5ff448f39cfe100cbbb3f53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/17 20:54:18 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between these sentences is: [[0.63414472]]\n"
     ]
    }
   ],
   "source": [
    "loaded_dynamic = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "similarity_data = pd.DataFrame([{\"sentence_1\": \"I like apples\", \"sentence_2\": \"I like oranges\"}])\n",
    "\n",
    "similarity_score = loaded_dynamic.predict(similarity_data)\n",
    "\n",
    "print(f\"The similarity between these sentences is: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Semantic Similarity with Distinct Text Pairs\n",
    "\n",
    "In this section, we use our loaded MLflow model to evaluate semantic similarity for two pairs of sentences, specifically chosen to demonstrate the model's capability to discern varying degrees of similarity.\n",
    "\n",
    "### Selection of Text Pairs\n",
    "\n",
    "1. **Low Similarity Pair (`low_similarity`)**:\n",
    "   - **Text Choice**: The first sentence describes an explorer at the edge of a rainforest, while the second details the process of installing software. These sentences were chosen for their starkly different themes and contexts â€“ one is an adventurous narrative, and the other is a technical instruction.\n",
    "   - **Expected Outcome**: Given their contrasting subject matters, we anticipate a low similarity score, reflecting the model's ability to recognize and differentiate disparate semantic contents.\n",
    "\n",
    "2. **High Similarity Pair (`high_similarity`)**:\n",
    "   - **Text Choice**: Both sentences in this pair describe personal experiences of visiting the Great Pyramids of Giza. While the sentence structures and specific details differ, the overarching theme, emotional tone, and subject matter are closely aligned.\n",
    "   - **Expected Outcome**: These sentences are expected to yield a high similarity score, demonstrating the model's capacity to detect semantic parallels in texts with similar underlying themes, despite surface-level variations.\n",
    "\n",
    "### sBERT Model's Role in Similarity Calculation\n",
    "\n",
    "- **Semantic Understanding**: The Sentence-BERT (sBERT) model implementation in our `SimilarityModel` encodes each sentence into a vector that captures its semantic essence. \n",
    "- **Cosine Similarity**: The model then computes the cosine similarity between these vectors. This similarity score quantifies how close the vectors (and hence the sentences) are in the multi-dimensional space, with a higher score indicating greater semantic similarity.\n",
    "\n",
    "### Computing and Displaying Similarity Scores\n",
    "\n",
    "- **Predicting for Low Similarity Pair**:\n",
    "  - We input the `low_similarity` pair to our model and obtain a similarity score. This score quantifies the semantic distance between the two vastly different sentences.\n",
    "  - The result is printed to give us a clear indication of how the model perceives the semantic relationship between these sentences.\n",
    "\n",
    "- **Predicting for High Similarity Pair**:\n",
    "  - Similarly, we input the `high_similarity` pair and obtain its similarity score. This score reflects the semantic closeness of the sentences, both centered around the awe-inspiring experience at the Pyramids of Giza.\n",
    "  - The output is printed, providing insight into the model's ability to recognize semantic similarities in contextually related sentences.\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "- **Model Validation**: These tests are critical for validating the effectiveness of our custom model in real-world scenarios. They demonstrate the model's nuanced understanding of language and its ability to quantify semantic relationships.\n",
    "- **Practical Implications**: Understanding how the model processes and evaluates semantic content is vital for applications such as content recommendation, information retrieval, and automated text comparison.\n",
    "\n",
    "By analyzing these similarity scores, we gain valuable insights into our model's semantic analysis capabilities, confirming its practical utility in distinguishing and quantifying semantic relationships between texts.\n",
    "\n",
    "Let's proceed to compute and observe the similarity scores for these carefully chosen text pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity score for the 'low_similarity' pair is: [[-0.00052751]]\n",
      "The similarity score for the 'high_similarity' pair is: [[0.83703309]]\n"
     ]
    }
   ],
   "source": [
    "low_similarity = {\n",
    "    \"sentence_1\": \"The explorer stood at the edge of the dense rainforest, \"\n",
    "                  \"contemplating the journey ahead. The untamed wilderness was \"\n",
    "                  \"a labyrinth of exotic plants and unknown dangers, a challenge \"\n",
    "                  \"for even the most seasoned adventurer, brimming with the \"\n",
    "                  \"prospect of new discoveries and uncharted territories.\",\n",
    "    \"sentence_2\": \"To install the software, begin by downloading the latest \"\n",
    "                  \"version from the official website. Once downloaded, run the \"\n",
    "                  \"installer and follow the on-screen instructions. Ensure that \"\n",
    "                  \"your system meets the minimum requirements and agree to the \"\n",
    "                  \"license terms to complete the installation process successfully.\"\n",
    "}\n",
    "\n",
    "high_similarity = {\n",
    "    \"sentence_1\": \"Standing in the shadow of the Great Pyramids of Giza, I felt a \"\n",
    "                  \"profound sense of awe. The towering structures, a testament to \"\n",
    "                  \"ancient ingenuity, rose majestically against the clear blue sky. \"\n",
    "                  \"As I walked around the base of the pyramids, the intricate \"\n",
    "                  \"stonework and sheer scale of these wonders of the ancient world \"\n",
    "                  \"left me speechless, enveloped in a deep sense of history.\",\n",
    "    \"sentence_2\": \"My visit to the Great Pyramids of Giza was an unforgettable \"\n",
    "                  \"experience. Gazing upon these monumental structures, I was \"\n",
    "                  \"captivated by their grandeur and historical significance. Each \"\n",
    "                  \"step around these ancient marvels filled me with a deep \"\n",
    "                  \"appreciation for the architectural prowess of a civilization long \"\n",
    "                  \"gone, yet still speaking through these timeless monuments.\"\n",
    "}\n",
    "\n",
    "low_similarity_score = loaded_dynamic.predict(low_similarity)\n",
    "\n",
    "print(f\"The similarity score for the 'low_similarity' pair is: {low_similarity_score}\")\n",
    "\n",
    "\n",
    "high_similarity_score = loaded_dynamic.predict(high_similarity)\n",
    "\n",
    "print(f\"The similarity score for the 'high_similarity' pair is: {high_similarity_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Harnessing the Power of Custom MLflow Python Functions in NLP\n",
    "\n",
    "As we conclude this tutorial, let's recap the significant strides we've made in understanding and applying advanced NLP techniques using Sentence Transformers and MLflow.\n",
    "\n",
    "### Key Takeaways from the Tutorial\n",
    "\n",
    "- **Versatile NLP Modeling**: We explored how to harness the advanced capabilities of Sentence Transformers for semantic similarity analysis, a critical task in many NLP applications.\n",
    "- **Custom MLflow Python Function**: The implementation of the custom `SimilarityModel` in MLflow demonstrated the power and flexibility of using Python functions to extend and adapt the functionality of pre-trained models to suit specific project needs.\n",
    "- **Model Management and Deployment**: We delved into the process of logging, managing, and deploying these models with MLflow, showcasing how MLflow streamlines these aspects of the machine learning lifecycle.\n",
    "- **Practical Semantic Analysis**: Through hands-on examples, we demonstrated the model's ability to discern varying degrees of semantic similarity between sentence pairs, validating its effectiveness in real-world semantic analysis tasks.\n",
    "\n",
    "### The Power and Flexibility of MLflow's Python Functions\n",
    "\n",
    "- **Customization for Specific Needs**: One of the tutorial's highlights is the demonstration of how MLflow's `PythonModel` can be customized. This customization is not only powerful but also necessary for tailoring models to specific NLP tasks that go beyond standard model functionalities.\n",
    "- **Adaptability and Extension**: The `PythonModel` framework in MLflow provides a solid foundation for implementing a wide range of NLP models. Its adaptability allows for the extension of base model functionalities, such as transforming a sentence embedding model into a semantic similarity comparison tool.\n",
    "\n",
    "### Empowering Advanced NLP Applications\n",
    "\n",
    "- **Ease of Modification**: The tutorial showcased that modifying the provided `PythonModel` implementation for different flavors in MLflow can be done with relative ease, empowering you to create models that align precisely with your project's requirements.\n",
    "- **Wide Applicability**: Whether it's semantic search, content recommendation, or automated text comparison, the approach outlined in this tutorial can be adapted to a broad spectrum of NLP tasks, opening doors to innovative applications in the field.\n",
    "\n",
    "### Moving Forward\n",
    "\n",
    "Armed with the knowledge and skills acquired in this tutorial, you are now well-equipped to apply these advanced NLP techniques in your projects. The seamless integration of Sentence Transformers with MLflow's robust model management and deployment capabilities paves the way for developing sophisticated, efficient, and effective NLP solutions.\n",
    "\n",
    "Thank you for joining us on this journey through advanced NLP modeling with Sentence Transformers and MLflow. We hope this tutorial has inspired you to explore further and innovate in your NLP endeavors!\n",
    "\n",
    "Happy Modeling!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
