{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Paraphrase Mining with Sentence Transformers and MLflow\n",
    "\n",
    "Welcome to our hands-on tutorial focused on **Advanced Paraphrase Mining using Sentence Transformers** and **MLflow**. This guide is crafted for those eager to delve into the fascinating world of Natural Language Processing (NLP), particularly in applying state-of-the-art NLP models within the robust framework of MLflow for effective model management and deployment.\n",
    "\n",
    "### Exploring Paraphrase Mining\n",
    "\n",
    "Paraphrase mining is the process of identifying textually distinct yet semantically similar sentences or phrases. Unlike basic text matching techniques, paraphrase mining delves deeper into the nuances of language, capturing the essence of meaning in different textual expressions. This capability is crucial in applications like document summarization, chatbot development, and information retrieval, where understanding the contextual similarity between sentences is essential.\n",
    "\n",
    "### The Role of Sentence Transformers in Paraphrase Mining\n",
    "\n",
    "**Sentence Transformers** are specialized adaptations of transformer models, fine-tuned to produce contextually rich sentence embeddings. These models, derived from the renowned Transformers library by ðŸ¤— Hugging Face, are excellent at understanding and comparing the semantic content of texts. In this tutorial, we will leverage `sentence-transformers` to transform sentences into embeddings and identify paraphrases effectively.\n",
    "\n",
    "### MLflow: Simplifying Model Management and Deployment\n",
    "\n",
    "MLflow plays a pivotal role in our paraphrase mining project by providing:\n",
    "\n",
    "- **Efficient Experiment Tracking**: Log and track your NLP experiments effortlessly, capturing intricate details like model parameters and sentence embeddings.\n",
    "- **Custom `PythonModel` Implementation**: We will explore a custom `PythonModel` implementation within MLflow, tailored for paraphrase mining, demonstrating the platform's flexibility.\n",
    "- **Streamlined Lifecycle Management**: Utilize MLflow's versioning and configuration control to manage the iterative nature of NLP model development.\n",
    "- **Consistent Deployment and Reproducibility**: With MLflow, ensure that your models are not only ready for deployment but also maintain consistency and reliability across different environments.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "Throughout this tutorial, you will:\n",
    "\n",
    "- Utilize the `sentence-transformers` library to perform advanced paraphrase mining.\n",
    "- Create and customize a `PythonModel` in MLflow for paraphrase mining.\n",
    "- Manage, log, and track models and configurations within the MLflow ecosystem.\n",
    "- Deploy your paraphrase mining model for practical applications, taking full advantage of MLflow's deployment capabilities.\n",
    "\n",
    "By the end of this tutorial, you will have developed a deep understanding of paraphrase mining using Sentence Transformers and gained valuable insights into leveraging MLflow for managing and deploying NLP models. Prepare to embark on an enriching journey through the realms of NLP, enhancing your skills in both language understanding and model management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Paraphrase Mining Model\n",
    "\n",
    "In this first code cell, we establish the foundation for our **Paraphrase Mining Model** using Sentence Transformers and MLflow. This model exemplifies the integration of sophisticated NLP techniques with the flexibility of MLflow for model management and deployment.\n",
    "\n",
    "### Overview of the Model Structure\n",
    "\n",
    "Our `ParaphraseMiningModel` class is a custom Python model that integrates advanced NLP capabilities with MLflow's deployment and tracking features.\n",
    "\n",
    "#### Loading Model and Corpus: `load_context` Method\n",
    "\n",
    "- The method loads a pre-trained Sentence Transformer model, optimized for semantic embeddings.\n",
    "- It also reads a corpus of text from a file, providing data for paraphrase identification.\n",
    "\n",
    "#### Paraphrase Mining Logic: `predict` Method\n",
    "\n",
    "- This method includes input validation, checking and extracting a query sentence from various input formats.\n",
    "- It allows users to customize the behavior of the model using parameters like `similarity_threshold`.\n",
    "- The core functionality of the method is to identify semantically similar sentences to the input query within the corpus.\n",
    "\n",
    "#### Sorting and Filtering Matches: `_sort_and_filter_matches` Helper Method\n",
    "\n",
    "- This helper method organizes the paraphrases based on their similarity scores.\n",
    "- It ensures that only unique and relevant paraphrases above the set similarity threshold are returned, filtering out duplicates.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- Utilizes advanced NLP techniques by leveraging Sentence Transformers.\n",
    "- Demonstrates the seamless integration of custom logic in the `predict` method.\n",
    "- Offers flexibility to end users to modify match criteria, enhancing usability.\n",
    "- Ensures efficient processing by pre-encoding the corpus in the `load_context`.\n",
    "- Includes robust error handling and validations for increased reliability.\n",
    "\n",
    "### Practical Implications\n",
    "\n",
    "This model provides a versatile framework for paraphrase mining, adaptable to various domains where textual similarity is key. It highlights the power of custom `PythonModel` in MLflow, tailored for the nuanced requirements of NLP applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class ParaphraseMiningModel(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load the model context for inference, including the customer feedback corpus.\"\"\"\n",
    "        try:\n",
    "            # Load the pre-trained sentence transformer model\n",
    "            self.model = SentenceTransformer.load(context.artifacts[\"model_path\"])\n",
    "            \n",
    "            # Load the customer feedback corpus from the specified file\n",
    "            corpus_file = context.artifacts[\"corpus_file\"]\n",
    "            with open(corpus_file, 'r') as file:\n",
    "                self.corpus = file.read().splitlines()\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading model and corpus: {e}\")\n",
    "\n",
    "    def _sort_and_filter_matches(self, query: str, paraphrase_pairs: List[tuple], similarity_threshold: float):\n",
    "        \"\"\"Sort and filter the matches by similarity score.\"\"\"\n",
    "        \n",
    "        # Convert to list of tuples and sort by score\n",
    "        sorted_matches = sorted(paraphrase_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Filter and collect paraphrases for the query, avoiding duplicates\n",
    "        query_paraphrases = {}\n",
    "        for score, i, j in sorted_matches:\n",
    "            if score < similarity_threshold:\n",
    "                continue\n",
    "            \n",
    "            paraphrase = self.corpus[j] if self.corpus[i] == query else self.corpus[i]\n",
    "            if paraphrase == query:\n",
    "                continue\n",
    "            \n",
    "            if paraphrase not in query_paraphrases or score > query_paraphrases[paraphrase]:\n",
    "                query_paraphrases[paraphrase] = score\n",
    "\n",
    "        return sorted(query_paraphrases.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        \"\"\"Predict method to perform paraphrase mining over the corpus.\"\"\"\n",
    "        \n",
    "        # Validate and extract the query input\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            if model_input.shape[1] != 1:\n",
    "                raise ValueError(\"DataFrame input must have exactly one column.\")\n",
    "            query = model_input.iloc[0, 0]\n",
    "        elif isinstance(model_input, dict):\n",
    "            query = model_input.get(\"query\")\n",
    "            if query is None:\n",
    "                raise ValueError(\"The input dictionary must have a key named 'query'.\")\n",
    "        else:\n",
    "            raise TypeError(f\"Unexpected type for model_input: {type(model_input)}. Must be either a Dict or a DataFrame.\")\n",
    "\n",
    "        # Determine the minimum similarity threshold\n",
    "        similarity_threshold = params.get(\"similarity_threshold\", 0.5) if params else 0.5\n",
    "\n",
    "        # Add the query to the corpus for paraphrase mining\n",
    "        extended_corpus = self.corpus + [query]\n",
    "\n",
    "        # Perform paraphrase mining\n",
    "        paraphrase_pairs = util.paraphrase_mining(self.model, extended_corpus, show_progress_bar=False)\n",
    "\n",
    "        # Convert to list of tuples and sort by score\n",
    "        sorted_paraphrases = self._sort_and_filter_matches(query, paraphrase_pairs, similarity_threshold)\n",
    "\n",
    "        # Warning if no paraphrases found\n",
    "        if not sorted_paraphrases:\n",
    "            warnings.warn(\n",
    "                \"No paraphrases found above the similarity threshold.\",\n",
    "                UserWarning\n",
    "            )\n",
    "\n",
    "        return {sentence[0]: str(sentence[1]) for sentence in sorted_paraphrases}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Corpus for Paraphrase Mining\n",
    "\n",
    "In this section of our tutorial, we focus on creating and preparing the corpus, which is a crucial component for effective paraphrase mining.\n",
    "\n",
    "### Corpus Creation\n",
    "\n",
    "- We define a `corpus` as a collection of sentences covering a wide range of topics. This diversity is essential to demonstrate the model's ability to identify paraphrases across various subjects.\n",
    "- The topics include everything from space exploration and AI technologies to hobbies like gardening and yoga. Such a varied corpus ensures that our paraphrase mining model can handle a wide array of input queries.\n",
    "\n",
    "### Writing the Corpus to a File\n",
    "\n",
    "- The corpus is written to a file named `feedback.txt`. This step simulates a real-world scenario where large datasets are often stored in files or databases.\n",
    "- Writing the corpus to a file also prepares it for loading into the Paraphrase Mining Model. This process will allow the model to access and process the corpus efficiently during the paraphrase mining task.\n",
    "\n",
    "### Significance of the Corpus\n",
    "\n",
    "- The corpus forms the backbone of our paraphrase mining application. It acts as the dataset against which the model will compare input queries to find semantically similar sentences.\n",
    "- By covering a broad spectrum of topics, we ensure that the model is versatile and robust, capable of handling a variety of real-world use cases.\n",
    "\n",
    "With the corpus prepared and saved, we are now set to move forward with loading it into our Paraphrase Mining Model and demonstrating the power of NLP in finding related sentences across different topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Exploring ancient cities in Europe offers a glimpse into history.\",\n",
    "    \"Modern AI technologies are revolutionizing industries.\",\n",
    "    \"Healthy eating contributes significantly to overall well-being.\",\n",
    "    \"Advancements in renewable energy are combating climate change.\",\n",
    "    \"Learning a new language opens doors to different cultures.\",\n",
    "    \"Gardening is a relaxing hobby that connects you with nature.\",\n",
    "    \"Blockchain technology could redefine digital transactions.\",\n",
    "    \"Homemade Italian pasta is a delight to cook and eat.\",\n",
    "    \"Practicing yoga daily improves both physical and mental health.\",\n",
    "    \"The art of photography captures moments in time.\",\n",
    "    \"Baking bread at home has become a popular quarantine activity.\",\n",
    "    \"Virtual reality is creating new experiences in gaming.\",\n",
    "    \"Sustainable travel is becoming a priority for eco-conscious tourists.\",\n",
    "    \"Reading books is a great way to unwind and learn.\",\n",
    "    \"Jazz music provides a rich tapestry of sound and rhythm.\",\n",
    "    \"Marathon training requires discipline and perseverance.\",\n",
    "    \"Studying the stars helps us understand our universe.\",\n",
    "    \"The rise of electric cars is an important environmental development.\",\n",
    "    \"Documentary films offer deep insights into real-world issues.\",\n",
    "    \"Crafting DIY projects can be both fun and rewarding.\",\n",
    "    \"The history of ancient civilizations is fascinating to explore.\",\n",
    "    \"Exploring the depths of the ocean reveals a world of marine wonders.\",\n",
    "    \"Learning to play a musical instrument can be a rewarding challenge.\",\n",
    "    \"Artificial intelligence is shaping the future of personalized medicine.\",\n",
    "    \"Cycling is not only a great workout but also eco-friendly transportation.\",\n",
    "    \"Home automation with IoT devices is enhancing living experiences.\",\n",
    "    \"Understanding quantum computing requires a grasp of complex physics.\",\n",
    "    \"A well-brewed cup of coffee is the perfect start to the day.\",\n",
    "    \"Urban farming is gaining popularity as a sustainable food source.\",\n",
    "    \"Meditation and mindfulness can lead to a more balanced life.\",\n",
    "    \"The popularity of podcasts has revolutionized audio storytelling.\",\n",
    "    \"Space exploration continues to push the boundaries of human knowledge.\",\n",
    "    \"Wildlife conservation is essential for maintaining biodiversity.\",\n",
    "    \"The fusion of technology and fashion is creating new trends.\",\n",
    "    \"E-learning platforms have transformed the educational landscape.\",\n",
    "    \"Dark chocolate has surprising health benefits when enjoyed in moderation.\",\n",
    "    \"Robotics in manufacturing is leading to more efficient production.\",\n",
    "    \"Creating a personal budget is key to financial well-being.\",\n",
    "    \"Hiking in nature is a great way to connect with the outdoors.\",\n",
    "    \"3D printing is innovating the way we create and manufacture objects.\",\n",
    "    \"Sommeliers can identify a wine's characteristics with just a taste.\",\n",
    "    \"Mind-bending puzzles and riddles are great for cognitive exercise.\",\n",
    "    \"Social media has a profound impact on communication and culture.\",\n",
    "    \"Urban sketching captures the essence of city life on paper.\",\n",
    "    \"The ethics of AI is a growing field in tech philosophy.\",\n",
    "    \"Homemade skincare remedies are becoming more popular.\",\n",
    "    \"Virtual travel experiences can provide a sense of adventure at home.\",\n",
    "    \"Ancient mythology still influences modern storytelling and literature.\",\n",
    "    \"Building model kits is a hobby that requires patience and precision.\",\n",
    "    \"The study of languages opens windows into different worldviews.\",\n",
    "    \"Professional esports has become a major global phenomenon.\",\n",
    "    \"The mysteries of the universe are unveiled through space missions.\",\n",
    "    \"Astronauts' experiences in space stations offer unique insights into life beyond Earth.\",\n",
    "    \"Telescopic observations bring distant galaxies within our view.\",\n",
    "    \"The study of celestial bodies helps us understand the cosmos.\",\n",
    "    \"Space travel advancements could lead to interplanetary exploration.\",\n",
    "    \"Observing celestial events provides valuable data for astronomers.\",\n",
    "    \"The development of powerful rockets is key to deep space exploration.\",\n",
    "    \"Mars rover missions are crucial in searching for extraterrestrial life.\",\n",
    "    \"Satellites play a vital role in our understanding of Earth's atmosphere.\",\n",
    "    \"Astrophysics is central to unraveling the secrets of space.\",\n",
    "    \"Zero gravity environments in space pose unique challenges and opportunities.\",\n",
    "    \"Space tourism might soon become a reality for many.\",\n",
    "    \"Lunar missions have contributed significantly to our knowledge of the moon.\",\n",
    "    \"The International Space Station is a hub for groundbreaking space research.\",\n",
    "    \"Studying comets and asteroids reveals information about the early solar system.\",\n",
    "    \"Advancements in space technology have implications for many scientific fields.\",\n",
    "    \"The possibility of life on other planets continues to intrigue scientists.\",\n",
    "    \"Black holes are among the most mysterious phenomena in space.\",\n",
    "    \"The history of space exploration is filled with remarkable achievements.\",\n",
    "    \"Future space missions could unlock the mysteries of dark matter.\"\n",
    "]\n",
    "\n",
    "# Write out the corpus to a file\n",
    "corpus_file = '/tmp/feedback.txt'\n",
    "with open(corpus_file, 'w') as file:\n",
    "    for sentence in corpus:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Paraphrase Mining Model\n",
    "\n",
    "This part of the tutorial involves setting up the Sentence Transformer model and preparing it for integration with MLflow. This step is crucial for leveraging the model's capabilities in our paraphrase mining application.\n",
    "\n",
    "### Loading the Sentence Transformer Model\n",
    "\n",
    "- We start by loading a pre-trained Sentence Transformer model, specifically `all-MiniLM-L6-v2`. This model is known for its efficiency in generating high-quality sentence embeddings and is well-suited for paraphrase mining tasks.\n",
    "\n",
    "### Preparing the Input Example\n",
    "\n",
    "- An input example is created using a DataFrame. This example represents a typical query that our model is expected to process. It helps in understanding the structure and format of the input data the model will receive.\n",
    "\n",
    "### Saving the Model\n",
    "\n",
    "- The loaded Sentence Transformer model is then saved to a directory (`/tmp/paraphrase_search_model`). This step is essential for creating a portable version of the model that can be loaded by MLflow for deployment and further use.\n",
    "\n",
    "### Defining Artifacts and Corpus Path\n",
    "\n",
    "- The paths to the saved model and the corpus file are defined as artifacts. Artifacts in MLflow are used to log additional files, like data or models, which are needed to understand or reproduce the work.\n",
    "\n",
    "### Generating Test Output for Signature\n",
    "\n",
    "- A sample output for paraphrase mining is generated. This output is a list of tuples, each containing a paraphrase and its corresponding similarity score. This sample helps in defining the expected format of the model's output.\n",
    "\n",
    "### Creating the Model Signature\n",
    "\n",
    "- A model signature is created using MLflow's `infer_signature` function. The signature captures the expected input and output formats of the model, ensuring compatibility and clarity in how the model is to be used.\n",
    "- Additionally, the parameter `similarity_threshold` is included in the signature, which is absolutely required if we want to expose this parameter for override during inference. If this is not declared when assigning the signature, the parameter will be ignored during inference.\n",
    "\n",
    "With these steps, we have successfully set up and saved our Sentence Transformer model, along with defining the expected input and output structures. This setup lays the groundwork for integrating the model with MLflow, ensuring that it is ready for deployment and use in our paraphrase mining application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['query': string]\n",
       "outputs: \n",
       "  ['This product is satisfactory and functions as expected.': string]\n",
       "params: \n",
       "  ['similarity_threshold': double (default: 0.5)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create an input example DataFrame\n",
    "input_example = pd.DataFrame({\"query\": [\"This product works well. I'm satisfied.\"]})\n",
    "\n",
    "# Save the model in the /tmp directory\n",
    "model_directory = \"/tmp/paraphrase_search_model\"\n",
    "model.save(model_directory)\n",
    "\n",
    "# Define the path for the corpus file\n",
    "corpus_file = \"/tmp/feedback.txt\"\n",
    "\n",
    "# Define the artifacts (paths to the model and corpus file)\n",
    "artifacts = {\n",
    "    \"model_path\": model_directory,\n",
    "    \"corpus_file\": corpus_file\n",
    "}\n",
    "\n",
    "# Generate test output for signature\n",
    "# Sample output for paraphrase mining could be a list of tuples (paraphrase, score)\n",
    "test_output = [{\"This product is satisfactory and functions as expected.\": \"0.8\"}]\n",
    "\n",
    "# Define the signature associated with the model\n",
    "# The signature includes the structure of the input and the expected output\n",
    "signature = infer_signature(model_input=input_example, model_output=test_output, params={\"similarity_threshold\": 0.5})\n",
    "\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the tracking server and creating an experiment\n",
    "\n",
    "In order to view the results in our tracking server (for the purposes of this tutorial, weâ€™ve started a local tracking server at this url)\n",
    "\n",
    "We can start an instance of the MLflow server locally by running the following from a terminal to start the tracking server:\n",
    "\n",
    "``` bash\n",
    "mlflow server --host 127.0.0.1 --port 8080\n",
    "```\n",
    "\n",
    "With the server started, the following code will ensure that all experiments, runs, models, parameters, and metrics that we log are being tracked within that server instance (which also provides us with the MLflow UI when navigating to that url address in a browser).\n",
    "\n",
    "After setting the tracking url, we create a new MLflow Experiment to store the run weâ€™re about to create in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/413386080563320984', creation_time=1700272457800, experiment_id='413386080563320984', last_update_time=1700272457800, lifecycle_stage='active', name='Semantic Similarity', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "mlflow.set_experiment(\"Semantic Similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging the Paraphrase Mining Model with MLflow\n",
    "\n",
    "In this crucial step, we demonstrate the process of logging our custom Paraphrase Mining Model with MLflow, a pivotal phase for model management and deployment.\n",
    "\n",
    "### Initiating an MLflow Run\n",
    "\n",
    "- We begin by starting an MLflow run, which serves as a record of our operations related to the model. This run encapsulates all actions of logging, tracking, and managing the model within the MLflow framework.\n",
    "\n",
    "### Logging the Model in MLflow\n",
    "\n",
    "- The model is logged using MLflow's function designed for registering Python models. This step is central to integrating our model into the MLflow ecosystem for effective management.\n",
    "- We assign a unique name to our model, making it easily identifiable within MLflow.\n",
    "- The custom Paraphrase Mining Model, instantiated from our defined class, is specified here for logging.\n",
    "- An input example is provided to illustrate the expected format of data the model will process, enhancing documentation and understanding of the model's usage.\n",
    "- A model signature is included, describing the model's input and output schema. This signature is crucial for ensuring that the model is used correctly and consistently in various environments.\n",
    "- Artifacts, including the paths to the model and corpus file, are specified. These artifacts are essential components required for the model's operation.\n",
    "- Python package dependencies are listed, ensuring that all necessary libraries are available in the environment where the model is deployed.\n",
    "\n",
    "### Outcomes and Benefits of Model Logging\n",
    "\n",
    "- By logging the model in MLflow, we effectively register it for management and deployment. The model becomes a part of the MLflow ecosystem, accessible for various operations.\n",
    "- This step enhances the model's trackability, facilitating effective version control and ensuring reproducibility across different deployment environments.\n",
    "\n",
    "This process of logging the model in MLflow is a testament to the platform's capabilities in handling complex models, such as our Paraphrase Mining Model. It showcases MLflow's role in simplifying model management and deployment, aligning with best practices in machine learning workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3b9c45ee85432dbeca2039c3af40da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/20 21:11:58 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560f2a5036894e76a764cb6683a0428e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamin.wilson/miniconda3/envs/mlflow-dev-env/lib/python3.8/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        \"paraphrase_model\",\n",
    "        python_model=ParaphraseMiningModel(),\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        artifacts=artifacts,\n",
    "        pip_requirements=[\"sentence_transformers\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Paraphrase Mining Prediction\n",
    "\n",
    "In this section of the tutorial, we demonstrate the practical application of our Paraphrase Mining Model. We load the model using MLflow and perform a paraphrase mining prediction, illustrating how the model operates in a real-world scenario.\n",
    "\n",
    "### Loading the Model for Inference\n",
    "\n",
    "- The model is loaded using MLflow's `load_model` function. This step is crucial as it retrieves the model from the MLflow registry, making it ready for inference.\n",
    "- We use the model's URI, which is a unique identifier within MLflow, to locate and load the specific model we have trained and logged.\n",
    "\n",
    "### Executing a Paraphrase Mining Prediction\n",
    "\n",
    "- A prediction is made using the `predict` method of the loaded model. This method is where the paraphrase mining logic, as defined in our model class, is executed.\n",
    "- We pass a query, \"Space exploration is fascinating.\", to the model. This query represents a typical sentence that we aim to find paraphrases for in our corpus.\n",
    "- Additionally, we set a parameter `similarity_threshold` to 0.65, specifying the minimum similarity score for considering sentences as paraphrases. This threshold is adjustable, allowing users to control the strictness of match criteria.\n",
    "\n",
    "### Interpreting the Model Output\n",
    "\n",
    "- The output is displayed in the notebook, showing a list of sentences from the corpus that are semantically similar to the input query, along with their similarity scores.\n",
    "- Sentences like \"Studying the stars helps us understand our universe.\" and \"The history of space exploration is filled with remarkable achievements.\" have high similarity scores, indicating strong semantic relatedness to the query.\n",
    "- This result demonstrates the model's ability to identify paraphrases - sentences that are different in wording but similar in meaning.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The successful execution of this prediction showcases the effectiveness of our Paraphrase Mining Model in identifying semantically similar sentences within a given corpus. It highlights the model's potential in various applications, such as content recommendation, information retrieval, and enhancing understanding of user queries in conversational AI systems. The output also reflects the model's nuanced understanding of language, crucial for accurate paraphrase mining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2edc485566b44179b00df029ff8eb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/20 21:11:59 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Studying the stars helps us understand our universe.': '0.8207424879074097',\n",
       " 'The history of space exploration is filled with remarkable achievements.': '0.7770636677742004',\n",
       " 'Exploring ancient cities in Europe offers a glimpse into history.': '0.7461957335472107',\n",
       " 'Space travel advancements could lead to interplanetary exploration.': '0.7090306282043457',\n",
       " 'Space exploration continues to push the boundaries of human knowledge.': '0.6893945932388306',\n",
       " 'The mysteries of the universe are unveiled through space missions.': '0.6830739974975586',\n",
       " 'The study of celestial bodies helps us understand the cosmos.': '0.671358048915863'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dynamic = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "loaded_dynamic.predict({\"query\": \"Space exploration is fascinating.\"}, params={\"similarity_threshold\": 0.65})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Insights and Potential Enhancements\n",
    "\n",
    "As we wrap up this tutorial, let's reflect on our journey through the implementation of a Paraphrase Mining Model using Sentence Transformers and MLflow. We've successfully built and deployed a model capable of identifying semantically similar sentences, showcasing the flexibility and power of MLflow's `PythonModel` implementation.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- We learned how to integrate advanced NLP techniques, specifically paraphrase mining, with MLflow. This integration not only enhances model management but also simplifies deployment and scalability.\n",
    "- The flexibility of the `PythonModel` implementation in MLflow was a central theme. We saw firsthand how it allows for the incorporation of custom logic into the model's predict function, catering to specific NLP tasks like paraphrase mining.\n",
    "- Through our custom model, we explored the dynamics of sentence embeddings, semantic similarity, and the nuances of language understanding. This understanding is crucial in a wide range of applications, from content recommendation to conversational AI.\n",
    "\n",
    "### Ideas for Enhancing the Paraphrase Mining Model\n",
    "\n",
    "While our model serves as a robust starting point, there are several enhancements that could be made within the `predict` function to make it more powerful and feature-rich:\n",
    "\n",
    "1. **Contextual Filters**: Introduce filters based on contextual clues or specific keywords to refine the search results further. This feature would allow users to narrow down paraphrases to those most relevant to their particular context or subject matter.\n",
    "\n",
    "2. **Sentiment Analysis Integration**: Incorporate sentiment analysis to group paraphrases by their emotional tone. This would be especially useful in applications like customer feedback analysis, where understanding sentiment is as important as content.\n",
    "\n",
    "3. **Multi-Lingual Support**: Expand the model to support paraphrase mining in multiple languages. This enhancement would significantly broaden the model's applicability in global or multi-lingual contexts.\n",
    "\n",
    "### Scalability with Vector Databases\n",
    "\n",
    "- Moving beyond a static text file as a corpus, a more scalable and real-world approach would involve connecting the model to an external vector database or in-memory store. \n",
    "- Pre-calculated embeddings could be stored and updated in such databases, accommodating real-time content generation without requiring model redeployment. This approach would dramatically improve the modelâ€™s scalability and responsiveness in real-world applications.\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "The journey through building and deploying the Paraphrase Mining Model has been both enlightening and practical. We've seen how MLflow's `PythonModel` offers a flexible canvas for crafting custom NLP solutions, and how sentence transformers can be leveraged to delve deep into the semantics of language.\n",
    "\n",
    "This tutorial is just the beginning. Thereâ€™s a vast potential for further exploration and innovation in paraphrase mining and NLP as a whole. We encourage you to build upon this foundation, experiment with enhancements, and continue pushing the boundaries of what's possible with MLflow and advanced NLP techniques.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
