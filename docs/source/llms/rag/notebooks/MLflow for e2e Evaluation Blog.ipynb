{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42084110-295b-493a-9b3e-5d8d29ff78b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# LLM RAG Evaluation with MLflow Example Notebook\n",
    "\n",
    "In this notebook, we will demonstrate how to evaluate various a RAG system with MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d87628a6-ef1d-4586-8080-13f538904076",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: openai in /databricks/python3/lib/python3.10/site-packages (0.27.8)\nRequirement already satisfied: aiohttp in /databricks/python3/lib/python3.10/site-packages (from openai) (3.8.5)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from openai) (4.64.1)\nRequirement already satisfied: requests>=2.20 in /databricks/python3/lib/python3.10/site-packages (from openai) (2.28.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-store 0.15.2 requires pyspark<4,>=3.1.2, which is not installed.\ntensorflow-cpu 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting langchain==0.0.344\n  Downloading langchain-0.0.344-py3-none-any.whl (1.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 8.9 MB/s eta 0:00:00\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (1.10.6)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (3.8.5)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (1.23.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (4.0.3)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (2.28.1)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from langchain==0.0.344) (8.2.3)\nRequirement already satisfied: anyio<4.0 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (3.5.0)\nCollecting langchain-core<0.1,>=0.0.8\n  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.5/181.5 kB 13.4 MB/s eta 0:00:00\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (6.0)\nCollecting jsonpatch<2.0,>=1.33\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nCollecting langsmith<0.1.0,>=0.0.63\n  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.2/48.2 kB 8.2 MB/s eta 0:00:00\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (0.5.14)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.10/site-packages (from langchain==0.0.344) (1.4.39)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.344) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.344) (22.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.344) (2.0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.344) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.344) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.344) (1.9.2)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.344) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.344) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.344) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.344) (0.9.0)\nCollecting jsonpointer>=1.9\n  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\nCollecting packaging<24.0,>=23.2\n  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 10.4 MB/s eta 0:00:00\nRequirement already satisfied: typing-extensions>=4.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.344) (4.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.344) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.344) (1.26.14)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.344) (2.0.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.344) (0.4.3)\nInstalling collected packages: packaging, jsonpointer, langsmith, jsonpatch, langchain-core, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 22.0\n    Not uninstalling packaging at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07\n    Can't uninstall 'packaging'. No files were found to uninstall.\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.0.41\n    Not uninstalling langsmith at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07\n    Can't uninstall 'langsmith'. No files were found to uninstall.\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.0.267\n    Not uninstalling langchain at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07\n    Can't uninstall 'langchain'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\ndatabricks-feature-store 0.15.2 requires pyspark<4,>=3.1.2, which is not installed.\ntensorflow-cpu 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\nSuccessfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.344 langchain-core-0.0.12 langsmith-0.0.69 packaging-23.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: tiktoken in /databricks/python3/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: requests>=2.26.0 in /databricks/python3/lib/python3.10/site-packages (from tiktoken) (2.28.1)\nRequirement already satisfied: regex>=2022.1.18 in /databricks/python3/lib/python3.10/site-packages (from tiktoken) (2022.7.9)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: mlflow[genai] in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (2.9.1)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (3.7.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (3.1.2)\nRequirement already satisfied: databricks-cli<1,>=0.8.7 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (0.17.7)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from mlflow[genai]) (6.11.0)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from mlflow[genai]) (1.13.0)\nRequirement already satisfied: pytz<2024 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (2022.7)\nRequirement already satisfied: pyarrow<15,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (8.0.0)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (2.28.1)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (0.4)\nRequirement already satisfied: querystring-parser<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from mlflow[genai]) (1.2.4)\nRequirement already satisfied: gunicorn<22 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (20.1.0)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (1.4.39)\nRequirement already satisfied: packaging<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from mlflow[genai]) (23.2)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (8.0.4)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (1.10.0)\nRequirement already satisfied: Flask<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (2.2.5)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (0.4.2)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (1.1.1)\nRequirement already satisfied: docker<7,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from mlflow[genai]) (6.1.3)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (6.0)\nRequirement already satisfied: gitpython<4,>=2.1.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (3.1.27)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (1.5.3)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (1.23.5)\nRequirement already satisfied: markdown<4,>=3.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (3.4.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (4.24.0)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (2.0.0)\nRequirement already satisfied: uvicorn[standard]<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (0.23.2)\nRequirement already satisfied: aiohttp<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (3.8.5)\nRequirement already satisfied: pydantic<3,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (1.10.6)\nRequirement already satisfied: watchfiles<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (0.20.0)\nCollecting boto3<2,>=1.28.56\n  Downloading boto3-1.33.10-py3-none-any.whl (139 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 3.8 MB/s eta 0:00:00\nRequirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.10/site-packages (from mlflow[genai]) (0.98.0)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4->mlflow[genai]) (22.1.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4->mlflow[genai]) (1.3.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4->mlflow[genai]) (1.9.2)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4->mlflow[genai]) (4.0.3)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4->mlflow[genai]) (2.0.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4->mlflow[genai]) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4->mlflow[genai]) (6.0.4)\nRequirement already satisfied: typing-extensions>=4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow[genai]) (4.8.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow[genai]) (1.2.0)\nCollecting botocore<1.34.0,>=1.33.10\n  Downloading botocore-1.33.10-py3-none-any.whl (11.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 30.7 MB/s eta 0:00:00\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.10/site-packages (from boto3<2,>=1.28.56->mlflow[genai]) (0.10.0)\nCollecting s3transfer<0.9.0,>=0.8.2\n  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.0/82.0 kB 18.7 MB/s eta 0:00:00\nRequirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow[genai]) (1.16.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow[genai]) (3.2.2)\nRequirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow[genai]) (2.3.0)\nRequirement already satisfied: tabulate>=0.7.7 in /databricks/python3/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow[genai]) (0.8.10)\nRequirement already satisfied: urllib3<2.0.0,>=1.26.7 in /databricks/python3/lib/python3.10/site-packages (from databricks-cli<1,>=0.8.7->mlflow[genai]) (1.26.14)\nRequirement already satisfied: websocket-client>=0.32.0 in /databricks/python3/lib/python3.10/site-packages (from docker<7,>=4.0.0->mlflow[genai]) (0.58.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /databricks/python3/lib/python3.10/site-packages (from fastapi<1->mlflow[genai]) (0.27.0)\nRequirement already satisfied: Werkzeug>=2.2.2 in /databricks/python3/lib/python3.10/site-packages (from Flask<4->mlflow[genai]) (2.2.2)\nRequirement already satisfied: itsdangerous>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Flask<4->mlflow[genai]) (2.0.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitpython<4,>=2.1.0->mlflow[genai]) (4.0.10)\nRequirement already satisfied: setuptools>=3.0 in /databricks/python3/lib/python3.10/site-packages (from gunicorn<22->mlflow[genai]) (65.6.3)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow[genai]) (3.11.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow[genai]) (2.1.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow[genai]) (1.4.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow[genai]) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow[genai]) (9.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow[genai]) (3.0.9)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow[genai]) (1.0.5)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow[genai]) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow[genai]) (4.25.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow[genai]) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow[genai]) (2022.12.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow[genai]) (2.2.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow[genai]) (1.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow[genai]) (2.0.1)\nRequirement already satisfied: h11>=0.8 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]<1->mlflow[genai]) (0.14.0)\nRequirement already satisfied: python-dotenv>=0.13 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]<1->mlflow[genai]) (1.0.0)\nRequirement already satisfied: httptools>=0.5.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]<1->mlflow[genai]) (0.6.0)\nRequirement already satisfied: websockets>=10.4 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]<1->mlflow[genai]) (11.0.3)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /databricks/python3/lib/python3.10/site-packages (from uvicorn[standard]<1->mlflow[genai]) (0.17.0)\nRequirement already satisfied: anyio>=3.0.0 in /databricks/python3/lib/python3.10/site-packages (from watchfiles<1->mlflow[genai]) (3.5.0)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio>=3.0.0->watchfiles<1->mlflow[genai]) (1.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow[genai]) (5.0.0)\nInstalling collected packages: botocore, s3transfer, boto3\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.27.96\n    Not uninstalling botocore at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07\n    Can't uninstall 'botocore'. No files were found to uninstall.\n  Attempting uninstall: s3transfer\n    Found existing installation: s3transfer 0.6.2\n    Not uninstalling s3transfer at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07\n    Can't uninstall 's3transfer'. No files were found to uninstall.\n  Attempting uninstall: boto3\n    Found existing installation: boto3 1.24.28\n    Not uninstalling boto3 at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07\n    Can't uninstall 'boto3'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-store 0.15.2 requires pyspark<4,>=3.1.2, which is not installed.\nSuccessfully installed boto3-1.33.10 botocore-1.33.10 s3transfer-0.8.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: databricks-sdk in /databricks/python3/lib/python3.10/site-packages (0.1.6)\nCollecting databricks-sdk\n  Downloading databricks_sdk-0.14.0-py3-none-any.whl (312 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 312.7/312.7 kB 4.5 MB/s eta 0:00:00\nRequirement already satisfied: requests<3,>=2.28.1 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk) (2.28.1)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.10/site-packages (from databricks-sdk) (2.21.0)\nRequirement already satisfied: urllib3<2.0 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk) (1.26.14)\nRequirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth~=2.0->databricks-sdk) (1.16.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk) (5.3.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk) (4.9)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.28.1->databricks-sdk) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.28.1->databricks-sdk) (2.0.4)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk) (0.4.8)\nInstalling collected packages: databricks-sdk\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.1.6\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\nSuccessfully installed databricks-sdk-0.14.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow>=2.8.1\n",
    "%pip install openai\n",
    "%pip install chromadb>=0.4.15\n",
    "%pip install langchain\n",
    "%pip install tiktoken\n",
    "%pip install 'mlflow[genai]'\n",
    "%pip install databricks-sdk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe9a743-feca-4de0-80f9-f64267578482",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734e7c44-e784-47ac-8adf-123198e96462",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: langchain in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (0.0.344)\nCollecting langchain\n  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 9.1 MB/s eta 0:00:00\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /databricks/python3/lib/python3.10/site-packages (from langchain) (3.8.5)\nRequirement already satisfied: langchain-core<0.1,>=0.0.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from langchain) (0.0.12)\nRequirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from langchain) (2.28.1)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.10/site-packages (from langchain) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.4.39)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.23.5)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from langchain) (1.33)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.63 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from langchain) (0.0.69)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /databricks/python3/lib/python3.10/site-packages (from langchain) (0.5.14)\nRequirement already satisfied: pydantic<3,>=1 in /databricks/python3/lib/python3.10/site-packages (from langchain) (1.10.6)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /databricks/python3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /databricks/python3/lib/python3.10/site-packages (from langchain-core<0.1,>=0.0.12->langchain) (3.5.0)\nRequirement already satisfied: packaging<24.0,>=23.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\nRequirement already satisfied: typing-extensions>=4.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\nRequirement already satisfied: greenlet!=0.4.17 in /databricks/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\nInstalling collected packages: langchain\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.0.344\n    Uninstalling langchain-0.0.344:\n      Successfully uninstalled langchain-0.0.344\nSuccessfully installed langchain-0.0.348\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "695c9abf-466c-4b34-a901-852a62d9d10f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import chromadb\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f8dfd16-c064-4a7e-9e3e-226894275e95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check mlflow version\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "899aa208-48aa-404e-b823-f47e410d9490",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0.4.18'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check chroma version\n",
    "chromadb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64d5d5eb-8ee7-496a-be8e-fd658c4a4f44",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Set-up Databricks Workspace Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24035a7d-2292-4d3b-9900-4e8ac638e252",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b27372e3-7ec0-42f3-b57a-6b7a9d750a82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "KEY_NAME = \"azureopenai_key\"\n",
    "SCOPE_NAME = \"abescope\"\n",
    "OPENAI_API_KEY = \"<your-openai-key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cacc0229-3b48-492a-91ba-712e5eb300d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "w.secrets.put_secret(scope=SCOPE_NAME, key=KEY_NAME, string_value=OPENAI_API_KEY)\n",
    "w.secrets.list_secrets(scope=SCOPE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf10085f-c63d-4942-b02e-029a205064ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "# w.secrets.delete_secret(scope=SCOPE_NAME, key=KEY_NAME)\n",
    "# w.secrets.delete_scope(scope=SCOPE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19cb7955-5f15-48e9-896c-fcf36cb60782",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope=SCOPE, key=KEY)\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai-for-abe.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"\n",
    "os.environ[\"OPENAI_ENGINE\"] = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96a5c4f9-8bd7-4e07-8caa-a80133d53433",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create and Test Endpoint on MLflow for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5ecf97-c82c-4812-8b5b-05734bc2fded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'test-endpoint-abraham-omor-demo',\n",
       " 'creator': 'abe.omorogbe@databricks.com',\n",
       " 'creation_timestamp': 1701904748000,\n",
       " 'last_updated_timestamp': 1701904748000,\n",
       " 'state': {'ready': 'READY'},\n",
       " 'config': {'served_entities': [{'name': 'abe-test-gpt',\n",
       "    'type': 'EXTERNAL_MODEL',\n",
       "    'external_model': {'provider': 'openai',\n",
       "     'name': 'gpt-3.5-turbo',\n",
       "     'task': 'llm/v1/completions',\n",
       "     'openai_config': {'openai_api_key': '{{secrets/abescope/azureopenai_key}}',\n",
       "      'openai_api_type': 'azure',\n",
       "      'openai_api_base': 'https://openai-for-abe.openai.azure.com/',\n",
       "      'openai_api_version': '2023-05-15',\n",
       "      'openai_deployment_name': 'gpt-35-turbo'}},\n",
       "    'state': {'deployment': 'DEPLOYMENT_READY',\n",
       "     'deployment_state_message': ''},\n",
       "    'creator': 'abe.omorogbe@databricks.com',\n",
       "    'creation_timestamp': 1701904748000}],\n",
       "  'traffic_config': {'routes': [{'served_model_name': 'abe-test-gpt',\n",
       "     'traffic_percentage': 100}]},\n",
       "  'config_version': 1},\n",
       " 'id': '27534bf1fffd431f8cfaf1bb5131f979',\n",
       " 'permission_level': 'CAN_MANAGE',\n",
       " 'tags': [{'key': 'foo', 'value': 'bar'}],\n",
       " 'route_optimized': False,\n",
       " 'task': 'llm/v1/completions',\n",
       " 'rate_limits': [{'calls': 5, 'key': 'user', 'renewal_period': 'minute'}],\n",
       " 'endpoint_type': 'EXTERNAL_MODEL'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.deployments\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "endpoint_name = f\"test-endpoint-abraham-omor-demo\"\n",
    "client.create_endpoint(\n",
    "name=endpoint_name,\n",
    "config={\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"name\": \"abe-test-gpt\",\n",
    "                \"external_model\": {\n",
    "                    \"name\": \"gpt-3.5-turbo\",\n",
    "                    \"provider\": \"openai\",\n",
    "                    \"task\": \"llm/v1/completions\",\n",
    "                    \"openai_config\": {\n",
    "                        \"openai_api_type\": \"azure\",\n",
    "                        \"openai_api_key\": \"{{secrets/abescope/azureopenai_key}}\",\n",
    "                        \"openai_api_base\": \"https://openai-for-abe.openai.azure.com/\",\n",
    "                        \"openai_deployment_name\": \"gpt-35-turbo\",\n",
    "                        \"openai_api_version\": \"2023-05-15\",\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e99f3b3-69b3-4a0c-82bb-d39170038b6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-8SvSXLjboY3wXDk8xKK8F8KJ5iaUq', 'object': 'text_completion', 'created': 1701904749, 'model': 'gpt-35-turbo', 'choices': [{'text': ' \\n-* \\n-Pi is calculated by dividing the circumference of a circle by its diameter. \\n-This results in the value of 3.14. \\n-It is also possible to calculate pi to many more decimal places using advanced mathematics. \\n-It is an irrational number, meaning that it cannot be expressed as a finite decimal or fraction, and its digits continue infinitely without repeating. \\n\\nWhy is Pi important? Be very concise. \\n-* \\n-Pi is important in mathematics and geometry because', 'index': 0, 'finish_reason': 'length', 'logprobs': None}], 'usage': {'prompt_tokens': 9, 'completion_tokens': 100, 'total_tokens': 109}}\n"
     ]
    }
   ],
   "source": [
    "print(client.predict(\n",
    "    endpoint=\"test-endpoint-abraham-omor\",\n",
    "    inputs={\n",
    "        \"prompt\": \"How is Pi calculated? Be very concise.\",\n",
    "        \"max_tokens\": 100,\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "273d1345-95d7-435a-a7b6-a5f3dbb3f073",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create RAG POC with LangChain and log with MLflow\n",
    "\n",
    "Use Langchain and Chroma to create a RAG system that answers questions based on the MLflow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7f64bef-116d-48f0-98d7-a18f858a9b64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 1022, which is longer than the specified 1000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-08 18:45:19,609] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236c9dc7c649428e88fc908f9de7c237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb355d7d14948ee831a02e0a944207f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3ec05951d84af68d9329e2d94be307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cbf131492c404ab894024967326488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8db0ab69004488999584744574bfd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffe21b672bc4cf6a2efbe5cda17163e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672890fc06ce40ae9e05c230679e0312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bc0fc1ebe9418b8f314aa38db8d369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c5a82396ee4f0ba617414bfa37d35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce6f1176598490e94c3d27e4e787c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4e6541665d482c8f5c2d98267ae2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78cfe97caed4481821c7e81f07af5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ed6d96cf054b59ad66b19cd53d0059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134456e7737749f9af9089e90117f7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import chromadb\n",
    "import openai\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.llms import OpenAI,Databricks \n",
    "#from langchain.llms import DatabricksEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    [ \n",
    "     \"https://mlflow.org/docs/latest/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/tracking/autolog.html\", \n",
    "     \"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\",\n",
    "     \"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\" ])\n",
    "\n",
    "documents = loader.load()\n",
    "CHUNK_SIZE = 1000\n",
    "text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "llm = Databricks(\n",
    "    endpoint_name=\"test-endpoint-abraham-omor\",\n",
    "    # model_kwargs={\"temperature\": 0.1,\"top_p\"=0.1,\"max_tokens\"=500}\n",
    "    #temperature=0.0, #parameters used in AI Playground\n",
    "    #top_p=0.1,\n",
    "    #max_tokens=500,\n",
    ")\n",
    "\n",
    "\n",
    "# create the embedding function using Databricks Foundation Model APIs\n",
    "# embedding_function = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "docsearch = Chroma.from_documents(texts, embedding_function)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(fetch_k=3),\n",
    "    return_source_documents=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36b6749f-a42a-449e-9348-8bdabc3f76dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluate the Vector Database and Retrieval using `mlflow.evaluate()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6bcacabf-3f1e-4622-82ca-f9045ebf77c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create an eval dataset (Golden Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54d629aa-7920-44d9-b896-a987adc5bffb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We're can [leveraging the power of an LLM to generate synthetic data for testing](#), offering a creative and efficient alternative. To our readers and customers, we emphasize the importance of crafting a dataset that mirrors the expected inputs and outputs of your RAG application. It's a journey worth taking for the incredible insights you'll gain!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d59ea8-3586-459e-88e4-c3b774e415a9",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "EVALUATION_DATASET_PATH = \"https://raw.githubusercontent.com/mlflow/mlflow/master/examples/llms/RAG/static_evaluation_dataset.csv\"\n",
    "\n",
    "synthetic_eval_data = pd.read_csv(EVALUATION_DATASET_PATH)\n",
    "\n",
    "# Load the static evaluation dataset from disk and deserialize the source and retrieved doc ids\n",
    "synthetic_eval_data[\"source\"] = synthetic_eval_data[\"source\"].apply(ast.literal_eval)\n",
    "synthetic_eval_data[\"retrieved_doc_ids\"] = synthetic_eval_data[\"retrieved_doc_ids\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78650ad4-0ea3-41a4-9298-47b47b1e112f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>retrieved_doc_ids</th></tr></thead><tbody><tr><td>What is the purpose of the MLflow Model Registry?</td><td>List(model-registry.html)</td><td>List(model-registry.html, introduction/index.html, introduction/index.html, deep-learning/index.html)</td></tr><tr><td>What is the purpose of registering a model with the Model Registry?</td><td>List(model-registry.html)</td><td>List(model-registry.html, models.html, introduction/index.html, introduction/index.html)</td></tr><tr><td>What can you do with registered models and model versions?</td><td>List(model-registry.html)</td><td>List(model-registry.html, models.html, deployment/deploy-model-to-kubernetes/index.html, deployment/index.html)</td></tr><tr><td>How can you add, modify, update, or delete a model in the Model Registry?</td><td>List(model-registry.html)</td><td>List(model-registry.html, models.html, deployment/deploy-model-to-kubernetes/index.html, introduction/index.html)</td></tr><tr><td>How can you deploy and organize models in the Model Registry?</td><td>List(model-registry.html)</td><td>List(model-registry.html, deployment/index.html, deployment/index.html, models.html)</td></tr><tr><td>What is the purpose of the mlflow.sklearn.log_model() method?</td><td>List(model-registry.html)</td><td>List(models.html, getting-started/intro-quickstart/index.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-1/index.html)</td></tr><tr><td>What method do you use to create a new registered model?</td><td>List(model-registry.html)</td><td>List(model-registry.html, models.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-2/index.html)</td></tr><tr><td>How can you deploy and organize models in the Model Registry?</td><td>List(model-registry.html)</td><td>List(model-registry.html, deployment/index.html, deployment/index.html, models.html)</td></tr><tr><td>How can you fetch a specific model version?</td><td>List(model-registry.html)</td><td>List(models.html, model-registry.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-2/index.html)</td></tr><tr><td>How can you fetch the latest model version in a specific stage?</td><td>List(model-registry.html)</td><td>List(models.html, model-registry.html, deployment/deploy-model-to-kubernetes/index.html, llms/prompt-engineering/index.html)</td></tr><tr><td>What can you do to promote MLflow Models across environments?</td><td>List(model-registry.html)</td><td>List(deployment/index.html, deployment/index.html, models.html, getting-started/quickstart-2/index.html)</td></tr><tr><td>How can you fetch a list of registered models in the MLflow registry?</td><td>List(model-registry.html)</td><td>List(model-registry.html, models.html, getting-started/quickstart-2/index.html, tutorials-and-examples/index.html)</td></tr><tr><td>What is the name of the model and its version details?</td><td>List(model-registry.html)</td><td>List(models.html, model-registry.html, new-features/index.html, getting-started/quickstart-2/index.html)</td></tr><tr><td>What is the purpose of saving the model in pickled format?</td><td>List(model-registry.html)</td><td>List(models.html, deployment/deploy-model-to-kubernetes/index.html, model-registry.html, deployment/index.html)</td></tr><tr><td>What is an MLflow Model and what is its purpose?</td><td>List(models.html)</td><td>List(introduction/index.html, introduction/index.html, deployment/index.html, deployment/index.html)</td></tr><tr><td>What are the flavors defined in the MLmodel file for the mlflow.sklearn library?</td><td>List(models.html)</td><td>List(community-model-flavors.html, models.html, traditional-ml/creating-custom-pyfunc/index.html, deployment/deploy-model-to-kubernetes/index.html)</td></tr><tr><td>What command can be used to package and deploy models to AWS SageMaker?</td><td>List(models.html)</td><td>List(deployment/index.html, deployment/index.html, deployment/deploy-model-to-kubernetes/index.html, models.html)</td></tr><tr><td>What is the default channel logged for models using MLflow v1.18 and above?</td><td>List(models.html)</td><td>List(models.html, tracking.html, new-features/index.html, python_api/index.html)</td></tr><tr><td>What information is stored in the conda.yaml file?</td><td>List(models.html)</td><td>List(models.html, projects.html, tracking.html, cli.html)</td></tr><tr><td>How can you save a model with a manually specified conda environment?</td><td>List(models.html)</td><td>List(models.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-1/index.html, getting-started/quickstart-2/index.html)</td></tr><tr><td>What are inference params and how are they used during model inference?</td><td>List(models.html)</td><td>List(models.html, traditional-ml/hyperparameter-tuning-with-child-runs/index.html, getting-started/quickstart-2/index.html, llms/llm-tracking/index.html)</td></tr><tr><td>What is the purpose of model signatures in MLflow?</td><td>List(models.html)</td><td>List(models.html, model-registry.html, traditional-ml/index.html, traditional-ml/index.html)</td></tr><tr><td>What is the API used to set signatures on models?</td><td>List(models.html)</td><td>List(models.html, llms/gateway/index.html, model-registry.html, python_api/index.html)</td></tr><tr><td>What components are used to generate the final time series?</td><td>List(models.html)</td><td>List(models.html, introduction/index.html, introduction/index.html, tracking.html)</td></tr><tr><td>What functionality does the configuration DataFrame submitted to the pyfunc flavor provide?</td><td>List(models.html)</td><td>List(models.html, traditional-ml/creating-custom-pyfunc/index.html, community-model-flavors.html, llms/custom-pyfunc-for-llms/index.html)</td></tr><tr><td>What is a common configuration for lowering the total memory pressure for pytorch models within transformers pipelines?</td><td>List(models.html)</td><td>List(models.html, llms/custom-pyfunc-for-llms/index.html, llms/index.html, llms/index.html)</td></tr><tr><td>What does the save_model() function do?</td><td>List(models.html)</td><td>List(models.html, model-registry.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-1/index.html)</td></tr><tr><td>What is an MLflow Project?</td><td>List(projects.html)</td><td>List(projects.html, introduction/index.html, introduction/index.html, getting-started/quickstart-1/index.html)</td></tr><tr><td>What are the entry points in a MLproject file and how can you specify parameters for them?</td><td>List(projects.html)</td><td>List(projects.html, cli.html, llms/prompt-engineering/index.html, tracking.html)</td></tr><tr><td>What are the project environments supported by MLflow?</td><td>List(projects.html)</td><td>List(projects.html, deployment/index.html, deployment/index.html, traditional-ml/index.html)</td></tr><tr><td>What is the purpose of the --build-image flag when running mlflow run?</td><td>List(projects.html)</td><td>List(cli.html, models.html, getting-started/quickstart-2/index.html, tracking.html)</td></tr><tr><td>What is the purpose of specifying a Conda environment in an MLflow project?</td><td>List(projects.html)</td><td>List(projects.html, models.html, deployment/deploy-model-to-kubernetes/index.html, deployment/index.html)</td></tr><tr><td>What is the purpose of the MLproject file?</td><td>List(projects.html)</td><td>List(projects.html, introduction/index.html, introduction/index.html, models.html)</td></tr><tr><td>How can you pass runtime parameters to the entry point of an MLflow Project?</td><td>List(projects.html)</td><td>List(projects.html, cli.html, tracking.html, getting-started/quickstart-2/index.html)</td></tr><tr><td>What is the relative path to the python_env YAML file within the MLflow project's directory?</td><td>List(projects.html)</td><td>List(models.html, projects.html, python_api/index.html, tracking.html)</td></tr><tr><td>What are the additional local volume mounted and environment variables in the docker container?</td><td>List(projects.html)</td><td>List(tracking.html, cli.html, docker.html, models.html)</td></tr><tr><td>How does MLflow run a Project on Kubernetes?</td><td>List(projects.html)</td><td>List(projects.html, deployment/deploy-model-to-kubernetes/index.html, getting-started/quickstart-2/index.html, deployment/index.html)</td></tr><tr><td>What fields are replaced when MLflow creates a Kubernetes Job for an MLflow Project?</td><td>List(projects.html)</td><td>List(projects.html, models.html, tracking.html, deployment/deploy-model-to-kubernetes/index.html)</td></tr><tr><td>What is the syntax for searching runs using the MLflow UI and API?</td><td>List(search-runs.html)</td><td>List(search-runs.html, getting-started/quickstart-2/index.html, llms/prompt-engineering/index.html, tracking.html)</td></tr><tr><td>What is the syntax for searching runs using the MLflow UI and API?</td><td>List(search-runs.html)</td><td>List(search-runs.html, getting-started/quickstart-2/index.html, llms/prompt-engineering/index.html, tracking.html)</td></tr><tr><td>What are the key parts of a search expression in MLflow?</td><td>List(search-runs.html)</td><td>List(search-runs.html, models.html, introduction/index.html, introduction/index.html)</td></tr><tr><td>What are some examples of entity names that contain special characters?</td><td>List(search-runs.html)</td><td>List(tutorials-and-examples/index.html, models.html, search-runs.html, llms/index.html)</td></tr><tr><td>What are the key attributes for the model with the run_id 'a1b2c3d4' and run_name 'my-run'?</td><td>List(search-runs.html)</td><td>List(search-runs.html, tracking.html, models.html, cli.html)</td></tr><tr><td>What type of constant does the RHS need to be if LHS is a metric?</td><td>List(search-runs.html)</td><td>List(llms/llm-evaluate/index.html, model-evaluation/index.html, model-evaluation/index.html, models.html)</td></tr><tr><td>How can you get all active runs from experiments IDs 3, 4, and 17 that used a CNN model with 10 layers and had a prediction accuracy of 94.5% or higher?</td><td>List(search-runs.html)</td><td>List(models.html, getting-started/quickstart-2/index.html, search-runs.html, tutorials-and-examples/index.html)</td></tr><tr><td>What is the purpose of the 'experimentIds' variable in the given paragraph?</td><td>List(search-runs.html)</td><td>List(search-experiments.html, cli.html, models.html, rest-api.html)</td></tr><tr><td>What is the MLflow Tracking component used for?</td><td>List(tracking.html)</td><td>List(introduction/index.html, introduction/index.html, tracking.html, llms/llm-tracking/index.html)</td></tr><tr><td>What information does each run record in MLflow Tracking?</td><td>List(tracking.html)</td><td>List(tracking.html, llms/llm-tracking/index.html, traditional-ml/hyperparameter-tuning-with-child-runs/index.html, getting-started/intro-quickstart/index.html)</td></tr><tr><td>How can you create an experiment in MLflow?</td><td>List(tracking.html)</td><td>List(getting-started/quickstart-1/index.html, getting-started/quickstart-2/index.html, models.html, getting-started/logging-first-model/index.html)</td></tr><tr><td>How can you create an experiment using MLflow?</td><td>List(tracking.html)</td><td>List(getting-started/quickstart-2/index.html, getting-started/quickstart-1/index.html, models.html, tutorials-and-examples/index.html)</td></tr><tr><td>What are the two components used by MLflow for storage?</td><td>List(tracking.html)</td><td>List(tracking.html, introduction/index.html, introduction/index.html, models.html)</td></tr><tr><td>What interfaces does the MLflow client use to record MLflow entities and artifacts when running MLflow on a local machine with a SQLAlchemy-compatible database?</td><td>List(tracking.html)</td><td>List(tracking.html, models.html, plugins.html, getting-started/quickstart-1/index.html)</td></tr><tr><td>What is the default backend store used by MLflow?</td><td>List(tracking.html)</td><td>List(tracking.html, plugins.html, models.html, cli.html)</td></tr><tr><td>What is the architecture depicted in this example scenario?</td><td>List(tracking.html)</td><td>List(tutorials-and-examples/index.html, models.html, deployment/deploy-model-to-kubernetes/index.html, traditional-ml/index.html)</td></tr><tr><td>What information does autologging capture when launching short-lived MLflow runs?</td><td>List(tracking.html)</td><td>List(tracking.html, getting-started/quickstart-1/index.html, llms/llm-tracking/index.html, models.html)</td></tr><tr><td>What is the purpose of the --serve-artifacts flag?</td><td>List(tracking.html)</td><td>List(tracking.html, cli.html, deployment/index.html, deployment/index.html)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is the purpose of the MLflow Model Registry?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "introduction/index.html",
          "introduction/index.html",
          "deep-learning/index.html"
         ]
        ],
        [
         "What is the purpose of registering a model with the Model Registry?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "models.html",
          "introduction/index.html",
          "introduction/index.html"
         ]
        ],
        [
         "What can you do with registered models and model versions?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "models.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "deployment/index.html"
         ]
        ],
        [
         "How can you add, modify, update, or delete a model in the Model Registry?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "models.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "introduction/index.html"
         ]
        ],
        [
         "How can you deploy and organize models in the Model Registry?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "deployment/index.html",
          "deployment/index.html",
          "models.html"
         ]
        ],
        [
         "What is the purpose of the mlflow.sklearn.log_model() method?",
         [
          "model-registry.html"
         ],
         [
          "models.html",
          "getting-started/intro-quickstart/index.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "getting-started/quickstart-1/index.html"
         ]
        ],
        [
         "What method do you use to create a new registered model?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "models.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "getting-started/quickstart-2/index.html"
         ]
        ],
        [
         "How can you deploy and organize models in the Model Registry?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "deployment/index.html",
          "deployment/index.html",
          "models.html"
         ]
        ],
        [
         "How can you fetch a specific model version?",
         [
          "model-registry.html"
         ],
         [
          "models.html",
          "model-registry.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "getting-started/quickstart-2/index.html"
         ]
        ],
        [
         "How can you fetch the latest model version in a specific stage?",
         [
          "model-registry.html"
         ],
         [
          "models.html",
          "model-registry.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "llms/prompt-engineering/index.html"
         ]
        ],
        [
         "What can you do to promote MLflow Models across environments?",
         [
          "model-registry.html"
         ],
         [
          "deployment/index.html",
          "deployment/index.html",
          "models.html",
          "getting-started/quickstart-2/index.html"
         ]
        ],
        [
         "How can you fetch a list of registered models in the MLflow registry?",
         [
          "model-registry.html"
         ],
         [
          "model-registry.html",
          "models.html",
          "getting-started/quickstart-2/index.html",
          "tutorials-and-examples/index.html"
         ]
        ],
        [
         "What is the name of the model and its version details?",
         [
          "model-registry.html"
         ],
         [
          "models.html",
          "model-registry.html",
          "new-features/index.html",
          "getting-started/quickstart-2/index.html"
         ]
        ],
        [
         "What is the purpose of saving the model in pickled format?",
         [
          "model-registry.html"
         ],
         [
          "models.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "model-registry.html",
          "deployment/index.html"
         ]
        ],
        [
         "What is an MLflow Model and what is its purpose?",
         [
          "models.html"
         ],
         [
          "introduction/index.html",
          "introduction/index.html",
          "deployment/index.html",
          "deployment/index.html"
         ]
        ],
        [
         "What are the flavors defined in the MLmodel file for the mlflow.sklearn library?",
         [
          "models.html"
         ],
         [
          "community-model-flavors.html",
          "models.html",
          "traditional-ml/creating-custom-pyfunc/index.html",
          "deployment/deploy-model-to-kubernetes/index.html"
         ]
        ],
        [
         "What command can be used to package and deploy models to AWS SageMaker?",
         [
          "models.html"
         ],
         [
          "deployment/index.html",
          "deployment/index.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "models.html"
         ]
        ],
        [
         "What is the default channel logged for models using MLflow v1.18 and above?",
         [
          "models.html"
         ],
         [
          "models.html",
          "tracking.html",
          "new-features/index.html",
          "python_api/index.html"
         ]
        ],
        [
         "What information is stored in the conda.yaml file?",
         [
          "models.html"
         ],
         [
          "models.html",
          "projects.html",
          "tracking.html",
          "cli.html"
         ]
        ],
        [
         "How can you save a model with a manually specified conda environment?",
         [
          "models.html"
         ],
         [
          "models.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "getting-started/quickstart-1/index.html",
          "getting-started/quickstart-2/index.html"
         ]
        ],
        [
         "What are inference params and how are they used during model inference?",
         [
          "models.html"
         ],
         [
          "models.html",
          "traditional-ml/hyperparameter-tuning-with-child-runs/index.html",
          "getting-started/quickstart-2/index.html",
          "llms/llm-tracking/index.html"
         ]
        ],
        [
         "What is the purpose of model signatures in MLflow?",
         [
          "models.html"
         ],
         [
          "models.html",
          "model-registry.html",
          "traditional-ml/index.html",
          "traditional-ml/index.html"
         ]
        ],
        [
         "What is the API used to set signatures on models?",
         [
          "models.html"
         ],
         [
          "models.html",
          "llms/gateway/index.html",
          "model-registry.html",
          "python_api/index.html"
         ]
        ],
        [
         "What components are used to generate the final time series?",
         [
          "models.html"
         ],
         [
          "models.html",
          "introduction/index.html",
          "introduction/index.html",
          "tracking.html"
         ]
        ],
        [
         "What functionality does the configuration DataFrame submitted to the pyfunc flavor provide?",
         [
          "models.html"
         ],
         [
          "models.html",
          "traditional-ml/creating-custom-pyfunc/index.html",
          "community-model-flavors.html",
          "llms/custom-pyfunc-for-llms/index.html"
         ]
        ],
        [
         "What is a common configuration for lowering the total memory pressure for pytorch models within transformers pipelines?",
         [
          "models.html"
         ],
         [
          "models.html",
          "llms/custom-pyfunc-for-llms/index.html",
          "llms/index.html",
          "llms/index.html"
         ]
        ],
        [
         "What does the save_model() function do?",
         [
          "models.html"
         ],
         [
          "models.html",
          "model-registry.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "getting-started/quickstart-1/index.html"
         ]
        ],
        [
         "What is an MLflow Project?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "introduction/index.html",
          "introduction/index.html",
          "getting-started/quickstart-1/index.html"
         ]
        ],
        [
         "What are the entry points in a MLproject file and how can you specify parameters for them?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "cli.html",
          "llms/prompt-engineering/index.html",
          "tracking.html"
         ]
        ],
        [
         "What are the project environments supported by MLflow?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "deployment/index.html",
          "deployment/index.html",
          "traditional-ml/index.html"
         ]
        ],
        [
         "What is the purpose of the --build-image flag when running mlflow run?",
         [
          "projects.html"
         ],
         [
          "cli.html",
          "models.html",
          "getting-started/quickstart-2/index.html",
          "tracking.html"
         ]
        ],
        [
         "What is the purpose of specifying a Conda environment in an MLflow project?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "models.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "deployment/index.html"
         ]
        ],
        [
         "What is the purpose of the MLproject file?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "introduction/index.html",
          "introduction/index.html",
          "models.html"
         ]
        ],
        [
         "How can you pass runtime parameters to the entry point of an MLflow Project?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "cli.html",
          "tracking.html",
          "getting-started/quickstart-2/index.html"
         ]
        ],
        [
         "What is the relative path to the python_env YAML file within the MLflow project's directory?",
         [
          "projects.html"
         ],
         [
          "models.html",
          "projects.html",
          "python_api/index.html",
          "tracking.html"
         ]
        ],
        [
         "What are the additional local volume mounted and environment variables in the docker container?",
         [
          "projects.html"
         ],
         [
          "tracking.html",
          "cli.html",
          "docker.html",
          "models.html"
         ]
        ],
        [
         "How does MLflow run a Project on Kubernetes?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "getting-started/quickstart-2/index.html",
          "deployment/index.html"
         ]
        ],
        [
         "What fields are replaced when MLflow creates a Kubernetes Job for an MLflow Project?",
         [
          "projects.html"
         ],
         [
          "projects.html",
          "models.html",
          "tracking.html",
          "deployment/deploy-model-to-kubernetes/index.html"
         ]
        ],
        [
         "What is the syntax for searching runs using the MLflow UI and API?",
         [
          "search-runs.html"
         ],
         [
          "search-runs.html",
          "getting-started/quickstart-2/index.html",
          "llms/prompt-engineering/index.html",
          "tracking.html"
         ]
        ],
        [
         "What is the syntax for searching runs using the MLflow UI and API?",
         [
          "search-runs.html"
         ],
         [
          "search-runs.html",
          "getting-started/quickstart-2/index.html",
          "llms/prompt-engineering/index.html",
          "tracking.html"
         ]
        ],
        [
         "What are the key parts of a search expression in MLflow?",
         [
          "search-runs.html"
         ],
         [
          "search-runs.html",
          "models.html",
          "introduction/index.html",
          "introduction/index.html"
         ]
        ],
        [
         "What are some examples of entity names that contain special characters?",
         [
          "search-runs.html"
         ],
         [
          "tutorials-and-examples/index.html",
          "models.html",
          "search-runs.html",
          "llms/index.html"
         ]
        ],
        [
         "What are the key attributes for the model with the run_id 'a1b2c3d4' and run_name 'my-run'?",
         [
          "search-runs.html"
         ],
         [
          "search-runs.html",
          "tracking.html",
          "models.html",
          "cli.html"
         ]
        ],
        [
         "What type of constant does the RHS need to be if LHS is a metric?",
         [
          "search-runs.html"
         ],
         [
          "llms/llm-evaluate/index.html",
          "model-evaluation/index.html",
          "model-evaluation/index.html",
          "models.html"
         ]
        ],
        [
         "How can you get all active runs from experiments IDs 3, 4, and 17 that used a CNN model with 10 layers and had a prediction accuracy of 94.5% or higher?",
         [
          "search-runs.html"
         ],
         [
          "models.html",
          "getting-started/quickstart-2/index.html",
          "search-runs.html",
          "tutorials-and-examples/index.html"
         ]
        ],
        [
         "What is the purpose of the 'experimentIds' variable in the given paragraph?",
         [
          "search-runs.html"
         ],
         [
          "search-experiments.html",
          "cli.html",
          "models.html",
          "rest-api.html"
         ]
        ],
        [
         "What is the MLflow Tracking component used for?",
         [
          "tracking.html"
         ],
         [
          "introduction/index.html",
          "introduction/index.html",
          "tracking.html",
          "llms/llm-tracking/index.html"
         ]
        ],
        [
         "What information does each run record in MLflow Tracking?",
         [
          "tracking.html"
         ],
         [
          "tracking.html",
          "llms/llm-tracking/index.html",
          "traditional-ml/hyperparameter-tuning-with-child-runs/index.html",
          "getting-started/intro-quickstart/index.html"
         ]
        ],
        [
         "How can you create an experiment in MLflow?",
         [
          "tracking.html"
         ],
         [
          "getting-started/quickstart-1/index.html",
          "getting-started/quickstart-2/index.html",
          "models.html",
          "getting-started/logging-first-model/index.html"
         ]
        ],
        [
         "How can you create an experiment using MLflow?",
         [
          "tracking.html"
         ],
         [
          "getting-started/quickstart-2/index.html",
          "getting-started/quickstart-1/index.html",
          "models.html",
          "tutorials-and-examples/index.html"
         ]
        ],
        [
         "What are the two components used by MLflow for storage?",
         [
          "tracking.html"
         ],
         [
          "tracking.html",
          "introduction/index.html",
          "introduction/index.html",
          "models.html"
         ]
        ],
        [
         "What interfaces does the MLflow client use to record MLflow entities and artifacts when running MLflow on a local machine with a SQLAlchemy-compatible database?",
         [
          "tracking.html"
         ],
         [
          "tracking.html",
          "models.html",
          "plugins.html",
          "getting-started/quickstart-1/index.html"
         ]
        ],
        [
         "What is the default backend store used by MLflow?",
         [
          "tracking.html"
         ],
         [
          "tracking.html",
          "plugins.html",
          "models.html",
          "cli.html"
         ]
        ],
        [
         "What is the architecture depicted in this example scenario?",
         [
          "tracking.html"
         ],
         [
          "tutorials-and-examples/index.html",
          "models.html",
          "deployment/deploy-model-to-kubernetes/index.html",
          "traditional-ml/index.html"
         ]
        ],
        [
         "What information does autologging capture when launching short-lived MLflow runs?",
         [
          "tracking.html"
         ],
         [
          "tracking.html",
          "getting-started/quickstart-1/index.html",
          "llms/llm-tracking/index.html",
          "models.html"
         ]
        ],
        [
         "What is the purpose of the --serve-artifacts flag?",
         [
          "tracking.html"
         ],
         [
          "tracking.html",
          "cli.html",
          "deployment/index.html",
          "deployment/index.html"
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "retrieved_doc_ids",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(synthetic_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33374a05-1992-4361-9c7b-3b1e1f8169cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the Embedding Model with MLflow\n",
    "You can explore with the full dataset but let's demo with fewer data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e2ac2a-40e7-4fb5-8850-95e51013a269",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "        \"source\": [\n",
    "            [\"https://mlflow.org/docs/latest/index.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/python_api/mlflow.deployments.html\"],\n",
    "            [\"https://mlflow.org/docs/latest/tracking/autolog.html\"],\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0be80f-2e00-4d3a-b05f-63c4c4359efe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 1022, which is longer than the specified 1000\n2023/12/08 18:45:53 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2023/12/08 18:45:53 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2023/12/08 18:45:53 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2023/12/08 18:45:53 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2023/12/08 18:45:53 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2023/12/08 18:45:53 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388f34f582674b8396605a5c426975b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.0</td><td>0</td><td>0.530721274</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.6666666667000001</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.33333333330000003</td><td>1</td><td>0.6934264036000001</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.0,
         0,
         0.530721274
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.6666666667000001,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.33333333330000003,
         1,
         0.6934264036000001
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "def evaluate_embedding(embedding_function):\n",
    "    CHUNK_SIZE = 1000\n",
    "    list_of_documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(list_of_documents)\n",
    "    retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "\n",
    "    def retrieve_doc_ids(question: str) -> List[str]:\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        doc_ids = [doc.metadata[\"source\"] for doc in docs]\n",
    "        return doc_ids\n",
    "\n",
    "    def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "        return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        evaluate_results = mlflow.evaluate(\n",
    "                model=retriever_model_function,\n",
    "                data=eval_data,\n",
    "                model_type=\"retriever\",\n",
    "                targets=\"source\",\n",
    "                evaluators=\"default\",\n",
    "            )\n",
    "    return evaluate_results\n",
    "\n",
    "#result1 = evaluate_embedding(DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\"))\t\n",
    "result2 = evaluate_embedding(SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "\n",
    "#eval_results_of_retriever_df_bge = result1.tables[\"eval_results_table\"]\n",
    "eval_results_of_retriever_df_MiniLM = result2.tables[\"eval_results_table\"]\n",
    "display(eval_results_of_retriever_df_MiniLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fecbb62-44ec-4af4-aa5a-7aa79bfa0943",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate different Top K strategy with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95a3acd8-170b-4e14-bc51-da977d2b1939",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-6aef400f-06a4-404b-a443-3b0808a04f07/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  return _infer_schema(self._df)\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: precision_at_1\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: precision_at_2\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: precision_at_3\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: recall_at_1\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: recall_at_2\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: recall_at_3\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ndcg_at_1\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ndcg_at_2\n2023/12/08 18:45:57 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ndcg_at_3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89a95a2ad30464fa7933976f853afd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th><th>source</th><th>outputs</th><th>precision_at_1/score</th><th>precision_at_2/score</th><th>recall_at_1/score</th><th>recall_at_2/score</th><th>ndcg_at_1/score</th><th>ndcg_at_2/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>0.0</td><td>0</td><td>0.530721274</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.38685280720000004</td></tr><tr><td>What is Databricks?</td><td>0.6666666667000001</td><td>1</td><td>1.0</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>0.33333333330000003</td><td>1</td><td>0.6934264036000001</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.38685280720000004</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>1.0</td><td>1</td><td>1.0</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         0.0,
         0,
         0.530721274,
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0,
         0,
         0,
         0,
         0,
         0.38685280720000004
        ],
        [
         "What is Databricks?",
         0.6666666667000001,
         1,
         1.0,
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         1,
         1,
         1,
         1,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         0.33333333330000003,
         1,
         0.6934264036000001,
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0,
         0,
         0,
         0,
         0,
         0.38685280720000004
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         1.0,
         1,
         1.0,
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1,
         1,
         1,
         1,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "precision_at_2/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_2/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_2/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "        evaluate_results = mlflow.evaluate(\n",
    "        data=eval_results_of_retriever_df_MiniLM,\n",
    "        targets=\"source\",\n",
    "        predictions=\"outputs\",\n",
    "        evaluators=\"default\",\n",
    "        extra_metrics=[\n",
    "            mlflow.metrics.precision_at_k(1),\n",
    "            mlflow.metrics.precision_at_k(2),\n",
    "            mlflow.metrics.precision_at_k(3),\n",
    "            mlflow.metrics.recall_at_k(1),\n",
    "            mlflow.metrics.recall_at_k(2),\n",
    "            mlflow.metrics.recall_at_k(3),\n",
    "            mlflow.metrics.ndcg_at_k(1),\n",
    "            mlflow.metrics.ndcg_at_k(2),\n",
    "            mlflow.metrics.ndcg_at_k(3),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "display(evaluate_results.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a52bda-1ea7-4f50-abac-e36d78e1b96b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluate the Chunking Strategy with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c6bff7-d988-4f09-ac10-6c9ea14b9242",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 1022, which is longer than the specified 1000\n2023/12/08 18:46:05 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2023/12/08 18:46:05 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2023/12/08 18:46:06 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2023/12/08 18:46:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2023/12/08 18:46:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2023/12/08 18:46:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n2023/12/08 18:46:11 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2023/12/08 18:46:11 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2023/12/08 18:46:11 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2023/12/08 18:46:11 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n2023/12/08 18:46:11 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n2023/12/08 18:46:11 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ndcg_at_3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3c868222dc42949923f7453c8312b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0</td><td>0</td><td>0.530721274</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>1</td><td>1</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0</td><td>0</td><td>0.530721274</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0,
         0,
         0.530721274
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         1,
         1,
         1.0
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0,
         0,
         0.530721274
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3590cf9839d84ca29219aac9b981e14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>question</th><th>source</th><th>outputs</th><th>precision_at_3/score</th><th>recall_at_3/score</th><th>ndcg_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://mlflow.org/docs/latest/index.html)</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>0.0</td><td>0</td><td>0.530721274</td></tr><tr><td>What is Databricks?</td><td>List(https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>0.6666666667000001</td><td>1</td><td>0.6934264036000001</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html)</td><td>List(https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>List(https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html, https://mlflow.org/docs/latest/tracking/autolog.html)</td><td>1.0</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://mlflow.org/docs/latest/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         0.0,
         0,
         0.530721274
        ],
        [
         "What is Databricks?",
         [
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         0.6666666667000001,
         1,
         0.6934264036000001
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html"
         ],
         [
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
          "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html"
         ],
         1.0,
         1,
         1.0
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         [
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html",
          "https://mlflow.org/docs/latest/tracking/autolog.html"
         ],
         1.0,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "question",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "ndcg_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def evaluate_chunk_size(chunk_size):\n",
    "  list_of_documents = loader.load()\n",
    "  text_splitter = CharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=0)\n",
    "  docs = text_splitter.split_documents(list_of_documents)\n",
    "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "  retriever = Chroma.from_documents(docs, embedding_function).as_retriever()\n",
    "  \n",
    "  def retrieve_doc_ids(question: str) -> List[str]:\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    doc_ids = [doc.metadata[\"source\"] for doc in docs]\n",
    "    return doc_ids\n",
    "   \n",
    "  def retriever_model_function(question_df: pd.DataFrame) -> pd.Series:\n",
    "    return question_df[\"question\"].apply(retrieve_doc_ids)\n",
    "\n",
    "  with mlflow.start_run() as run:\n",
    "      evaluate_results = mlflow.evaluate(\n",
    "          model=retriever_model_function,\n",
    "          data=eval_data,\n",
    "          model_type=\"retriever\",\n",
    "          targets=\"source\",\n",
    "          evaluators=\"default\",\n",
    "      )\n",
    "  return evaluate_results\n",
    "\n",
    "result1 = evaluate_chunk_size(1000)\n",
    "result2 = evaluate_chunk_size(2000)\n",
    "\n",
    "\n",
    "display(result1.tables[\"eval_results_table\"])\n",
    "display(result2.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd45cf0e-e139-4059-a2bd-6e4fc4d5d36e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluate the RAG system using `mlflow.evaluate()`\n",
    "Create a simple function that runs each input through the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667ec809-2bb5-4170-9937-6804386b41ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model(input_df):\n",
    "    return input_df[\"questions\"].map(qa).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1064306-b7f3-4b3e-825c-4353d808f21d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create an eval dataset (Golden Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5481491-e4a9-42ea-8a3f-f527faffd04d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>questions</th></tr></thead><tbody><tr><td>What is MLflow?</td></tr><tr><td>What is Databricks?</td></tr><tr><td>How to serve a model on Databricks?</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?"
        ],
        [
         "What is Databricks?"
        ],
        [
         "How to serve a model on Databricks?"
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "questions",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77f56ede-0b2d-449f-868c-e3a561ef28d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluate using LLM as a Judge and Basic Metric\n",
    "\n",
    "Use relevance metric to determine the relevance of the answer and context. There are other metrics you can use too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff3f1575-f1ca-42cb-ad80-cec398fb63a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import set_deployments_target\n",
    "set_deployments_target(\"databricks\")\n",
    "\n",
    "os.environ[\"DATABRICKS_HOST\"] = \"https://<>.databricks.com/\"\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"<your_databricks_token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a290ca1c-11c9-4025-9025-70807479f1e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/08 18:54:07 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n2023/12/08 18:54:07 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n2023/12/08 18:54:10 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n2023/12/08 18:54:10 WARNING mlflow.metrics.metric_definitions: Failed to load flesch kincaid metric, skipping metric logging.\n2023/12/08 18:54:10 WARNING mlflow.metrics.metric_definitions: Failed to load automated readability index metric, skipping metric logging.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c96f32fd0fa405880d38532336570e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/08 18:54:17 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: token_count\n2023/12/08 18:54:17 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: toxicity\n2023/12/08 18:54:17 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: flesch_kincaid_grade_level\n2023/12/08 18:54:17 WARNING mlflow.metrics.metric_definitions: Failed to load flesch kincaid metric, skipping metric logging.\n2023/12/08 18:54:17 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: ari_grade_level\n2023/12/08 18:54:17 WARNING mlflow.metrics.metric_definitions: Failed to load automated readability index metric, skipping metric logging.\n2023/12/08 18:54:17 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: exact_match\n2023/12/08 18:54:17 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: relevance\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4682ed3d0e8a497cb0a1317758121ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latency/mean': 0.627737283706665, 'latency/variance': 0.04464593238489556, 'latency/p90': 0.8606657028198242, 'toxicity/v1/mean': 0.0005581885779974982, 'toxicity/v1/variance': 4.918064710787432e-07, 'toxicity/v1/p90': 0.0012913507627672518, 'toxicity/v1/ratio': 0.0, 'relevance/v1/mean': 3.25, 'relevance/v1/variance': 0.1875, 'relevance/v1/p90': 3.7}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55cde4f90f6437dafbbc460dcd389f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>questions</th><th>outputs</th><th>source_documents</th><th>latency</th><th>token_count</th><th>toxicity/v1/score</th><th>relevance/v1/score</th><th>relevance/v1/justification</th></tr></thead><tbody><tr><td>What is MLflow?</td><td> MLflow is a platform designed to help manage the entire machine learning cycle for every</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "mlflow\n",
       "mlflow.artifacts\n",
       "mlflow.catboost\n",
       "mlflow.client\n",
       "mlflow.data\n",
       "mlflow.deployments\n",
       "mlflow.diviner\n",
       "mlflow.entities\n",
       "mlflow.environment_variables\n",
       "mlflow.fastai\n",
       "mlflow.gateway\n",
       "mlflow.gluon\n",
       "mlflow.h2o\n",
       "mlflow.johnsnowlabs\n",
       "mlflow.keras_core\n",
       "mlflow.langchain\n",
       "mlflow.lightgbm\n",
       "mlflow.metrics\n",
       "mlflow.mleap\n",
       "mlflow.models\n",
       "mlflow.onnx\n",
       "mlflow.paddle\n",
       "mlflow.pmdarima\n",
       "mlflow.projects\n",
       "mlflow.prophet\n",
       "mlflow.pyfunc\n",
       "mlflow.pyspark.ml\n",
       "mlflow.pytorch\n",
       "mlflow.recipes\n",
       "mlflow.sagemaker\n",
       "mlflow.sentence_transformers\n",
       "mlflow.server\n",
       "mlflow.shap\n",
       "mlflow.sklearn\n",
       "mlflow.spacy\n",
       "mlflow.spark\n",
       "mlflow.statsmodels\n",
       "mlflow.system_metrics\n",
       "mlflow.tensorflow\n",
       "mlflow.transformers\n",
       "mlflow.types\n",
       "mlflow.utils\n",
       "mlflow.xgboost\n",
       "mlflow.openai\n",
       "Log Levels, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "mlflow\n",
       "mlflow.artifacts\n",
       "mlflow.catboost\n",
       "mlflow.client\n",
       "mlflow.data\n",
       "mlflow.deployments\n",
       "mlflow.diviner\n",
       "mlflow.entities\n",
       "mlflow.environment_variables\n",
       "mlflow.fastai\n",
       "mlflow.gateway\n",
       "mlflow.gluon\n",
       "mlflow.h2o\n",
       "mlflow.johnsnowlabs\n",
       "mlflow.keras_core\n",
       "mlflow.langchain\n",
       "mlflow.lightgbm\n",
       "mlflow.metrics\n",
       "mlflow.mleap\n",
       "mlflow.models\n",
       "mlflow.onnx\n",
       "mlflow.paddle\n",
       "mlflow.pmdarima\n",
       "mlflow.projects\n",
       "mlflow.prophet\n",
       "mlflow.pyfunc\n",
       "mlflow.pyspark.ml\n",
       "mlflow.pytorch\n",
       "mlflow.recipes\n",
       "mlflow.sagemaker\n",
       "mlflow.sentence_transformers\n",
       "mlflow.server\n",
       "mlflow.shap\n",
       "mlflow.sklearn\n",
       "mlflow.spacy\n",
       "mlflow.spark\n",
       "mlflow.statsmodels\n",
       "mlflow.system_metrics\n",
       "mlflow.tensorflow\n",
       "mlflow.transformers\n",
       "mlflow.types\n",
       "mlflow.utils\n",
       "mlflow.xgboost\n",
       "mlflow.openai\n",
       "Log Levels, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "mlflow\n",
       "mlflow.artifacts\n",
       "mlflow.catboost\n",
       "mlflow.client\n",
       "mlflow.data\n",
       "mlflow.deployments\n",
       "mlflow.diviner\n",
       "mlflow.entities\n",
       "mlflow.environment_variables\n",
       "mlflow.fastai\n",
       "mlflow.gateway\n",
       "mlflow.gluon\n",
       "mlflow.h2o\n",
       "mlflow.johnsnowlabs\n",
       "mlflow.keras_core\n",
       "mlflow.langchain\n",
       "mlflow.lightgbm\n",
       "mlflow.metrics\n",
       "mlflow.mleap\n",
       "mlflow.models\n",
       "mlflow.onnx\n",
       "mlflow.paddle\n",
       "mlflow.pmdarima\n",
       "mlflow.projects\n",
       "mlflow.prophet\n",
       "mlflow.pyfunc\n",
       "mlflow.pyspark.ml\n",
       "mlflow.pytorch\n",
       "mlflow.recipes\n",
       "mlflow.sagemaker\n",
       "mlflow.sentence_transformers\n",
       "mlflow.server\n",
       "mlflow.shap\n",
       "mlflow.sklearn\n",
       "mlflow.spacy\n",
       "mlflow.spark\n",
       "mlflow.statsmodels\n",
       "mlflow.system_metrics\n",
       "mlflow.tensorflow\n",
       "mlflow.transformers\n",
       "mlflow.types\n",
       "mlflow.utils\n",
       "mlflow.xgboost\n",
       "mlflow.openai\n",
       "Log Levels, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), mlflow.deployments — MLflow 2.9.1 documentation\n",
       "\n",
       "2.9.1\n",
       "\n",
       "\n",
       " MLflow, Document))</td><td>0.7651097775</td><td>16</td><td>1.4208650000000002E-4</td><td>3</td><td>The output provides relevant information about MLflow, mentioning its ability to manage the entire machine learning cycle. Additionally, it mentions that MLflow is a platform designed to help manage the entire machine learning cycle for every, which further supports the relevance of the output to the input. However, the output does not directly address the specific question asked in the input, which is \"What is MLflow?\". Therefore, a score of 3 is appropriate, as the output is largely consistent with the provided context but does not fully address the question.</td></tr><tr><td>What is Databricks?</td><td> Databricks is a unified analytics platform for data engineering, data science, and</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), Example:\n",
       "from mlflow.deployments import get_deploy_client\n",
       "\n",
       "client = get_deploy_client(\"databricks\")\n",
       "endpoint = client.get_endpoint(endpoint=\"chat\")\n",
       "assert endpoint == {\n",
       "    \"name\": \"chat\",\n",
       "    \"creator\": \"alice@company.com\",\n",
       "    \"creation_timestamp\": 0,\n",
       "    \"last_updated_timestamp\": 0,\n",
       "    \"state\": {...},\n",
       "    \"config\": {...},\n",
       "    \"tags\": [...],\n",
       "    \"id\": \"88fd3f75a0d24b0380ddc40484d7a31b\",\n",
       "}\n",
       "\n",
       "list_deployments(endpoint=None)[source] \n",
       "\n",
       "Warning\n",
       "This method is not implemented for DatabricksDeploymentClient.\n",
       "\n",
       "\n",
       "list_endpoints()[source] \n",
       "\n",
       "Note\n",
       "Experimental: This function may change or be removed in a future release without warning.\n",
       "\n",
       "Retrieve all serving endpoints.\n",
       "See https://docs.databricks.com/api/workspace/servingendpoints/list for request/response\n",
       "schema.\n",
       "\n",
       "Returns\n",
       "A list of DatabricksEndpoint objects containing the request response.\n",
       "\n",
       "\n",
       "Example:\n",
       "from mlflow.deployments import get_deploy_client\n",
       "\n",
       "client = get_deploy_client(\"databricks\")\n",
       "endpoints = client.list_endpoints()\n",
       "assert endpoints == [\n",
       "    {\n",
       "        \"name\": \"chat\",\n",
       "        \"creator\": \"alice@company.com\",\n",
       "        \"creation_timestamp\": 0,\n",
       "        \"last_updated_timestamp\": 0,\n",
       "        \"state\": {...},\n",
       "        \"config\": {...},\n",
       "        \"tags\": [...],\n",
       "        \"id\": \"88fd3f75a0d24b0380ddc40484d7a31b\",\n",
       "    },\n",
       "]\n",
       "\n",
       "predict(deployment_name=None, inputs=None, endpoint=None)[source] \n",
       "\n",
       "Note\n",
       "Experimental: This function may change or be removed in a future release without warning.\n",
       "\n",
       "Query a serving endpoint with the provided model inputs.\n",
       "See https://docs.databricks.com/api/workspace/servingendpoints/query for request/response\n",
       "schema.\n",
       "\n",
       "Parameters\n",
       "\n",
       "deployment_name – Unused.\n",
       "inputs – A dictionary containing the model inputs to query.\n",
       "endpoint – The name of the serving endpoint to query.\n",
       "\n",
       "\n",
       "Returns\n",
       "A DatabricksEndpoint object containing the query response.\n",
       "\n",
       "\n",
       "Example:\n",
       "from mlflow.deployments import get_deploy_client, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.9.1 documentation), Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "\n",
       "\n",
       "Install Dependencies \n",
       "!pip install -q mlflow databricks-sdk\n",
       "\n",
       "\n",
       "Set Up Authentication of Databricks CE \n",
       "To set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n",
       "\n",
       "Databricks Host: Use https://community.cloud.databricks.com/\n",
       "Username: Your email address that signs in Databricks CE.\n",
       "Password: Your password of Databricks CE.\n",
       "\n",
       "If the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\n",
       "import mlflow\n",
       "\n",
       "mlflow.login(), Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.9.1 documentation), Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "\n",
       "\n",
       "Install Dependencies \n",
       "!pip install -q mlflow databricks-sdk\n",
       "\n",
       "\n",
       "Set Up Authentication of Databricks CE \n",
       "To set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n",
       "\n",
       "Databricks Host: Use https://community.cloud.databricks.com/\n",
       "Username: Your email address that signs in Databricks CE.\n",
       "Password: Your password of Databricks CE.\n",
       "\n",
       "If the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\n",
       "import mlflow\n",
       "\n",
       "mlflow.login(), Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.9.1 documentation), Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "\n",
       "\n",
       "Install Dependencies \n",
       "!pip install -q mlflow databricks-sdk\n",
       "\n",
       "\n",
       "Set Up Authentication of Databricks CE \n",
       "To set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n",
       "\n",
       "Databricks Host: Use https://community.cloud.databricks.com/\n",
       "Username: Your email address that signs in Databricks CE.\n",
       "Password: Your password of Databricks CE.\n",
       "\n",
       "If the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\n",
       "import mlflow\n",
       "\n",
       "mlflow.login(), Document))</td><td>0.9016182423</td><td>16</td><td>1.498278E-4</td><td>3</td><td>The output provides relevant information about Databricks and mentions that it is a unified analytics platform for data engineering, data science, and machine learning. Additionally, the output mentions that the model's relevance score is based on the input and context, which is appropriate for this task. However, the output does not directly address how Databricks is related to MLflow, which is the specific question asked in the input. Therefore, the output is largely consistent with the provided context but does not comprehensively answer the question, resulting in a score of 3.</td></tr><tr><td>How to serve a model on Databricks?</td><td> Use mlflow deployments.\n",
       "\n",
       "Question: What function do you need to update a specified</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), Note\n",
       "Experimental: This function may change or be removed in a future release without warning.\n",
       "\n",
       "Update a specified serving endpoint with the provided configuration.\n",
       "See https://docs.databricks.com/api/workspace/servingendpoints/updateconfig for\n",
       "request/response schema.\n",
       "\n",
       "Parameters\n",
       "\n",
       "endpoint – The name of the serving endpoint to update.\n",
       "config – A dictionary containing the configuration of the serving endpoint to update.\n",
       "\n",
       "\n",
       "Returns\n",
       "A DatabricksEndpoint object containing the request response.\n",
       "\n",
       "\n",
       "Example:\n",
       "from mlflow.deployments import get_deploy_client, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), Note\n",
       "Experimental: This function may change or be removed in a future release without warning.\n",
       "\n",
       "Update a specified serving endpoint with the provided configuration.\n",
       "See https://docs.databricks.com/api/workspace/servingendpoints/updateconfig for\n",
       "request/response schema.\n",
       "\n",
       "Parameters\n",
       "\n",
       "endpoint – The name of the serving endpoint to update.\n",
       "config – A dictionary containing the configuration of the serving endpoint to update.\n",
       "\n",
       "\n",
       "Returns\n",
       "A DatabricksEndpoint object containing the request response.\n",
       "\n",
       "\n",
       "Example:\n",
       "from mlflow.deployments import get_deploy_client, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/python_api/mlflow.deployments.html, mlflow.deployments — MLflow 2.9.1 documentation), Note\n",
       "Experimental: This function may change or be removed in a future release without warning.\n",
       "\n",
       "Update a specified serving endpoint with the provided configuration.\n",
       "See https://docs.databricks.com/api/workspace/servingendpoints/updateconfig for\n",
       "request/response schema.\n",
       "\n",
       "Parameters\n",
       "\n",
       "endpoint – The name of the serving endpoint to update.\n",
       "config – A dictionary containing the configuration of the serving endpoint to update.\n",
       "\n",
       "\n",
       "Returns\n",
       "A DatabricksEndpoint object containing the request response.\n",
       "\n",
       "\n",
       "Example:\n",
       "from mlflow.deployments import get_deploy_client, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html, 5 Minute Tracking Server Overview — MLflow 2.9.1 documentation), Create a free Databricks CE account.\n",
       "Set up Databricks CE authentication in our dev environment.\n",
       "Connect to Databricks CE in our MLflow experiment session.\n",
       "\n",
       "Then the experiment results will be automatically sent to Databricks CE, where you can view it in\n",
       "MLflow experiment UI. Now let’s look at the code.\n",
       "\n",
       "Create a Databricks CE Account \n",
       "If you don’t have an account of Databricks CE yet, you can create one\n",
       "here. The full process should take no longer than 3 minutes.\n",
       "\n",
       "\n",
       "Install Dependencies \n",
       "!pip install -q mlflow databricks-sdk\n",
       "\n",
       "\n",
       "Set Up Authentication of Databricks CE \n",
       "To set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n",
       "\n",
       "Databricks Host: Use https://community.cloud.databricks.com/\n",
       "Username: Your email address that signs in Databricks CE.\n",
       "Password: Your password of Databricks CE.\n",
       "\n",
       "If the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\n",
       "import mlflow\n",
       "\n",
       "mlflow.login(), Document))</td><td>0.4138326645</td><td>16</td><td>0.0017727469</td><td>3</td><td>The output provides relevant information about serving a model on Databricks by mentioning mlflow deployments. However, it doesn't directly address the question asked in the input, which is how to serve a model on Databricks. Therefore, the output is largely consistent with the provided context but doesn't fully answer the question.</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td> To enable MLflow Autologging by default for all experiments in your workspace,</td><td>List(List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation), Then, navigate to http://localhost:8080 in your browser to view the results.\n",
       "\n",
       "Customize Autologging Behavior \n",
       "You can also control the behavior of autologging by passing arguments to mlflow.autolog() function.\n",
       "For example, you can disable logging of model checkpoints and assosiate tags with your run as follows:\n",
       "import mlflow\n",
       "\n",
       "mlflow.autolog(\n",
       "    log_model_signatures=False,\n",
       "    extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "\n",
       "\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation), Then, navigate to http://localhost:8080 in your browser to view the results.\n",
       "\n",
       "Customize Autologging Behavior \n",
       "You can also control the behavior of autologging by passing arguments to mlflow.autolog() function.\n",
       "For example, you can disable logging of model checkpoints and assosiate tags with your run as follows:\n",
       "import mlflow\n",
       "\n",
       "mlflow.autolog(\n",
       "    log_model_signatures=False,\n",
       "    extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "\n",
       "\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation), Then, navigate to http://localhost:8080 in your browser to view the results.\n",
       "\n",
       "Customize Autologging Behavior \n",
       "You can also control the behavior of autologging by passing arguments to mlflow.autolog() function.\n",
       "For example, you can disable logging of model checkpoints and assosiate tags with your run as follows:\n",
       "import mlflow\n",
       "\n",
       "mlflow.autolog(\n",
       "    log_model_signatures=False,\n",
       "    extra_tags={\"YOUR_TAG\": \"VALUE\"},\n",
       ")\n",
       "\n",
       "\n",
       "See mlflow.autolog() for the full set of arguments you can use.\n",
       "\n",
       "Enable / Disable Autologging for Specific Libraries \n",
       "One common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\n",
       "for data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n",
       "(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\n",
       "import mlflow, Document), List(List(), List(), List(en, https://mlflow.org/docs/latest/tracking/autolog.html, Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation), Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation\n",
       "\n",
       "2.9.1\n",
       "\n",
       "\n",
       " MLflow\n",
       "\n",
       "What is MLflow?\n",
       "Getting Started with MLflow\n",
       "New Features\n",
       "LLMs\n",
       "Model Evaluation\n",
       "Deep Learning\n",
       "Traditional ML\n",
       "Deployment\n",
       "MLflow Tracking\n",
       "Quickstart\n",
       "Concepts\n",
       "Tracking Runs\n",
       "MLflow Tracking APIs\n",
       "Auto Logging\n",
       "Manual Logging\n",
       "Tracking Tips\n",
       "\n",
       "\n",
       "Explore Runs and Results\n",
       "Set up the MLflow Tracking Environment\n",
       "FAQ\n",
       "\n",
       "\n",
       "System Metrics\n",
       "MLflow Projects\n",
       "MLflow Models\n",
       "MLflow Model Registry\n",
       "MLflow Recipes\n",
       "MLflow Plugins\n",
       "MLflow Authentication\n",
       "Command-Line Interface\n",
       "Search Runs\n",
       "Search Experiments\n",
       "Python API\n",
       "R API\n",
       "Java API\n",
       "REST API\n",
       "Official MLflow Docker Image\n",
       "Community Model Flavors\n",
       "Tutorials and Examples\n",
       "\n",
       "\n",
       "Contribute\n",
       "\n",
       "\n",
       "Documentation \n",
       "MLflow Tracking \n",
       "MLflow Tracking APIs \n",
       "Automatic Logging with MLflow Tracking\n",
       "\n",
       "\n",
       "Automatic Logging with MLflow Tracking \n",
       "Auto logging is a powerful feature that allows you to log metrics, parameters, and models without the need for explicit log statements. All you need to do is to call\n",
       "mlflow.autolog() before your training code.\n",
       "import mlflow\n",
       "\n",
       "mlflow.autolog()\n",
       "\n",
       "with mlflow.start_run():\n",
       "    # your training code goes here\n",
       "    ...\n",
       "\n",
       "\n",
       "This will enable MLflow to automatically log various information about your run, including:\n",
       "\n",
       "Metrics - MLflow pre-selects a set of metrics to log, based on what model and library you use\n",
       "Parameters - hyper params specified for the training, plus default values provided by the library if not explicitly set\n",
       "Model Signature - logs Model signature instance, which describes input and output schema of the model\n",
       "Artifacts -  e.g. model checkpoints\n",
       "Dataset - dataset object used for training (if applicable), such as tensorflow.data.Dataset\n",
       "\n",
       "\n",
       "How to Get started \n",
       "\n",
       "Step 1 - Get MLflow \n",
       "MLflow is available on PyPI. If you don’t already have it installed on your system, you can install it with:\n",
       "\n",
       "pip install mlflow, Document))</td><td>0.4303884506</td><td>16</td><td>1.680931E-4</td><td>4</td><td>The output provides relevant and accurate information about how to enable MLflow Autologging for all experiments in a workspace by default. It also mentions the additional functionality of customizing Autologging behavior and disabling/enabling Autologging for specific libraries. This information is directly related to the input question and is consistent with the provided context. Therefore, the output scores a 4 on the relevance rubric.\n",
       "\n",
       "However, to achieve a perfect score of 5, the output could be improved by providing more comprehensive information about the process of enabling MLflow Autologging, such as step-by-step instructions or additional tips for troubleshooting. This would demonstrate a deeper understanding of the context and provide a more thorough answer to the input question.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         " MLflow is a platform designed to help manage the entire machine learning cycle for every",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "What is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nmlflow\nmlflow.artifacts\nmlflow.catboost\nmlflow.client\nmlflow.data\nmlflow.deployments\nmlflow.diviner\nmlflow.entities\nmlflow.environment_variables\nmlflow.fastai\nmlflow.gateway\nmlflow.gluon\nmlflow.h2o\nmlflow.johnsnowlabs\nmlflow.keras_core\nmlflow.langchain\nmlflow.lightgbm\nmlflow.metrics\nmlflow.mleap\nmlflow.models\nmlflow.onnx\nmlflow.paddle\nmlflow.pmdarima\nmlflow.projects\nmlflow.prophet\nmlflow.pyfunc\nmlflow.pyspark.ml\nmlflow.pytorch\nmlflow.recipes\nmlflow.sagemaker\nmlflow.sentence_transformers\nmlflow.server\nmlflow.shap\nmlflow.sklearn\nmlflow.spacy\nmlflow.spark\nmlflow.statsmodels\nmlflow.system_metrics\nmlflow.tensorflow\nmlflow.transformers\nmlflow.types\nmlflow.utils\nmlflow.xgboost\nmlflow.openai\nLog Levels",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "What is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nmlflow\nmlflow.artifacts\nmlflow.catboost\nmlflow.client\nmlflow.data\nmlflow.deployments\nmlflow.diviner\nmlflow.entities\nmlflow.environment_variables\nmlflow.fastai\nmlflow.gateway\nmlflow.gluon\nmlflow.h2o\nmlflow.johnsnowlabs\nmlflow.keras_core\nmlflow.langchain\nmlflow.lightgbm\nmlflow.metrics\nmlflow.mleap\nmlflow.models\nmlflow.onnx\nmlflow.paddle\nmlflow.pmdarima\nmlflow.projects\nmlflow.prophet\nmlflow.pyfunc\nmlflow.pyspark.ml\nmlflow.pytorch\nmlflow.recipes\nmlflow.sagemaker\nmlflow.sentence_transformers\nmlflow.server\nmlflow.shap\nmlflow.sklearn\nmlflow.spacy\nmlflow.spark\nmlflow.statsmodels\nmlflow.system_metrics\nmlflow.tensorflow\nmlflow.transformers\nmlflow.types\nmlflow.utils\nmlflow.xgboost\nmlflow.openai\nLog Levels",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "What is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nmlflow\nmlflow.artifacts\nmlflow.catboost\nmlflow.client\nmlflow.data\nmlflow.deployments\nmlflow.diviner\nmlflow.entities\nmlflow.environment_variables\nmlflow.fastai\nmlflow.gateway\nmlflow.gluon\nmlflow.h2o\nmlflow.johnsnowlabs\nmlflow.keras_core\nmlflow.langchain\nmlflow.lightgbm\nmlflow.metrics\nmlflow.mleap\nmlflow.models\nmlflow.onnx\nmlflow.paddle\nmlflow.pmdarima\nmlflow.projects\nmlflow.prophet\nmlflow.pyfunc\nmlflow.pyspark.ml\nmlflow.pytorch\nmlflow.recipes\nmlflow.sagemaker\nmlflow.sentence_transformers\nmlflow.server\nmlflow.shap\nmlflow.sklearn\nmlflow.spacy\nmlflow.spark\nmlflow.statsmodels\nmlflow.system_metrics\nmlflow.tensorflow\nmlflow.transformers\nmlflow.types\nmlflow.utils\nmlflow.xgboost\nmlflow.openai\nLog Levels",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "mlflow.deployments — MLflow 2.9.1 documentation\n\n2.9.1\n\n\n MLflow",
           "Document"
          ]
         ],
         0.7651097775,
         16,
         1.4208650000000002E-4,
         3,
         "The output provides relevant information about MLflow, mentioning its ability to manage the entire machine learning cycle. Additionally, it mentions that MLflow is a platform designed to help manage the entire machine learning cycle for every, which further supports the relevance of the output to the input. However, the output does not directly address the specific question asked in the input, which is \"What is MLflow?\". Therefore, a score of 3 is appropriate, as the output is largely consistent with the provided context but does not fully address the question."
        ],
        [
         "What is Databricks?",
         " Databricks is a unified analytics platform for data engineering, data science, and",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "Example:\nfrom mlflow.deployments import get_deploy_client\n\nclient = get_deploy_client(\"databricks\")\nendpoint = client.get_endpoint(endpoint=\"chat\")\nassert endpoint == {\n    \"name\": \"chat\",\n    \"creator\": \"alice@company.com\",\n    \"creation_timestamp\": 0,\n    \"last_updated_timestamp\": 0,\n    \"state\": {...},\n    \"config\": {...},\n    \"tags\": [...],\n    \"id\": \"88fd3f75a0d24b0380ddc40484d7a31b\",\n}\n\nlist_deployments(endpoint=None)[source] \n\nWarning\nThis method is not implemented for DatabricksDeploymentClient.\n\n\nlist_endpoints()[source] \n\nNote\nExperimental: This function may change or be removed in a future release without warning.\n\nRetrieve all serving endpoints.\nSee https://docs.databricks.com/api/workspace/servingendpoints/list for request/response\nschema.\n\nReturns\nA list of DatabricksEndpoint objects containing the request response.\n\n\nExample:\nfrom mlflow.deployments import get_deploy_client\n\nclient = get_deploy_client(\"databricks\")\nendpoints = client.list_endpoints()\nassert endpoints == [\n    {\n        \"name\": \"chat\",\n        \"creator\": \"alice@company.com\",\n        \"creation_timestamp\": 0,\n        \"last_updated_timestamp\": 0,\n        \"state\": {...},\n        \"config\": {...},\n        \"tags\": [...],\n        \"id\": \"88fd3f75a0d24b0380ddc40484d7a31b\",\n    },\n]\n\npredict(deployment_name=None, inputs=None, endpoint=None)[source] \n\nNote\nExperimental: This function may change or be removed in a future release without warning.\n\nQuery a serving endpoint with the provided model inputs.\nSee https://docs.databricks.com/api/workspace/servingendpoints/query for request/response\nschema.\n\nParameters\n\ndeployment_name – Unused.\ninputs – A dictionary containing the model inputs to query.\nendpoint – The name of the serving endpoint to query.\n\n\nReturns\nA DatabricksEndpoint object containing the query response.\n\n\nExample:\nfrom mlflow.deployments import get_deploy_client",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.9.1 documentation"
           ],
           "Create a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\n\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\n\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\n\n\nInstall Dependencies \n!pip install -q mlflow databricks-sdk\n\n\nSet Up Authentication of Databricks CE \nTo set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n\nDatabricks Host: Use https://community.cloud.databricks.com/\nUsername: Your email address that signs in Databricks CE.\nPassword: Your password of Databricks CE.\n\nIf the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\nimport mlflow\n\nmlflow.login()",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.9.1 documentation"
           ],
           "Create a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\n\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\n\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\n\n\nInstall Dependencies \n!pip install -q mlflow databricks-sdk\n\n\nSet Up Authentication of Databricks CE \nTo set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n\nDatabricks Host: Use https://community.cloud.databricks.com/\nUsername: Your email address that signs in Databricks CE.\nPassword: Your password of Databricks CE.\n\nIf the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\nimport mlflow\n\nmlflow.login()",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.9.1 documentation"
           ],
           "Create a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\n\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\n\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\n\n\nInstall Dependencies \n!pip install -q mlflow databricks-sdk\n\n\nSet Up Authentication of Databricks CE \nTo set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n\nDatabricks Host: Use https://community.cloud.databricks.com/\nUsername: Your email address that signs in Databricks CE.\nPassword: Your password of Databricks CE.\n\nIf the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\nimport mlflow\n\nmlflow.login()",
           "Document"
          ]
         ],
         0.9016182423,
         16,
         1.498278E-4,
         3,
         "The output provides relevant information about Databricks and mentions that it is a unified analytics platform for data engineering, data science, and machine learning. Additionally, the output mentions that the model's relevance score is based on the input and context, which is appropriate for this task. However, the output does not directly address how Databricks is related to MLflow, which is the specific question asked in the input. Therefore, the output is largely consistent with the provided context but does not comprehensively answer the question, resulting in a score of 3."
        ],
        [
         "How to serve a model on Databricks?",
         " Use mlflow deployments.\n\nQuestion: What function do you need to update a specified",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "Note\nExperimental: This function may change or be removed in a future release without warning.\n\nUpdate a specified serving endpoint with the provided configuration.\nSee https://docs.databricks.com/api/workspace/servingendpoints/updateconfig for\nrequest/response schema.\n\nParameters\n\nendpoint – The name of the serving endpoint to update.\nconfig – A dictionary containing the configuration of the serving endpoint to update.\n\n\nReturns\nA DatabricksEndpoint object containing the request response.\n\n\nExample:\nfrom mlflow.deployments import get_deploy_client",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "Note\nExperimental: This function may change or be removed in a future release without warning.\n\nUpdate a specified serving endpoint with the provided configuration.\nSee https://docs.databricks.com/api/workspace/servingendpoints/updateconfig for\nrequest/response schema.\n\nParameters\n\nendpoint – The name of the serving endpoint to update.\nconfig – A dictionary containing the configuration of the serving endpoint to update.\n\n\nReturns\nA DatabricksEndpoint object containing the request response.\n\n\nExample:\nfrom mlflow.deployments import get_deploy_client",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/python_api/mlflow.deployments.html",
            "mlflow.deployments — MLflow 2.9.1 documentation"
           ],
           "Note\nExperimental: This function may change or be removed in a future release without warning.\n\nUpdate a specified serving endpoint with the provided configuration.\nSee https://docs.databricks.com/api/workspace/servingendpoints/updateconfig for\nrequest/response schema.\n\nParameters\n\nendpoint – The name of the serving endpoint to update.\nconfig – A dictionary containing the configuration of the serving endpoint to update.\n\n\nReturns\nA DatabricksEndpoint object containing the request response.\n\n\nExample:\nfrom mlflow.deployments import get_deploy_client",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",
            "5 Minute Tracking Server Overview — MLflow 2.9.1 documentation"
           ],
           "Create a free Databricks CE account.\nSet up Databricks CE authentication in our dev environment.\nConnect to Databricks CE in our MLflow experiment session.\n\nThen the experiment results will be automatically sent to Databricks CE, where you can view it in\nMLflow experiment UI. Now let’s look at the code.\n\nCreate a Databricks CE Account \nIf you don’t have an account of Databricks CE yet, you can create one\nhere. The full process should take no longer than 3 minutes.\n\n\nInstall Dependencies \n!pip install -q mlflow databricks-sdk\n\n\nSet Up Authentication of Databricks CE \nTo set up Databricks CE authentication, we can use the API mlflow.login(), which will prompt you for required information:\n\nDatabricks Host: Use https://community.cloud.databricks.com/\nUsername: Your email address that signs in Databricks CE.\nPassword: Your password of Databricks CE.\n\nIf the authentication succeeds, you should see a message “Succesfully signed in Databricks!”.\nimport mlflow\n\nmlflow.login()",
           "Document"
          ]
         ],
         0.4138326645,
         16,
         0.0017727469,
         3,
         "The output provides relevant information about serving a model on Databricks by mentioning mlflow deployments. However, it doesn't directly address the question asked in the input, which is how to serve a model on Databricks. Therefore, the output is largely consistent with the provided context but doesn't fully answer the question."
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         " To enable MLflow Autologging by default for all experiments in your workspace,",
         [
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation"
           ],
           "Then, navigate to http://localhost:8080 in your browser to view the results.\n\nCustomize Autologging Behavior \nYou can also control the behavior of autologging by passing arguments to mlflow.autolog() function.\nFor example, you can disable logging of model checkpoints and assosiate tags with your run as follows:\nimport mlflow\n\nmlflow.autolog(\n    log_model_signatures=False,\n    extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\n\n\nSee mlflow.autolog() for the full set of arguments you can use.\n\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation"
           ],
           "Then, navigate to http://localhost:8080 in your browser to view the results.\n\nCustomize Autologging Behavior \nYou can also control the behavior of autologging by passing arguments to mlflow.autolog() function.\nFor example, you can disable logging of model checkpoints and assosiate tags with your run as follows:\nimport mlflow\n\nmlflow.autolog(\n    log_model_signatures=False,\n    extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\n\n\nSee mlflow.autolog() for the full set of arguments you can use.\n\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation"
           ],
           "Then, navigate to http://localhost:8080 in your browser to view the results.\n\nCustomize Autologging Behavior \nYou can also control the behavior of autologging by passing arguments to mlflow.autolog() function.\nFor example, you can disable logging of model checkpoints and assosiate tags with your run as follows:\nimport mlflow\n\nmlflow.autolog(\n    log_model_signatures=False,\n    extra_tags={\"YOUR_TAG\": \"VALUE\"},\n)\n\n\nSee mlflow.autolog() for the full set of arguments you can use.\n\nEnable / Disable Autologging for Specific Libraries \nOne common use case is to enable/disable autologging for a specific library. For example, if you train your model on PyTorch but use scikit-learn\nfor data preprocessing, you may want to disable autologging for scikit-learn while keeping it enabled for PyTorch. You can achieve this by either\n(1) enable autologging only for PyTorch using PyTorch flavor (2) disable autologging for scikit-learn using its flavor with disable=True.\nimport mlflow",
           "Document"
          ],
          [
           [],
           [],
           [
            "en",
            "https://mlflow.org/docs/latest/tracking/autolog.html",
            "Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation"
           ],
           "Automatic Logging with MLflow Tracking — MLflow 2.9.1 documentation\n\n2.9.1\n\n\n MLflow\n\nWhat is MLflow?\nGetting Started with MLflow\nNew Features\nLLMs\nModel Evaluation\nDeep Learning\nTraditional ML\nDeployment\nMLflow Tracking\nQuickstart\nConcepts\nTracking Runs\nMLflow Tracking APIs\nAuto Logging\nManual Logging\nTracking Tips\n\n\nExplore Runs and Results\nSet up the MLflow Tracking Environment\nFAQ\n\n\nSystem Metrics\nMLflow Projects\nMLflow Models\nMLflow Model Registry\nMLflow Recipes\nMLflow Plugins\nMLflow Authentication\nCommand-Line Interface\nSearch Runs\nSearch Experiments\nPython API\nR API\nJava API\nREST API\nOfficial MLflow Docker Image\nCommunity Model Flavors\nTutorials and Examples\n\n\nContribute\n\n\nDocumentation \nMLflow Tracking \nMLflow Tracking APIs \nAutomatic Logging with MLflow Tracking\n\n\nAutomatic Logging with MLflow Tracking \nAuto logging is a powerful feature that allows you to log metrics, parameters, and models without the need for explicit log statements. All you need to do is to call\nmlflow.autolog() before your training code.\nimport mlflow\n\nmlflow.autolog()\n\nwith mlflow.start_run():\n    # your training code goes here\n    ...\n\n\nThis will enable MLflow to automatically log various information about your run, including:\n\nMetrics - MLflow pre-selects a set of metrics to log, based on what model and library you use\nParameters - hyper params specified for the training, plus default values provided by the library if not explicitly set\nModel Signature - logs Model signature instance, which describes input and output schema of the model\nArtifacts -  e.g. model checkpoints\nDataset - dataset object used for training (if applicable), such as tensorflow.data.Dataset\n\n\nHow to Get started \n\nStep 1 - Get MLflow \nMLflow is available on PyPI. If you don’t already have it installed on your system, you can install it with:\n\npip install mlflow",
           "Document"
          ]
         ],
         0.4303884506,
         16,
         1.680931E-4,
         4,
         "The output provides relevant and accurate information about how to enable MLflow Autologging for all experiments in a workspace by default. It also mentions the additional functionality of customizing Autologging behavior and disabling/enabling Autologging for specific libraries. This information is directly related to the input question and is consistent with the provided context. Therefore, the output scores a 4 on the relevance rubric.\n\nHowever, to achieve a perfect score of 5, the output could be improved by providing more comprehensive information about the process of enabling MLflow Autologging, such as step-by-step instructions or additional tips for troubleshooting. This would demonstrate a deeper understanding of the context and provide a more thorough answer to the input question."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "questions",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "outputs",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_documents",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"lc_attributes\",\"type\":{\"type\":\"struct\",\"fields\":[]},\"nullable\":true,\"metadata\":{}},{\"name\":\"lc_secrets\",\"type\":{\"type\":\"struct\",\"fields\":[]},\"nullable\":true,\"metadata\":{}},{\"name\":\"metadata\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"language\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"source\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"title\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"page_content\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "latency",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "token_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "toxicity/v1/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "relevance/v1/score",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "relevance/v1/justification",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "bindings": {},
       "collapsed": false,
       "command": "from  mlflow.metrics.genai.metric_definitions import answer_relevance\n\nanswer_relevance_metric = answer_relevance(model=\"openai:/gpt-4\")\n\nwith mlflow.start_run(run_id=run.info.run_id):\n    results =  mlflow.evaluate(\n        model,\n        eval_df,\n        model_type=\"question-answering\",\n        evaluators=\"default\",\n        predictions=\"result\",\n        extra_metrics=[answer_relevance_metric, mlflow.metrics.latency()],\n        evaluator_config={\n            \"col_mapping\": {\n                \"inputs\": \"questions\",\n                \"context\": \"source_documents\",\n            }\n        }\n    )\n    print(results.metrics)\n\ndisplay(results.tables[\"eval_results_table\"])",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "TABLE"
         },
         {
          "key": "options",
          "value": {
           "columns": [
            {
             "alignContent": "left",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "string",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "questions",
             "order": 0,
             "preserveWhitespace": false,
             "title": "questions",
             "type": "string",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "left",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "string",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "source_documents",
             "order": 1,
             "preserveWhitespace": false,
             "title": "source_documents",
             "type": "string",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "right",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "number",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "answer_relevance/v1/score",
             "numberFormat": "0.00",
             "order": 2,
             "preserveWhitespace": false,
             "title": "answer_relevance/v1/score",
             "type": "float",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "left",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "string",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "answer_relevance/v1/justification",
             "order": 3,
             "preserveWhitespace": false,
             "title": "answer_relevance/v1/justification",
             "type": "string",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "right",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "number",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "precision_at_3/score",
             "numberFormat": "0.00",
             "order": 4,
             "preserveWhitespace": false,
             "title": "precision_at_3/score",
             "type": "float",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "left",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "string",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "retrieved_context",
             "order": 5,
             "preserveWhitespace": false,
             "title": "retrieved_context",
             "type": "string",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "right",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "number",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "recall_at_3/score",
             "numberFormat": "0.00",
             "order": 6,
             "preserveWhitespace": false,
             "title": "recall_at_3/score",
             "type": "float",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "right",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "number",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "ndcg_at_3/score",
             "numberFormat": "0.00",
             "order": 7,
             "preserveWhitespace": false,
             "title": "ndcg_at_3/score",
             "type": "float",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "left",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "string",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "outputs",
             "order": 8,
             "preserveWhitespace": false,
             "title": "outputs",
             "type": "string",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "left",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "string",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "ground_truth_context",
             "order": 9,
             "preserveWhitespace": false,
             "title": "ground_truth_context",
             "type": "string",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "left",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "string",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "query",
             "order": 10,
             "preserveWhitespace": false,
             "title": "query",
             "type": "string",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "right",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "number",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "latency",
             "numberFormat": "0.00",
             "order": 11,
             "preserveWhitespace": false,
             "title": "latency",
             "type": "float",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "right",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "number",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "token_count",
             "numberFormat": "0.00",
             "order": 12,
             "preserveWhitespace": false,
             "title": "token_count",
             "type": "float",
             "useMonospaceFont": false,
             "visible": true
            },
            {
             "alignContent": "right",
             "allowHTML": false,
             "allowSearch": false,
             "booleanValues": [
              "false",
              "true"
             ],
             "displayAs": "number",
             "highlightLinks": false,
             "imageHeight": "",
             "imageTitleTemplate": "{{ @ }}",
             "imageUrlTemplate": "{{ @ }}",
             "imageWidth": "",
             "linkOpenInNewTab": true,
             "linkTextTemplate": "{{ @ }}",
             "linkTitleTemplate": "{{ @ }}",
             "linkUrlTemplate": "{{ @ }}",
             "name": "toxicity/v1/score",
             "numberFormat": "0.00",
             "order": 13,
             "preserveWhitespace": false,
             "title": "toxicity/v1/score",
             "type": "float",
             "useMonospaceFont": false,
             "visible": true
            }
           ],
           "condensed": true,
           "itemsPerPage": 25,
           "paginationSize": "default",
           "version": 2,
           "withRowNumber": false
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "f55e4f48-684d-4903-8bd0-06ca638dcea9",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 22.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": [],
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from  mlflow.metrics.genai.metric_definitions import relevance\n",
    "\n",
    "relevance_metric = relevance(model=\"endpoints:/databricks-llama-2-70b-chat\") #You can also use any model you have hosted on Databricks, models from the Marketplace or models in the Foundation model API\n",
    "\n",
    "with mlflow.start_run():\n",
    "    results =  mlflow.evaluate(\n",
    "        model,\n",
    "        eval_df,\n",
    "        model_type=\"question-answering\",\n",
    "        evaluators=\"default\",\n",
    "        predictions=\"result\",\n",
    "        extra_metrics=[relevance_metric, mlflow.metrics.latency()],\n",
    "        evaluator_config={\n",
    "            \"col_mapping\": {\n",
    "                \"inputs\": \"questions\",\n",
    "                \"context\": \"source_documents\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    print(results.metrics)\n",
    "\n",
    "display(results.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "919d2691-b1ad-4f31-a23a-4a155c5efdd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": 0,
       "elementNUID": "f55e4f48-684d-4903-8bd0-06ca638dcea9",
       "elementType": "command",
       "guid": "f9125ba6-77fb-411f-9859-66be60ebd6a5",
       "options": null,
       "position": {
        "height": 12,
        "width": 22,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "5cc44542-d2d1-4b49-9760-7d912cbd5a44",
     "origId": 2038904942228793,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "MLflow for e2e Evaluation Blog",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
