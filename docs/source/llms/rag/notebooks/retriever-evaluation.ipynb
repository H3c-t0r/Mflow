{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8938de9-7fae-41cd-ad6b-7ee26c288eab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Evaluate Retriever with Doc IDs\n",
    "\n",
    "In mlflow 2.8.0, we introduced a new model type \"retriever\" to the `mlflow.evaluate()` API. It helps you to evaluate the retriever in a RAG application, and contains a built-in metric `precision_at_k`.\n",
    "\n",
    "This notebook illustrates how to use `mlflow.evaluate()` to evaluate the retriever in a RAG application. It has the following sections:\n",
    "\n",
    "1. Evaluation dataset preparation\n",
    "2. Metrics definition\n",
    "3. Calling `mlflow.evaluate()`\n",
    "4. Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1621bac5-708f-4d98-aa7a-597ae9337876",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Collecting git+https://github.com/bbqiu/mlflow@retriever-recall\n",
      "  Cloning https://github.com/bbqiu/mlflow (to revision retriever-recall) to /tmp/pip-req-build-szvgb1w3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/bbqiu/mlflow /tmp/pip-req-build-szvgb1w3\n",
      "  Running command git checkout -b retriever-recall --track origin/retriever-recall\n",
      "  Switched to a new branch 'retriever-recall'\n",
      "  branch 'retriever-recall' set up to track 'origin/retriever-recall'.\n",
      "  Resolved https://github.com/bbqiu/mlflow to commit ace64d76b3e5e86db120f34339f6b5878fbb8304\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting entrypoints<1\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting gitpython<4,>=2.1.0\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.6/190.6 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting sqlparse<1,>=0.4.0\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.2/41.2 kB 7.4 MB/s eta 0:00:00\n",
      "Collecting psutil<6\n",
      "  Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 283.6/283.6 kB 9.3 MB/s eta 0:00:00\n",
      "Collecting Jinja2<4,>=2.11\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 14.0 MB/s eta 0:00:00\n",
      "Collecting scipy<2\n",
      "  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.4/36.4 MB 40.7 MB/s eta 0:00:00\n",
      "Collecting pandas<3\n",
      "  Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 93.0 MB/s eta 0:00:00\n",
      "Collecting scikit-learn<2\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 98.8 MB/s eta 0:00:00\n",
      "Collecting pyyaml<7,>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 705.5/705.5 kB 58.7 MB/s eta 0:00:00\n",
      "Collecting docker<7,>=4.0.0\n",
      "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.1/148.1 kB 20.0 MB/s eta 0:00:00\n",
      "Collecting pytz<2024\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.5/502.5 kB 47.6 MB/s eta 0:00:00\n",
      "Collecting markdown<4,>=3.3\n",
      "  Downloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 17.9 MB/s eta 0:00:00\n",
      "Collecting pyarrow<14,>=4.0.0\n",
      "  Downloading pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.0/40.0 MB 37.0 MB/s eta 0:00:00\n",
      "Collecting gunicorn<22\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.2/80.2 kB 12.9 MB/s eta 0:00:00\n",
      "Collecting protobuf<5,>=3.12.0\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.6/311.6 kB 32.2 MB/s eta 0:00:00\n",
      "Collecting packaging<24\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 11.0 MB/s eta 0:00:00\n",
      "Collecting cloudpickle<3\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting databricks-cli<1,>=0.8.7\n",
      "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.3/150.3 kB 27.0 MB/s eta 0:00:00\n",
      "Collecting alembic!=1.10.0,<2\n",
      "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.8/226.8 kB 28.5 MB/s eta 0:00:00\n",
      "Collecting sqlalchemy<3,>=1.4.0\n",
      "  Downloading SQLAlchemy-2.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 100.5 MB/s eta 0:00:00\n",
      "Collecting click<9,>=7.0\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 15.2 MB/s eta 0:00:00\n",
      "Collecting matplotlib<4\n",
      "  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 110.8 MB/s eta 0:00:00\n",
      "Collecting Flask<4\n",
      "  Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.7/99.7 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting querystring-parser<2\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 78.6 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.17.3\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 13.2 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata!=4.7.0,<7,>=3.7.0\n",
      "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 17.7 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting urllib3<3,>=1.26.7\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 kB 22.0 MB/s eta 0:00:00\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 28.6 MB/s eta 0:00:00\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.6.4-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.3/57.3 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting itsdangerous>=2.1.2\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting Werkzeug>=3.0.0\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.7/226.7 kB 31.4 MB/s eta 0:00:00\n",
      "Collecting blinker>=1.6.2\n",
      "  Downloading blinker-1.6.3-py3-none-any.whl (13 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 13.4 MB/s eta 0:00:00\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 76.1 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.7/301.7 kB 39.2 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 118.0 MB/s eta 0:00:00\n",
      "Collecting python-dateutil>=2.7\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 35.0 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 130.2 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 17.8 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 kB 43.8 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.3/158.3 kB 22.7 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.2/139.2 kB 24.2 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 11.1 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.2/302.2 kB 39.0 MB/s eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 613.2/613.2 kB 61.8 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: mlflow\n",
      "  Building wheel for mlflow (pyproject.toml): started\n",
      "  Building wheel for mlflow (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for mlflow: filename=mlflow-2.7.2.dev0-py3-none-any.whl size=4569213 sha256=3386adceb343042f90ba8bd75e84134d8de50bc3dfafbc7d3c6fa84d5e4c74e6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-92gk38xq/wheels/2d/cd/36/db2d7f974689d6c9f6466e20a5d26156dbd386f4b22a230295\n",
      "Successfully built mlflow\n",
      "Installing collected packages: pytz, zipp, websocket-client, urllib3, tzdata, typing-extensions, threadpoolctl, tabulate, sqlparse, smmap, six, pyyaml, pyparsing, pyjwt, psutil, protobuf, pillow, packaging, oauthlib, numpy, MarkupSafe, markdown, kiwisolver, joblib, itsdangerous, idna, greenlet, fonttools, entrypoints, cycler, cloudpickle, click, charset-normalizer, certifi, blinker, Werkzeug, sqlalchemy, scipy, requests, querystring-parser, python-dateutil, pyarrow, Mako, Jinja2, importlib-metadata, gunicorn, gitdb, contourpy, scikit-learn, pandas, matplotlib, gitpython, Flask, docker, databricks-cli, alembic, mlflow\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.7\n",
      "    Not uninstalling pytz at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'pytz'. No files were found to uninstall.\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 1.0.0\n",
      "    Not uninstalling zipp at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'zipp'. No files were found to uninstall.\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 0.58.0\n",
      "    Not uninstalling websocket-client at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'websocket-client'. No files were found to uninstall.\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.14\n",
      "    Not uninstalling urllib3 at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'urllib3'. No files were found to uninstall.\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Not uninstalling threadpoolctl at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'threadpoolctl'. No files were found to uninstall.\n",
      "  Attempting uninstall: tabulate\n",
      "    Found existing installation: tabulate 0.9.0\n",
      "    Uninstalling tabulate-0.9.0:\n",
      "      Successfully uninstalled tabulate-0.9.0\n",
      "  Attempting uninstall: sqlparse\n",
      "    Found existing installation: sqlparse 0.4.4\n",
      "    Uninstalling sqlparse-0.4.4:\n",
      "      Successfully uninstalled sqlparse-0.4.4\n",
      "  Attempting uninstall: smmap\n",
      "    Found existing installation: smmap 5.0.1\n",
      "    Uninstalling smmap-5.0.1:\n",
      "      Successfully uninstalled smmap-5.0.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Not uninstalling six at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'six'. No files were found to uninstall.\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Not uninstalling pyparsing at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'pyparsing'. No files were found to uninstall.\n",
      "  Attempting uninstall: pyjwt\n",
      "    Found existing installation: PyJWT 2.3.0\n",
      "    Not uninstalling pyjwt at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'PyJWT'. No files were found to uninstall.\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.0\n",
      "    Not uninstalling psutil at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'psutil'. No files were found to uninstall.\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.0\n",
      "    Not uninstalling protobuf at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'protobuf'. No files were found to uninstall.\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.4.0\n",
      "    Not uninstalling pillow at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'Pillow'. No files were found to uninstall.\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 22.0\n",
      "    Not uninstalling packaging at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'packaging'. No files were found to uninstall.\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.0\n",
      "    Not uninstalling oauthlib at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'oauthlib'. No files were found to uninstall.\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Not uninstalling numpy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'numpy'. No files were found to uninstall.\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.1\n",
      "    Not uninstalling markupsafe at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.5\n",
      "    Uninstalling Markdown-3.5:\n",
      "      Successfully uninstalled Markdown-3.5\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.4\n",
      "    Not uninstalling kiwisolver at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'kiwisolver'. No files were found to uninstall.\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.2.0\n",
      "    Not uninstalling joblib at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'joblib'. No files were found to uninstall.\n",
      "  Attempting uninstall: itsdangerous\n",
      "    Found existing installation: itsdangerous 2.1.2\n",
      "    Uninstalling itsdangerous-2.1.2:\n",
      "      Successfully uninstalled itsdangerous-2.1.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Not uninstalling idna at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'idna'. No files were found to uninstall.\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.0.0\n",
      "    Uninstalling greenlet-3.0.0:\n",
      "      Successfully uninstalled greenlet-3.0.0\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.25.0\n",
      "    Not uninstalling fonttools at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'fonttools'. No files were found to uninstall.\n",
      "  Attempting uninstall: entrypoints\n",
      "    Found existing installation: entrypoints 0.4\n",
      "    Not uninstalling entrypoints at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'entrypoints'. No files were found to uninstall.\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Not uninstalling cycler at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'cycler'. No files were found to uninstall.\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.2.1\n",
      "    Uninstalling cloudpickle-2.2.1:\n",
      "      Successfully uninstalled cloudpickle-2.2.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Not uninstalling charset-normalizer at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'charset-normalizer'. No files were found to uninstall.\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Not uninstalling certifi at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'certifi'. No files were found to uninstall.\n",
      "  Attempting uninstall: blinker\n",
      "    Found existing installation: blinker 1.6.3\n",
      "    Uninstalling blinker-1.6.3:\n",
      "      Successfully uninstalled blinker-1.6.3\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 3.0.0\n",
      "    Uninstalling Werkzeug-3.0.0:\n",
      "      Successfully uninstalled Werkzeug-3.0.0\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.22\n",
      "    Uninstalling SQLAlchemy-2.0.22:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.22\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.0\n",
      "    Not uninstalling scipy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'scipy'. No files were found to uninstall.\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Not uninstalling requests at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'requests'. No files were found to uninstall.\n",
      "  Attempting uninstall: querystring-parser\n",
      "    Found existing installation: querystring-parser 1.2.4\n",
      "    Uninstalling querystring-parser-1.2.4:\n",
      "      Successfully uninstalled querystring-parser-1.2.4\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Not uninstalling python-dateutil at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'python-dateutil'. No files were found to uninstall.\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 8.0.0\n",
      "    Not uninstalling pyarrow at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'pyarrow'. No files were found to uninstall.\n",
      "  Attempting uninstall: Mako\n",
      "    Found existing installation: Mako 1.2.4\n",
      "    Uninstalling Mako-1.2.4:\n",
      "      Successfully uninstalled Mako-1.2.4\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Not uninstalling jinja2 at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'Jinja2'. No files were found to uninstall.\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.6.4\n",
      "    Not uninstalling importlib-metadata at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n",
      "  Attempting uninstall: gunicorn\n",
      "    Found existing installation: gunicorn 21.2.0\n",
      "    Uninstalling gunicorn-21.2.0:\n",
      "      Successfully uninstalled gunicorn-21.2.0\n",
      "  Attempting uninstall: gitdb\n",
      "    Found existing installation: gitdb 4.0.11\n",
      "    Uninstalling gitdb-4.0.11:\n",
      "      Successfully uninstalled gitdb-4.0.11\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.0.5\n",
      "    Not uninstalling contourpy at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'contourpy'. No files were found to uninstall.\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.1.1\n",
      "    Not uninstalling scikit-learn at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'scikit-learn'. No files were found to uninstall.\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Not uninstalling pandas at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'pandas'. No files were found to uninstall.\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.0\n",
      "    Not uninstalling matplotlib at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65\n",
      "    Can't uninstall 'matplotlib'. No files were found to uninstall.\n",
      "  Attempting uninstall: gitpython\n",
      "    Found existing installation: GitPython 3.1.40\n",
      "    Uninstalling GitPython-3.1.40:\n",
      "      Successfully uninstalled GitPython-3.1.40\n",
      "  Attempting uninstall: Flask\n",
      "    Found existing installation: Flask 2.3.3\n",
      "    Uninstalling Flask-2.3.3:\n",
      "      Successfully uninstalled Flask-2.3.3\n",
      "  Attempting uninstall: docker\n",
      "    Found existing installation: docker 6.1.3\n",
      "    Uninstalling docker-6.1.3:\n",
      "      Successfully uninstalled docker-6.1.3\n",
      "  Attempting uninstall: databricks-cli\n",
      "    Found existing installation: databricks-cli 0.18.0\n",
      "    Uninstalling databricks-cli-0.18.0:\n",
      "      Successfully uninstalled databricks-cli-0.18.0\n",
      "  Attempting uninstall: alembic\n",
      "    Found existing installation: alembic 1.12.0\n",
      "    Uninstalling alembic-1.12.0:\n",
      "      Successfully uninstalled alembic-1.12.0\n",
      "  Attempting uninstall: mlflow\n",
      "    Found existing installation: mlflow 2.7.2.dev0\n",
      "    Uninstalling mlflow-2.7.2.dev0:\n",
      "      Successfully uninstalled mlflow-2.7.2.dev0\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "databricks-sdk 0.1.6 requires requests<2.29.0,>=2.28.1, but you have requests 2.31.0 which is incompatible.\n",
      "botocore 1.27.96 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.7 which is incompatible.\n",
      "Successfully installed Flask-3.0.0 Jinja2-3.1.2 Mako-1.2.4 MarkupSafe-2.1.3 Werkzeug-3.0.1 alembic-1.12.1 blinker-1.6.3 certifi-2023.7.22 charset-normalizer-3.3.1 click-8.1.7 cloudpickle-2.2.1 contourpy-1.1.1 cycler-0.12.1 databricks-cli-0.18.0 docker-6.1.3 entrypoints-0.4 fonttools-4.43.1 gitdb-4.0.11 gitpython-3.1.40 greenlet-3.0.1 gunicorn-21.2.0 idna-3.4 importlib-metadata-6.8.0 itsdangerous-2.1.2 joblib-1.3.2 kiwisolver-1.4.5 markdown-3.5 matplotlib-3.8.0 mlflow-2.7.2.dev0 numpy-1.26.1 oauthlib-3.2.2 packaging-23.2 pandas-2.1.2 pillow-10.1.0 protobuf-4.24.4 psutil-5.9.6 pyarrow-13.0.0 pyjwt-2.8.0 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 pyyaml-6.0.1 querystring-parser-1.2.4 requests-2.31.0 scikit-learn-1.3.2 scipy-1.11.3 six-1.16.0 smmap-5.0.1 sqlalchemy-2.0.22 sqlparse-0.4.4 tabulate-0.9.0 threadpoolctl-3.2.0 typing-extensions-4.8.0 tzdata-2023.3 urllib3-2.0.7 websocket-client-1.6.4 zipp-3.17.0\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall git+https://github.com/bbqiu/mlflow@retriever-recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eb54321-3156-4323-b29d-d1ab5adc7c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f25b3107-7c7d-4286-bf76-72d5bf02372c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.2.dev0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a690cc-7672-4f24-8518-8faabfc9afea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Evaluation dataset preparation\n",
    "\n",
    "When evaluating a retriever, it's recommended to save the retrieved document IDs into a static dataset represented by a Pandas Dataframe or an MLflow Pandas Dataset containing the input queries, retrieved relevant document IDs, and the ground-truth relevant document IDs for the evaluation.\n",
    "\n",
    "A \"document ID\" should be a string that identifies a document.\n",
    "\n",
    "For each row, the retrieved relevant document IDs and the ground-truth relevant document IDs should be provided as a tuple of document ID strings.\n",
    "\n",
    "The column name of the retrieved relevant document IDs should be specified by the `predictions` parameter, and the column name of the ground-truth relevant document IDs should be specified by the `targets` parameter.\n",
    "\n",
    "Alternatively, you can use a function that returns a tuple of document ID strings for\n",
    "the evaluation. The function should take a Pandas DataFrame as input and return a Pandas\n",
    "DataFrame with the same number of rows, where each row contains a tuple of document ID\n",
    "strings.\n",
    "\n",
    "Here is a simple example dataset that illustrates the expected data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a61b1b2-582e-49d5-864d-b58d2b6c3392",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Databricks?\",\n",
    "            \"How to serve a model on Databricks?\",\n",
    "            \"How to enable MLflow Autologging for my workspace by default?\",\n",
    "        ],\n",
    "        \"retrieved_context\": [\n",
    "            [\n",
    "                \"https://docs.databricks.com/en/mlflow/index.html\",\n",
    "                \"https://docs.databricks.com/en/mlflow/quick-start.html\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://docs.databricks.com/en/introduction/index.html\",\n",
    "                \"https://docs.databricks.com/en/getting-started/overview.html\",\n",
    "            ],\n",
    "            [\n",
    "                \"https://docs.databricks.com/en/machine-learning/model-serving/index.html\",\n",
    "                \"https://docs.databricks.com/en/machine-learning/model-serving/model-serving-intro.html\",\n",
    "            ],\n",
    "            [],\n",
    "        ],\n",
    "        \"ground_truth_context\": [\n",
    "            [\"https://docs.databricks.com/en/mlflow/index.html\"],\n",
    "            [\"https://docs.databricks.com/en/introduction/index.html\"],\n",
    "            [\n",
    "                \"https://docs.databricks.com/en/machine-learning/model-serving/index.html\",\n",
    "                \"https://docs.databricks.com/en/machine-learning/model-serving/llm-optimized-model-serving.html\",\n",
    "            ],\n",
    "            [\"https://docs.databricks.com/en/mlflow/databricks-autologging.html\"],\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24b6eedd-d0cd-4c53-a834-ca706a4eaeab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Metric Definition\n",
    "\n",
    "A built-in metric `mlflow.metrics.precision_at_k(k)` is available for the retriever evaluation.\n",
    "\n",
    "This metric computes a score between 0 and 1 for each row representing the precision of the\n",
    "retriever model at the given k value. The score is calculated by dividing the number of relevant\n",
    "documents retrieved by the total number of documents retrieved or k, whichever is smaller.\n",
    "If no relevant documents are retrieved, the score is 1, indication that no false positives were\n",
    "retrieved.\n",
    "\n",
    "The ``k`` parameter should be a positive integer representing the number of retrieved documents\n",
    "to evaluate for each row. ``k`` defaults to 3.\n",
    "\n",
    "This metric is a default metric for the ``retriever`` model type.\n",
    "\n",
    "When the model type is ``\"retriever\"``, this metric will be calculated automatically with the\n",
    "default ``k`` value of 3. To use another ``k`` value, use the ``evaluator_config`` parameter\n",
    "in the ``mlflow.evaluate()`` API as follows: ``evaluator_config={\"k\": <k_value>}``.\n",
    "\n",
    "\n",
    "```python\n",
    "# Case 1: Specifying the model type\n",
    "evaluate_results = mlflow.evaluate(\n",
    "    data=data,\n",
    "    model_type=\"retriever\",\n",
    "    targets=\"ground_truth_context\",\n",
    "    predictions=\"retrieved_context\",\n",
    "    evaluators=\"default\",\n",
    "    evaluator_config={\"k\": 5}\n",
    "  )\n",
    "```\n",
    "\n",
    "Alternatively, you can directly specify the ``mlflow.metrics.precision_at_k(<k_value>)`` metric\n",
    "in the ``extra_metrics`` parameter of the ``mlflow.evaluate()`` API without specifying a model\n",
    "type. In this case, the ``k`` value specified in the ``evaluator_config`` parameter will be\n",
    "ignored.\n",
    "\n",
    "\n",
    "```python\n",
    "# Case 2: Specifying the extra_metrics\n",
    "evaluate_results = mlflow.evaluate(\n",
    "    data=data,\n",
    "    targets=\"ground_truth_context\",\n",
    "    predictions=\"retrieved_context\",\n",
    "    extra_matrics=[mlflow.metrics.precision_at_k(5)],\n",
    "  )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b8c2330-3c76-4a00-98a9-703359a780d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Calling mlflow.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0390728a-a6cf-4c84-867a-0c6832114471",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/mlflow/data/digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]\n",
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/mlflow/models/evaluation/base.py:414: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(_hash_array_like_element_as_bytes)\n",
      "2023/10/27 23:08:11 WARNING mlflow.data.pandas_dataset: Failed to infer schema for Pandas dataset. Exception: Unable to map 'object' type to MLflow DataType. object can be mapped iff all values have identical data type which is one of (string, (bytes or byterray),  int, float).\n",
      "2023/10/27 23:08:12 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/10/27 23:08:12 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: precision_at_3\n",
      "2023/10/27 23:08:12 INFO mlflow.models.evaluation.default_evaluator: Evaluating builtin metrics: recall_at_3\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    evaluate_results = mlflow.evaluate(\n",
    "        data=data,\n",
    "        model_type=\"retriever\",\n",
    "        targets=\"ground_truth_context\",\n",
    "        predictions=\"retrieved_context\",\n",
    "        evaluators=\"default\",\n",
    "        evaluator_config={\"retriever_k\": 3},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb24318b-6149-4703-ad06-731c8a75866f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'precision_at_3/mean': 0.375,\n",
      "    'precision_at_3/p90': 0.5,\n",
      "    'precision_at_3/variance': 0.046875,\n",
      "    'recall_at_3/mean': 0.625,\n",
      "    'recall_at_3/p90': 1.0,\n",
      "    'recall_at_3/variance': 0.171875}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(evaluate_results.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525ccc10-3a60-4dc9-804e-083cfa313349",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Result Analysis\n",
    "\n",
    "You can view the per-row scores in the logged \"eval_results_table.json\" in artifacts by either loading it to a pandas dataframe (shown below) or visiting the MLflow run comparason UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f3d5b3-245c-46b7-87ce-d85e261eac28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/connect/session.py:423: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if is_datetime64_dtype(t) or is_datetime64tz_dtype(t)\n",
      "/databricks/spark/python/pyspark/sql/pandas/serializers.py:275: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(series.dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>questions</th><th>ground_truth_context</th><th>retrieved_context</th><th>precision_at_3/score</th><th>recall_at_3/score</th></tr></thead><tbody><tr><td>What is MLflow?</td><td>List(https://docs.databricks.com/en/mlflow/index.html)</td><td>List(https://docs.databricks.com/en/mlflow/index.html, https://docs.databricks.com/en/mlflow/quick-start.html)</td><td>0.5</td><td>1.0</td></tr><tr><td>What is Databricks?</td><td>List(https://docs.databricks.com/en/introduction/index.html)</td><td>List(https://docs.databricks.com/en/introduction/index.html, https://docs.databricks.com/en/getting-started/overview.html)</td><td>0.5</td><td>1.0</td></tr><tr><td>How to serve a model on Databricks?</td><td>List(https://docs.databricks.com/en/machine-learning/model-serving/index.html, https://docs.databricks.com/en/machine-learning/model-serving/llm-optimized-model-serving.html)</td><td>List(https://docs.databricks.com/en/machine-learning/model-serving/index.html, https://docs.databricks.com/en/machine-learning/model-serving/model-serving-intro.html)</td><td>0.5</td><td>0.5</td></tr><tr><td>How to enable MLflow Autologging for my workspace by default?</td><td>List(https://docs.databricks.com/en/mlflow/databricks-autologging.html)</td><td>List()</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is MLflow?",
         [
          "https://docs.databricks.com/en/mlflow/index.html"
         ],
         [
          "https://docs.databricks.com/en/mlflow/index.html",
          "https://docs.databricks.com/en/mlflow/quick-start.html"
         ],
         0.5,
         1
        ],
        [
         "What is Databricks?",
         [
          "https://docs.databricks.com/en/introduction/index.html"
         ],
         [
          "https://docs.databricks.com/en/introduction/index.html",
          "https://docs.databricks.com/en/getting-started/overview.html"
         ],
         0.5,
         1
        ],
        [
         "How to serve a model on Databricks?",
         [
          "https://docs.databricks.com/en/machine-learning/model-serving/index.html",
          "https://docs.databricks.com/en/machine-learning/model-serving/llm-optimized-model-serving.html"
         ],
         [
          "https://docs.databricks.com/en/machine-learning/model-serving/index.html",
          "https://docs.databricks.com/en/machine-learning/model-serving/model-serving-intro.html"
         ],
         0.5,
         0.5
        ],
        [
         "How to enable MLflow Autologging for my workspace by default?",
         [
          "https://docs.databricks.com/en/mlflow/databricks-autologging.html"
         ],
         [],
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "questions",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ground_truth_context",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "retrieved_context",
         "type": "{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}"
        },
        {
         "metadata": "{}",
         "name": "precision_at_3/score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "recall_at_3/score",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(evaluate_results.tables[\"eval_results_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55e66e36-8e8b-4ad4-9595-9b4647e04305",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-420022480716680>, line 1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m evaluate_results\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_results_table\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth_context\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_results_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mground_truth_context\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n",
       "\u001b[1;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n",
       "\u001b[1;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[1;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n",
       "\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n",
       "\u001b[1;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n",
       "\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n",
       "\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
       "\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n",
       "\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
       "\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n",
       "\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n",
       "\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
       "\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n",
       "\u001b[1;32m    598\u001b[0m \n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n",
       "\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
       "\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
       "\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n",
       "\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:232\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n",
       "\u001b[1;32m    226\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n",
       "\u001b[1;32m    227\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got the class instead. Try instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    229\u001b[0m     )\n",
       "\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
       "\u001b[0;32m--> 232\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
       "\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, NumpyEADtype):\n",
       "\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# Ensure we don't end up with a NumpyExtensionArray\u001b[39;00m\n",
       "\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1657\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n",
       "\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m npdtype\n",
       "\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m npdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
       "\u001b[0;32m-> 1657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\u001b[1;32m   1659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m npdtype\n",
       "\n",
       "\u001b[0;31mTypeError\u001b[0m: dtype '<class 'tuple'>' not understood"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\nFile \u001b[0;32m<command-420022480716680>, line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_results\u001b[38;5;241m.\u001b[39mtables[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_results_table\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth_context\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_results_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mground_truth_context\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\n\nFile \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\nFile \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\nFile \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\nFile \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\nFile \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:232\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    226\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got the class instead. Try instantiating \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 232\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, NumpyEADtype):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# Ensure we don't end up with a NumpyExtensionArray\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\nFile \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-3531e620-387e-4c5b-aa5f-0354c0bfda65/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1657\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m npdtype\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m npdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m npdtype\n\n\u001b[0;31mTypeError\u001b[0m: dtype '<class 'tuple'>' not understood",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: dtype '<class 'tuple'>' not understood",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_results.tables[\"eval_results_table\"][\"ground_truth_context\"] = evaluate_results.tables[\n",
    "    \"eval_results_table\"\n",
    "][\"ground_truth_context\"].astype(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0ea34a-74eb-4537-b934-a30b88e27502",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"A\": [(\"doc1\",), (\"doc2\",), (\"doc3\",)]})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Using apply can lead to \"unwrapping\"\n",
    "df[\"B\"] = df[\"A\"].apply(lambda x: x)\n",
    "print(\"\\nDataFrame after apply:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf18dd29-1017-4245-9f3b-923dbd46f742",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Evaluate Retriever with Doc IDs",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
