{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Code Assistant with OpenAI & MLflow\n",
    "\n",
    "### Overview\n",
    "\n",
    "Welcome to this comprehensive tutorial, where you'll embark on a fascinating journey through the integration of OpenAI's powerful language models with MLflow, where we'll be building an actually useful tool that can, with the simple addition of a decorator to any function that we declare, get immediate feedback within an interactive environment on code under active development.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "1. **Master OpenAI's GPT-4 for Code Assistance**: Understand how to leverage OpenAI's GPT-4 model for providing real-time coding assistance. Learn to harness its capabilities for generating code suggestions, explanations, and improving overall coding efficiency.\n",
    "2. **Utilize MLflow for Enhanced Model Tracking**: Delve into MLflow's powerful tracking systems to manage machine learning experiments. Learn how to adapt a `pyfunc model` from within MLflow to control how the output of an LLM is displayed from within an interactive coding environment.\n",
    "3. **Seamlessly Combine OpenAI and MLflow**: Discover the practical steps to integrate OpenAI's AI capabilities with MLflow's tracking and management systems. This integration exemplifies how combining these tools can streamline the development and deployment of intelligent applications.\n",
    "4. **Develop and Deploy a Custom Python Code Assistant**: Gain hands-on experience in creating a Python-based code assistant using OpenAI's model. Then, actually see it in action as it is used within a Jupyter Notebook environment to give helpful assistance during development.\n",
    "5. **Improve Code Quality with AI-driven Insights**: Apply AI-powered analysis to review and enhance your code. Learn how an AI assistant can provide real-time feedback on code quality, suggest improvements, and help maintain high coding standards.\n",
    "6. **Explore Advanced Python Features for Robust Development**: Understand advanced Python features like decorators and functional programming. These are crucial for building efficient, scalable, and maintainable software solutions, especially when integrating AI capabilities.\n",
    "\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **MLflow's Model Management**: Explore MLflow's features for tracking experiments, packaging code into reproducible runs, and managing and deploying models.\n",
    "2. **Custom Python Model**: Learn how to use MLflow's built-in customization for defining a generic Python function that will allow you to craft your own processing logic while interfacing with OpenAI to perform alternative handling to the LLM's output.\n",
    "3. **Python Decorators and Functional Programming**: Learn about advanced Python concepts like decorators and functional programming for efficient code evaluation and enhancement.\n",
    "\n",
    "### Why Use MLflow for this?\n",
    "\n",
    "MLflow emerges as a pivotal element in this tutorial, making our use case not only feasible but also highly efficient. It offers a secure and seamless interface with OpenAI's advanced language models. In this tutorial, we'll explore how MLflow greatly simplifies the process of storing specific instructional prompts for OpenAI, and enhances the user experience by adding readable formatting to the returned text.\n",
    "\n",
    "The flexibility and scalability of MLflow make it a robust choice for integrating with various tools, particularly in interactive coding environments like Jupyter Notebooks. We'll witness firsthand how MLflow facilitates rapid experimentation and iteration, allowing us to create a functional tool with minimal effort. This tool will not just assist in development but will also elevate the overall coding and model management experience. By leveraging MLflow's comprehensive features, we'll navigate through a seamless end-to-end workflow, from setting up intricate models to executing complex tasks efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Disable a few less-than-useful UserWarnings from setuptools and pydantic\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import inspect\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import shutil\n",
    "import textwrap\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.types.schema import ColSpec, ParamSchema, ParamSpec, Schema\n",
    "\n",
    "\n",
    "# Run a quick validation that we have an entry for the OPEN_API_KEY within environment variables\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"OPENAI_API_KEY environment variable must be set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the MLflow Client\n",
    "\n",
    "Depending on where you are running this notebook, your configuration may vary for how you initialize the MLflow Client.\n",
    "If you are uncertain about how to configure and use an MLflow Tracking server or what options are available (The easiest is to use the free managed service within [Databricks Community Edition](https://community.cloud.databricks.com/)), you can see [the guide to running notebooks here](https://www.mlflow.org/docs/latest/getting-started/running-notebooks/index.html) for more information on setting the tracking server uri and configuring access to either managed or self-managed MLflow tracking servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the MLflow Experiment\n",
    "\n",
    "In this section of the tutorial, we use MLflow's `set_experiment` function to define an experiment named \"Code Helper\". This step is essential in MLflow's workflow for several reasons:\n",
    "\n",
    "1. **Unique Identification**: A unique and distinct experiment name like \"Code Helper\" is crucial for easy identification and segregation of the runs pertaining to this specific project, especially when working on multiple projects or experiments simultaneously.\n",
    "\n",
    "2. **Simplified Tracking**: Naming the experiment enables effortless tracking of all the runs and models associated with it, maintaining a clear history of model development, parameters, metrics, and results.\n",
    "\n",
    "3. **Ease of Access in MLflow UI**: A distinct experiment name ensures quick location and access to our experiment's runs and models within the MLflow UI, facilitating analysis, comparison of different runs, and sharing findings.\n",
    "\n",
    "4. **Facilitates Better Organization**: As projects grow in complexity, having a well-named experiment aids in better organization and management of the machine learning lifecycle, making it easier to navigate through different stages of the experiment.\n",
    "\n",
    "The use of a unique experiment name like \"Code Helper\" lays the foundation for efficient model management and tracking, a critical aspect of any machine learning workflow, especially in dynamic and collaborative environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/benjamin.wilson/repos/mlflow-fork/mlflow/docs/source/llms/openai/notebooks/mlruns/703316263508654123', creation_time=1701891935339, experiment_id='703316263508654123', last_update_time=1701891935339, lifecycle_stage='active', name='Code Helper', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Code Helper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Instruction Set for the AI Model\n",
    "\n",
    "In this part of the tutorial, we define a specific set of instructions to guide the behavior of our AI model. This is achieved through the `instruction` array, which outlines the roles and expected interactions between the system (AI model) and the user. Here's a breakdown of its components:\n",
    "\n",
    "1. **System Role**: The first element of the array defines the role of the AI model as a 'system'. It describes the model as a 'helpful expert Software Engineer' whose purpose is to assist in code analysis and provide educational support. The AI model is expected to:\n",
    "   - Offer clear explanations of the code's intent.\n",
    "   - Assess the code's correctness and readability.\n",
    "   - Suggest improvements while focusing on simplicity, maintainability, and adherence to best coding practices.\n",
    "\n",
    "2. **User Role**: The second element represents the 'user' role. This part is where the user (in this case, the person learning from the tutorial) interacts with the AI model by submitting code for review. The user is expected to:\n",
    "   - Provide code snippets for evaluation.\n",
    "   - Seek feedback and suggestions for code improvement from the AI model.\n",
    "\n",
    "This instruction set is crucial for creating an interactive learning experience. It guides the AI model in providing targeted, constructive feedback, making it an invaluable tool for understanding coding practices and enhancing coding skills.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"As an AI specializing in code review, your task is to analyze and critique the submitted code. For each code snippet, provide a detailed review that includes: \"\n",
    "            \"1. Identification of any errors or bugs. \"\n",
    "            \"2. Suggestions for optimizing code efficiency and structure. \"\n",
    "            \"3. Recommendations for enhancing code readability and maintainability. \"\n",
    "            \"4. Best practice advice relevant to the code’s language and functionality. \"\n",
    "            \"Your feedback should help the user improve their coding skills and understand best practices in software development.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"Review my code and suggest improvements: {code}\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and Utilizing the Model Signature in MLflow\n",
    "\n",
    "In this part of the tutorial, we define a `ModelSignature` for our OpenAI model, which is a crucial step in both saving the base model and later in our custom Python Model implementation. Here's an overview of the process:\n",
    "\n",
    "1. **Model Signature Definition**:\n",
    "   - We create a `ModelSignature` object that specifies the input, output, and parameters of our model.\n",
    "   - The `inputs` and `outputs` are defined as schemas with a single string column, indicating that our model will be processing string type data.\n",
    "   - The `params` schema includes two parameters: `max_tokens` and `temperature`, each with a default value and data type defined.\n",
    "\n",
    "> **Note** We're explicitly defining the model signature here for purposes of demonstration. The schema will be automatically inferred if you do not specify one and will be set based on the `task` that is defined when logging or saving the model. \n",
    "\n",
    "2. **Logging the Base OpenAI Model**:\n",
    "   - Using `mlflow.openai.log_model`, we log the base OpenAI model (`gpt-4`) along with the `instruction` set we defined earlier.\n",
    "   - The `signature` we defined is also passed in this step, ensuring that the model is saved with the correct specifications for inputs, outputs, and parameters.\n",
    "\n",
    "This dual-purpose signature is vital as it ensures consistency in how the model processes data both in its base form and when it's later wrapped in a custom Python Model. This approach streamlines the workflow and maintains uniformity across different stages of model implementation and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Cost Considerations for GPT-4 Usage\n",
    "\n",
    "#### High(er) Cost of GPT-4\n",
    "It's crucial to note that **using GPT-4, as opposed to GPT-3.5, can incur higher costs**. GPT-4's advanced capabilities and enhanced performance come with a price premium, making it a more expensive option compared to earlier models like GPT-3.5.\n",
    "\n",
    "#### Why Choose GPT-4 in This Tutorial\n",
    "- **Enhanced Capabilities**: We opt for GPT-4 in this tutorial primarily due to its superior capabilities, especially in areas such as code refactoring and detecting issues in code implementations.\n",
    "- **Demonstration Purposes**: The use of GPT-4 here serves as a demonstration to showcase the cutting-edge advancements in language model technology and its applications in complex tasks.\n",
    "\n",
    "#### Consider Alternatives for Cost-Effectiveness\n",
    "For projects where cost is a significant concern, or where the advanced features of GPT-4 are not essential, **consider using GPT-3.5 or other more cost-effective alternatives**. These models still offer robust performance for a wide range of applications but at a lower cost.\n",
    "\n",
    "#### Budgeting for GPT-4\n",
    "If you choose to proceed with GPT-4, it is recommended to:\n",
    "- **Monitor Usage Closely**: Keep track of your API usage to manage costs effectively.\n",
    "- **Budget Accordingly**: Allocate sufficient resources to cover the higher costs associated with GPT-4.\n",
    "\n",
    "By being mindful of these cost considerations, you can make informed decisions about which OpenAI model best suits your project's needs and budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model signature that will be used for both the base model and the eventual custom pyfunc implementation later.\n",
    "signature = ModelSignature(\n",
    "    inputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "    outputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "    params=ParamSchema(\n",
    "        [\n",
    "            ParamSpec(name=\"max_tokens\", default=500, dtype=\"long\"),\n",
    "            ParamSpec(name=\"temperature\", default=0, dtype=\"float\"),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Log the base OpenAI model with the included instruction set (prompt)\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.openai.log_model(\n",
    "        model=\"gpt-4\",\n",
    "        task=openai.ChatCompletion,\n",
    "        artifact_path=\"base_model\",\n",
    "        messages=instruction,\n",
    "        signature=signature,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our logged model in the MLflow UI\n",
    "\n",
    "After logging the model, you can open up the MLflow UI and see the components that have been logged. Notice that the configuration for our model, including the model type (gpt-4), the endpoint API type (task) is recorded (chat.completions), and the prompt have all been logged. \n",
    "\n",
    "![openai-ui](https://i.imgur.com/72EGEG8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancing User Experience with Custom Pyfunc Implementation\n",
    "\n",
    "In this section, we introduce a custom Python Model, `CodeHelper`, which significantly improves the user experience when interacting with the OpenAI model in an interactive development environment like Jupyter Notebook. The `CodeHelper` class is designed to format the output from the OpenAI model, making it more readable and visually appealing, similar to a chat interface. Here's how it works:\n",
    "\n",
    "1. **Initialization and Model Loading**:\n",
    "   - The `CodeHelper` class inherits from `PythonModel`.\n",
    "   - The `load_context` method is used to load the OpenAI model, which is saved as `self.model`. This model is loaded from the `context.artifacts`, ensuring that the appropriate model is used for predictions.\n",
    "\n",
    "2. **Response Formatting**:\n",
    "   - The `_format_response` method is crucial for enhancing the output format.\n",
    "   - It processes each item in the response, handling text and code blocks differently.\n",
    "   - Text lines outside of code blocks are wrapped to a width of 80 characters for better readability.\n",
    "   - Lines within code blocks (marked by `` ``` ``) are not wrapped, preserving the code structure.\n",
    "   - This formatting creates an output that resembles a chat interface, making the interaction more intuitive and user-friendly.\n",
    "\n",
    "3. **Making Predictions**:\n",
    "   - The `predict` method is where the model’s prediction occurs.\n",
    "   - It calls the loaded OpenAI model to get the raw response for the given input.\n",
    "   - The raw response is then passed to the `_format_response` method for formatting.\n",
    "   - The formatted response is returned, providing a clear and easy-to-read output.\n",
    "\n",
    "By implementing this custom `pyfunc`, we enhance the user's interaction with the AI code helper. It not only makes the output easier to understand but also presents it in a familiar format, akin to messaging, which is especially beneficial in interactive coding environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom pyfunc implementation that applies text and code formatting to the output results from the OpenAI model\n",
    "class CodeHelper(PythonModel):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.model = mlflow.pyfunc.load_model(context.artifacts[\"model_path\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_response(response):\n",
    "        formatted_output = \"\"\n",
    "        in_code_block = False\n",
    "\n",
    "        for item in response:\n",
    "            lines = item.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                # Check for the start/end of a code block\n",
    "                if line.strip().startswith(\"```\"):\n",
    "                    in_code_block = not in_code_block\n",
    "                    formatted_output += line + \"\\n\"\n",
    "                    continue\n",
    "\n",
    "                if in_code_block:\n",
    "                    # Don't wrap lines inside code blocks\n",
    "                    formatted_output += line + \"\\n\"\n",
    "                else:\n",
    "                    # Wrap lines outside of code blocks\n",
    "                    wrapped_lines = textwrap.fill(line, width=80)\n",
    "                    formatted_output += wrapped_lines + \"\\n\"\n",
    "\n",
    "        return formatted_output\n",
    "\n",
    "    def predict(self, context, model_input, params):\n",
    "        # Call the loaded OpenAI model instance to get the raw response\n",
    "        raw_response = self.model.predict(model_input, params=params)\n",
    "\n",
    "        # Return the formatted response so that it is easier to read\n",
    "        return self._format_response(raw_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location that we'll be using to save (and load) our custom pyfunc implementation\n",
    "final_model_path = \"/tmp/my_code_helper\"\n",
    "\n",
    "# As before, we're cleaning up the destination location for the serialized custom model, in case you want to run this notebook several times.\n",
    "if os.path.exists(final_model_path):\n",
    "    shutil.rmtree(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Custom Python Model with MLflow\n",
    "\n",
    "This part of the tutorial demonstrates how to save the custom Python model, `CodeHelper`, using MLflow. The process involves specifying the model's location and additional information to ensure it is properly stored and can be retrieved for future use. Here’s an overview:\n",
    "\n",
    "1. **Defining Artifacts**:\n",
    "   - An `artifacts` dictionary is created with a key `\"model_path\"` pointing to the location of the base OpenAI model. This step is important to link our custom model with the necessary base model files. We retrieve the location of the logged openai model from earlier by accessing the `model_uri` property from the return of the `log_model()` function.\n",
    "\n",
    "2. **Saving the Model**:\n",
    "   - The `mlflow.pyfunc.save_model` function is used to save the `CodeHelper` model.\n",
    "   - `path`: Specifies the location (`final_model_path`) where the model will be saved.\n",
    "   - `python_model`: An instance of the `CodeHelper` class is provided, indicating the model to be saved.\n",
    "   - `input_example`: An example input (`[\"x = 1\"]`) is given, which is useful for understanding the model's expected input format.\n",
    "   - `signature`: The previously defined `ModelSignature` is passed, ensuring consistency in how the model processes data.\n",
    "   - `artifacts`: The `artifacts` dictionary is included to associate the base OpenAI model with our custom model.\n",
    "\n",
    "This step is crucial for encapsulating the entire functionality of our `CodeHelper` model in a format that MLflow can manage and track. It allows for easy deployment and versioning of the model, facilitating its use in various applications and environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb15a6a626c465db467050bc7e3f810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the location of the base model that we'll be using within our custom pyfunc implementation\n",
    "artifacts = {\"model_path\": model_info.model_uri}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.save_model(\n",
    "        path=final_model_path,\n",
    "        python_model=CodeHelper(),\n",
    "        input_example=[\"x = 1\"],\n",
    "        signature=signature,\n",
    "        artifacts=artifacts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our saved Custom Python Model\n",
    "\n",
    "In this next section, we load the model that we just saved so that we can use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_helper = mlflow.pyfunc.load_model(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the `code_inspector` Decorator Function\n",
    "\n",
    "The `code_inspector` function is a Python decorator designed to augment functions with automatic code review capabilities using an MLflow pyfunc model. Here's a breakdown of how it works:\n",
    "\n",
    "1. **Decorator Function Setup**:\n",
    "   - `code_inspector` takes an MLflow model as an argument. This model is used to evaluate the code of any function it decorates.\n",
    "   - Inside, it defines `decorator_check_my_function`, a function that creates the actual decorator.\n",
    "\n",
    "2. **Wrapper Function**:\n",
    "   - `decorator_check_my_function` further defines `wrapper`, which will wrap around the original function.\n",
    "   - `wrapper` accepts arbitrary arguments and keyword arguments, allowing it to decorate any function.\n",
    "   - It uses `inspect.getsource` to extract the source code of the decorated function.\n",
    "\n",
    "3. **Code Analysis and Feedback**:\n",
    "   - The source code is then analyzed by the MLflow model using `model.predict`.\n",
    "   - The model's feedback, which may include code improvements, error identification, or suggestions, is printed out.\n",
    "   - In case of exceptions during model prediction or formatting, the error is printed.\n",
    "   - After printing the feedback, `wrapper` executes the original function and returns its result.\n",
    "\n",
    "4. **Application**:\n",
    "   - Apply `code_inspector` as a decorator to functions for real-time code quality checks and feedback.\n",
    "   - This is particularly useful for learning and improving coding practices, as it provides insights into code quality and best practices.\n",
    "\n",
    "This decorator enhances the functionality of functions, allowing them to be automatically reviewed for code quality and correctness using an MLflow pyfunc model, thereby enriching the development and learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_inspector(model):\n",
    "    \"\"\"\n",
    "    Function decorator that will evaluate the implementation of any decorated function and provide feedback on it when called\n",
    "\n",
    "    Args:\n",
    "        model: The MLflow pyfunc model that will be used to evaluate the code\n",
    "    \"\"\"\n",
    "\n",
    "    def decorator_check_my_function(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                parsed_func = inspect.getsource(func)\n",
    "                response = model.predict(parsed_func)\n",
    "                # Print the response so that even if the code doesn't execute properly, we'll get feedback about what to change\n",
    "                print(response)\n",
    "            # If there is an error with calling the model or in parsing the response, we still want to return the function response\n",
    "            except Exception as e:\n",
    "                print(\"Error during model prediction or formatting:\", e)\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator_check_my_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Usage Trial: The `summing_function` with `code_inspector`\n",
    "\n",
    "We apply the `code_inspector` decorator to a function named `summing_function`. This function is designed to calculate the sum of sums for a given range. Here's an insight into its functionality and the enhancement brought by `code_inspector`:\n",
    "\n",
    "1. **Function Overview**:\n",
    "   - `summing_function` calculates the cumulative sum of numbers up to `n`. It does so by iterating over a range and summing the intermediate sums at each step.\n",
    "   - A dictionary, `intermediate_sums`, is used to store these sums, which are then aggregated to find the final sum.\n",
    "\n",
    "2. **Using `code_inspector`**:\n",
    "   - The function is decorated with `code_inspector(loaded_helper)`. This means that each time `summing_function` is called, the MLflow model loaded as `loaded_helper` analyzes its code.\n",
    "   - The decorator provides real-time feedback on the code, assessing aspects like quality, efficiency, and best practices.\n",
    "\n",
    "3. **Educational Benefit**:\n",
    "   - This setup is ideal for learning, allowing users to receive instant, actionable feedback on their code.\n",
    "   - It offers a practical way to understand the logic behind the function and learn coding optimizations and improvements.\n",
    "\n",
    "By integrating `code_inspector` with `summing_function`, the tutorial demonstrates an interactive approach to enhancing coding skills, with immediate feedback aiding in understanding and improvement.\n",
    "\n",
    "Before proceeding to see the response from GPT-4, can you identify all of the issues in this code (there are more than a few)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def summing_function(n):\n",
    "    sum_result = 0\n",
    "\n",
    "    intermediate_sums = {}\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        intermediate_sums[str(i)] = sum([x for x in range(1, i + 1)])\n",
    "        for key in intermediate_sums:\n",
    "            if key == str(i):\n",
    "                sum_result = intermediate_sums[key]\n",
    "\n",
    "    final_sum = sum([intermediate_sums[key] for key in intermediate_sums if int(key) == n])\n",
    "\n",
    "    return int(str(final_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution and Analysis of `summing_function(1000)`\n",
    "\n",
    "When we execute `summing_function(1000)`, several key processes take place, utilizing our custom MLflow model through the `code_inspector` decorator. Here's what happens:\n",
    "\n",
    "1. **Decorator Activation**:\n",
    "   - On calling `summing_function(1000)`, the `code_inspector` decorator is the first to activate. This decorator is designed to use the `loaded_helper` model to analyze the decorated function.\n",
    "\n",
    "2. **Model Analyzes the Function Code**:\n",
    "   - `code_inspector` retrieves the source code of `summing_function` using the `inspect` module.\n",
    "   - This source code is then passed to the `loaded_helper` model, which performs an analysis based on its training and provided instructions. The model predicts feedback on code quality, efficiency, and best practices.\n",
    "\n",
    "3. **Feedback Presentation**:\n",
    "   - The feedback generated by the model is printed out. This feedback might include suggestions for code optimization, identification of potential errors, or general advice on coding practices.\n",
    "   - This step provides an educational insight into the code quality before the function executes its logic.\n",
    "\n",
    "4. **Function Execution**:\n",
    "   - After the feedback is displayed, the `summing_function` proceeds to execute with the input `1000`.\n",
    "   - The function calculates the cumulative sum of numbers up to 1000, but due to its inefficient implementation, this process may be slower and more resource-intensive than necessary.\n",
    "\n",
    "5. **Return of Result**:\n",
    "   - The function returns the final computed sum, which is the result of the summing logic implemented within it.\n",
    "\n",
    "This demonstration highlights how the `code_inspector` decorator, combined with our custom MLflow model, provides a unique, real-time code analysis and feedback mechanism, enhancing the learning and development experience in an interactive environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Identification of any errors or bugs:\n",
      "   There are no syntax errors in your code, but there are logical errors. The\n",
      "code is more complex than it needs to be for calculating the sum of numbers from\n",
      "1 to n.\n",
      "\n",
      "2. Suggestions for optimizing code efficiency and structure:\n",
      "   The code can be significantly simplified. The use of a dictionary to store\n",
      "intermediate sums is unnecessary and inefficient. The sum of numbers from 1 to n\n",
      "can be calculated directly using the formula n*(n+1)/2. This reduces the time\n",
      "complexity from O(n) to O(1).\n",
      "\n",
      "3. Recommendations for enhancing code readability and maintainability:\n",
      "   The code can be made more readable by removing unnecessary steps and using\n",
      "meaningful variable names. The conversion of integers to strings and back to\n",
      "integers is unnecessary and can be confusing.\n",
      "\n",
      "4. Best practice advice relevant to the code’s language and functionality:\n",
      "   In Python, it's a good practice to use list comprehensions sparingly and only\n",
      "when they improve readability. In this case, the use of list comprehensions is\n",
      "unnecessary and makes the code more complex.\n",
      "\n",
      "Here's a simplified version of your function:\n",
      "\n",
      "```python\n",
      "def summing_function(n):\n",
      "    return n * (n + 1) // 2\n",
      "```\n",
      "\n",
      "This function does exactly the same thing as your original function, but it's\n",
      "much simpler and more efficient. It's also easier to read and understand.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summing_function(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of `one_liner` Function\n",
    "\n",
    "The `one_liner` function, decorated with `code_inspector`, demonstrates an interesting approach but has several issues:\n",
    "\n",
    "1. **Complexity**: The function uses nested lambda expressions to calculate the factorial of `n`. While compact, this approach is overly complex and hard to read, making the code less maintainable and understandable.\n",
    "\n",
    "2. **Readability**: Good coding practice emphasizes readability, which is compromised here due to the one-liner approach. Such code can be challenging to debug and understand, especially for those unfamiliar with the specific coding style.\n",
    "\n",
    "3. **Best Practices**: While demonstrating Python's capabilities for writing concise code, this example strays from common best practices, particularly in terms of clarity and simplicity.\n",
    "\n",
    "When reviewed by the `code_inspector` model, these issues are likely to be highlighted, emphasizing the importance of balancing clever coding with readability and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def one_liner(n):\n",
    "    return (\n",
    "        (lambda f, n: f(f, n))(lambda f, n: n * f(f, n - 1) if n > 1 else 1, n)\n",
    "        if isinstance(n, int) and n >= 0\n",
    "        else \"Invalid input\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code you've provided is a one-liner implementation of the factorial function\n",
      "using lambda functions and recursion. Here's a detailed review:\n",
      "\n",
      "1. Errors or bugs:\n",
      "   There are no syntax errors or bugs in your code. It correctly calculates the\n",
      "factorial of a non-negative integer and returns an error message for invalid\n",
      "inputs.\n",
      "\n",
      "2. Suggestions for optimizing code efficiency and structure:\n",
      "   While your one-liner is clever, it's not the most efficient or readable way\n",
      "to calculate a factorial. Recursive functions can be less efficient and more\n",
      "memory-intensive than iterative solutions, especially for large inputs. Also,\n",
      "Python has a recursion limit, which can be hit for large factorials.\n",
      "\n",
      "3. Recommendations for enhancing code readability and maintainability:\n",
      "   The biggest issue with this code is its readability. While one-liners can be\n",
      "fun and sometimes efficient, they often sacrifice readability, which is one of\n",
      "the key principles of Python (as per PEP 20, \"The Zen of Python\"). It's\n",
      "generally better to write clear, understandable code than to condense everything\n",
      "into one line. This is especially important in a team setting, where others need\n",
      "to understand your code.\n",
      "\n",
      "4. Best practice advice relevant to the code’s language and functionality:\n",
      "   Here's a more readable and efficient version of your function using a simple\n",
      "for loop:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if not isinstance(n, int) or n < 0:\n",
      "        return \"Invalid input\"\n",
      "    result = 1\n",
      "    for i in range(1, n + 1):\n",
      "        result *= i\n",
      "    return result\n",
      "```\n",
      "\n",
      "This version of the function is easier to understand, and it avoids the\n",
      "potential stack overflow issues that can occur with recursion. It also follows\n",
      "Python's best practices for readability and simplicity.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_liner(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing `find_phone_numbers` Function\n",
    "\n",
    "The `find_phone_numbers` function, enhanced with the `code_inspector`, is designed to extract phone numbers from a given text but contains a few notable issues and expected behaviors:\n",
    "\n",
    "1. **Typographical Error**: The function incorrectly uses `re.complie` instead of `re.compile`, leading to a runtime exception.\n",
    "\n",
    "2. **Pattern Matching Inaccuracy**: The regular expression pattern `\"(\\d{3})-\\d{3}-\\d{4}\"`, while formatted for typical phone numbers, can result in errors if a phone number does not appear in the string.\n",
    "\n",
    "3. **Lack of Error Handling**: Directly accessing the first element in `phone_numbers` without checking if the list is empty can lead to an `IndexError`.\n",
    "\n",
    "4. **Import Statement Position**: The `import re` statement is inside the function, which is unconventional. Imports are typically placed at the top of a script for clarity.\n",
    "\n",
    "5. **Analysis and Exception Handling**:\n",
    "   - Due to how we crafted our custom MLflow model in `code_inspector`, the function's issues will be analyzed and feedback will be returned before the function's logic is executed.\n",
    "   - After this analysis, the execution of the function will likely result in an exception (due to the typographical error), demonstrating the importance of careful code review and testing.\n",
    "\n",
    "The `code_inspector` model's review will highlight these coding missteps, emphasizing the value of proper syntax, pattern accuracy, and error handling in Python programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def find_phone_numbers(text):\n",
    "    pattern = \"(\\d{3})-\\d{3}-\\d{4}\"\n",
    "\n",
    "    import re\n",
    "\n",
    "    compiled_pattern = re.complie(pattern)\n",
    "\n",
    "    phone_numbers = compiled_pattern.findall(text)\n",
    "    first_number = phone_numbers[0]\n",
    "\n",
    "    print(f\"First found phone number: {first_number}\")\n",
    "    return phone_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a detailed review of your code:\n",
      "\n",
      "1. Errors or Bugs:\n",
      "   - There's a typo in the `re.compile` function. You've written `re.complie`\n",
      "instead of `re.compile`.\n",
      "\n",
      "2. Suggestions for Optimizing Code Efficiency and Structure:\n",
      "   - The import statement `import re` is inside the function. It's a good\n",
      "practice to keep all import statements at the top of the file. This makes it\n",
      "easier to see what modules are being used in the script.\n",
      "   - The function will throw an error if no phone numbers are found in the text\n",
      "because you're trying to access the first element of `phone_numbers` without\n",
      "checking if it exists. You should add a condition to check if `phone_numbers` is\n",
      "not empty before accessing its first element.\n",
      "\n",
      "3. Recommendations for Enhancing Code Readability and Maintainability:\n",
      "   - The function name `find_phone_numbers` is clear and descriptive, which is\n",
      "good. However, the variable `pattern` could be more descriptive. Consider\n",
      "renaming it to `phone_number_pattern` or something similar.\n",
      "   - You should add docstrings to your function to describe what it does, what\n",
      "its parameters are, and what it returns.\n",
      "\n",
      "4. Best Practice Advice:\n",
      "   - Use exception handling to catch potential errors and make your program more\n",
      "robust.\n",
      "   - Avoid using print statements in functions that are meant to return values.\n",
      "If you want to debug, consider using logging instead.\n",
      "\n",
      "Here's your improved code:\n",
      "\n",
      "```python\n",
      "import re\n",
      "\n",
      "def find_phone_numbers(text):\n",
      "    \"\"\"\n",
      "    This function finds all phone numbers in the given text.\n",
      "\n",
      "    Parameters:\n",
      "    text (str): The text to search for phone numbers.\n",
      "\n",
      "    Returns:\n",
      "    list: A list of found phone numbers.\n",
      "    \"\"\"\n",
      "    phone_number_pattern = \"(\\d{3})-\\d{3}-\\d{4}\"\n",
      "    compiled_pattern = re.compile(phone_number_pattern)\n",
      "    phone_numbers = compiled_pattern.findall(text)\n",
      "\n",
      "    if phone_numbers:\n",
      "        first_number = phone_numbers[0]\n",
      "        print(f\"First found phone number: {first_number}\")\n",
      "\n",
      "    return phone_numbers\n",
      "```\n",
      "\n",
      "Remember, the print statement is not recommended in production code. It's there\n",
      "for the purpose of this example.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 're' has no attribute 'complie'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_29389/78508464.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_phone_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Give us a call at 888-867-5309\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_29389/2021999358.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error during model prediction or formatting:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/ipykernel_29389/773713950.py\u001b[0m in \u001b[0;36mfind_phone_numbers\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcompiled_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mphone_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 're' has no attribute 'complie'"
     ]
    }
   ],
   "source": [
    "find_phone_numbers(\"Give us a call at 888-867-5309\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Harnessing the Power of MLflow in AI-Assisted Development\n",
    "\n",
    "As we conclude this tutorial, we have traversed through the integration of OpenAI's language models with the robust capabilities of MLflow, creating a powerful toolkit for AI-assisted software development. Here's a recap of our journey and the key takeaways:\n",
    "\n",
    "1. **Integrating OpenAI with MLflow**:\n",
    "   - We explored how to seamlessly integrate OpenAI's advanced language models within the MLflow framework. This integration highlighted the potential of combining AI intelligence with robust model management.\n",
    "\n",
    "2. **Implementing a Custom Python Model**:\n",
    "   - Our journey included creating a custom `CodeHelper` model, which showcased MLflow's flexibility in handling custom Python functions. This model significantly enhanced the user experience by formatting AI responses into a more readable format.\n",
    "\n",
    "3. **Real-Time Code Analysis and Feedback**:\n",
    "   - By employing the `code_inspector` decorator, we demonstrated MLflow's utility in providing real-time, insightful feedback on code quality and efficiency, fostering a learning environment that guides towards best coding practices.\n",
    "\n",
    "4. **Handling Complex Code Analysis**:\n",
    "   - The tutorial presented complex code examples, revealing how MLflow, combined with OpenAI, can handle intricate code analysis, offering suggestions and identifying potential issues.\n",
    "\n",
    "5. **Learning from Interactive Feedback**:\n",
    "   - The interactive feedback loop, enabled by our MLflow model, illustrated a practical approach to learning and improving coding skills, making this toolset particularly valuable for educational and development purposes.\n",
    "\n",
    "6. **Flexibility and Scalability of MLflow**:\n",
    "   - Throughout the tutorial, MLflow's flexibility and scalability were evident. Whether it's managing simple Python functions or integrating state-of-the-art AI models, MLflow proved to be an invaluable asset in streamlining the model management process.\n",
    "\n",
    "In summary, this tutorial not only provided insights into effective coding practices but also underscored the versatility of MLflow in enhancing AI-assisted software development. It stands as a testament to how machine learning tools and models can be innovatively applied to improve code quality, efficiency, and the overall development experience.\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "To continue your learning journey, see the additional [advanced tutorials for MLflow's OpenAI flavor](https://www.mlflow.org/docs/latest/llms/openai/index.html#advanced-tutorials)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
