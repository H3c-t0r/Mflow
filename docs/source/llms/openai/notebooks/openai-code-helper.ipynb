{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Code Assistant with OpenAI & MLflow\n",
    "\n",
    "### Overview\n",
    "\n",
    "Welcome to this comprehensive tutorial, where you'll embark on a fascinating journey through the integration of OpenAI's powerful language models with MLflow, where we'll be building an actually useful tool that can, with the simple addition of a decorator to any function that we declare, get immediate feedback within an interactive environment on code under active development.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "1. **Master OpenAI's GPT-4 for Code Assistance**: Understand how to leverage OpenAI's GPT-4 model for providing real-time coding assistance. Learn to harness its capabilities for generating code suggestions, explanations, and improving overall coding efficiency.\n",
    "2. **Utilize MLflow for Enhanced Model Tracking**: Delve into MLflow's powerful tracking systems to manage machine learning experiments. Learn how to adapt the `Python Model` from within MLflow to control how the output of an LLM is displayed from within an interactive coding environment.\n",
    "3. **Seamlessly Combine OpenAI and MLflow**: Discover the practical steps to integrate OpenAI's AI capabilities with MLflow's tracking and management systems. This integration exemplifies how combining these tools can streamline the development and deployment of intelligent applications.\n",
    "4. **Develop and Deploy a Custom Python Code Assistant**: Gain hands-on experience in creating a Python-based code assistant using OpenAI's model. Then, actually see it in action as it is used within a Jupyter Notebook environment to give helpful assistance during development.\n",
    "5. **Improve Code Quality with AI-driven Insights**: Apply AI-powered analysis to review and enhance your code. Learn how an AI assistant can provide real-time feedback on code quality, suggest improvements, and help maintain high coding standards.\n",
    "6. **Explore Advanced Python Features for Robust Development**: Understand advanced Python features like decorators and functional programming. These are crucial for building efficient, scalable, and maintainable software solutions, especially when integrating AI capabilities.\n",
    "\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **OpenAI's GPT-4 Model**: Dive into the capabilities of the state-of-the-art GPT-4 model, understanding its role in generating human-like text.\n",
    "2. **MLflow's Model Management**: Explore MLflow's features for tracking experiments, packaging code into reproducible runs, and managing and deploying models.\n",
    "3. **Python Decorators and Functional Programming**: Learn about advanced Python concepts like decorators and functional programming for efficient code evaluation and enhancement.\n",
    "4. **Regular Expressions and Error Handling**: Understand the implementation of regular expressions for pattern matching and effective error handling techniques in Python.\n",
    "\n",
    "### MLflow's Significance\n",
    "\n",
    "MLflow stands out in this tutorial as a pivotal tool for managing the lifecycle of machine learning projects. Its capabilities in model tracking, versioning, and deployment are essential for maintaining a robust and scalable machine learning workflow. The tutorial emphasizes MLflow's utility in enhancing productivity, ensuring reproducibility, and facilitating collaboration among data science teams.\n",
    "\n",
    "With a blend of theoretical insights and practical coding examples, this tutorial is designed to offer a well-rounded learning experience, catering to both beginners and seasoned practitioners in the field of machine learning. Let's dive into the world of AI model management and optimization with OpenAI and MLflow!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Disable a few less-than-useful UserWarnings from setuptools and pydantic\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import inspect\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "import shutil\n",
    "import textwrap\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.types.schema import ColSpec, ParamSchema, ParamSpec, Schema\n",
    "\n",
    "\n",
    "# Run a quick validation that we have an entry for the OPEN_API_KEY within environment variables\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"OPENAI_API_KEY environment variable must be set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Code Helper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a helpful expert Software Engineer who is here to assist me with my code and teach me along the way. When I paste in code, you will \"\n",
    "            \"provide a brief explanation of what the code is intending to accomplish and whether or not it is clearly understandable. If the code is incorrect, \"\n",
    "            \"has logical flaws, or is estimated to be fairly difficult to read, you will provide a concise explanation of what to change and the reasoning behind \"\n",
    "            \"these changes. Your primary goal is to provide explanations, justifications and suggestions in order that I learn a better way of writing code. \"\n",
    "            \"Please focus on code simplicity, maintainability, readability, and conformance to widely accepted patterns within the language of code that I submit to you.\"\n",
    "        ),\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Please check my code for errors and provide me with suggestions on how to improve it: {code}\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/tmp/code-helper\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This path cleanup is used to remove the model path if it already exists, provided in case you need to re-run this notebook in its entirety. \n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model signature that will be used for both the base model and the eventual custom pyfunc implementation later.\n",
    "signature = ModelSignature(\n",
    "        inputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "        outputs=Schema([ColSpec(type=\"string\", name=None)]),\n",
    "        params=ParamSchema(\n",
    "            [\n",
    "                ParamSpec(name=\"max_tokens\", default=500, dtype=\"long\"),\n",
    "                ParamSpec(name=\"temperature\", default=0, dtype=\"float\"),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Save the base OpenAI model with the included instruction set (prompt)\n",
    "mlflow.openai.save_model(\n",
    "    model=\"gpt-4\",\n",
    "    task=openai.ChatCompletion,\n",
    "    path=model_path,\n",
    "    messages=instruction,\n",
    "    signature=signature,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom pyfunc implementation that applies text and code formatting to the output results from the OpenAI model\n",
    "class CodeHelper(PythonModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def load_context(self, context):\n",
    "\n",
    "        self.model = mlflow.pyfunc.load_model(context.artifacts[\"model_path\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_response(response):\n",
    "        formatted_output = \"\"\n",
    "        in_code_block = False\n",
    "\n",
    "        for item in response:\n",
    "            lines = item.split('\\n')\n",
    "            for line in lines:\n",
    "                # Check for the start/end of a code block\n",
    "                if line.strip().startswith(\"```\"):\n",
    "                    in_code_block = not in_code_block\n",
    "                    formatted_output += line + '\\n'\n",
    "                    continue\n",
    "\n",
    "                if in_code_block:\n",
    "                    # Don't wrap lines inside code blocks\n",
    "                    formatted_output += line + '\\n'\n",
    "                else:\n",
    "                    # Wrap lines outside of code blocks\n",
    "                    wrapped_lines = textwrap.fill(line, width=80)\n",
    "                    formatted_output += wrapped_lines + '\\n'\n",
    "\n",
    "        return formatted_output\n",
    "\n",
    "    def predict(self, context, model_input, params):\n",
    "\n",
    "        # Call the loaded OpenAI model instance to get the raw response\n",
    "        raw_response = self.model.predict(model_input, params=params)\n",
    "\n",
    "        # Return the formatted response so that it is easier to read\n",
    "        return self._format_response(raw_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location that we'll be using to save (and load) our custom pyfunc implementation\n",
    "final_model_path = \"/tmp/my_code_helper\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, we're cleaning up the destination location for the serialized custom model, in case you want to run this notebook several times.\n",
    "if os.path.exists(final_model_path):\n",
    "    shutil.rmtree(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location of the \n",
    "artifacts = {\"model_path\": model_path}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.save_model(\n",
    "        path=final_model_path,\n",
    "        python_model=CodeHelper(),\n",
    "        input_example=[\"x = 1\"],\n",
    "        signature=signature,\n",
    "        artifacts=artifacts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_helper = mlflow.pyfunc.load_model(final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_inspector(model):\n",
    "    \"\"\"\n",
    "    Function decorator that will evaluate the implementation of any decorated function and provide feedback on it when called\n",
    "    \n",
    "    Args:\n",
    "        model: The MLflow pyfunc model that will be used to evaluate the code\n",
    "    \"\"\"\n",
    "    def decorator_check_my_function(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                parsed_func = inspect.getsource(func)\n",
    "                response = model.predict(parsed_func)\n",
    "                # Print the response so that even if the code doesn't execute properly, we'll get feedback about what to change\n",
    "                print(response)\n",
    "            except Exception as e:\n",
    "                print(\"Error during model prediction or formatting:\", e)\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator_check_my_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def summing_function(n):\n",
    "    sum_result = 0\n",
    "\n",
    "    intermediate_sums = {}\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        intermediate_sums[str(i)] = sum([x for x in range(1, i + 1)])\n",
    "        for key in intermediate_sums:\n",
    "            if key == str(i):\n",
    "                sum_result = intermediate_sums[key]\n",
    "    \n",
    "    final_sum = sum([intermediate_sums[key] for key in intermediate_sums if int(key) == n])\n",
    "\n",
    "    return int(str(final_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summing_function(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def one_liner(n):\n",
    "    return (lambda f, n: f(f, n))(lambda f, n: n * f(f, n - 1) if n > 1 else 1, n) if isinstance(n, int) and n >= 0 else \"Invalid input\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_liner(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def processData(data):\n",
    "    a = []\n",
    "    if len(data) == 0:\n",
    "        print(\"No data\")\n",
    "        return\n",
    "    else:\n",
    "        for d in range(len(data)):\n",
    "            if data[d] % 2 == 0:\n",
    "                a.append(data[d] + 1)\n",
    "            else:\n",
    "                a.append(data[d])\n",
    "        index = 0\n",
    "        while index < len(a):\n",
    "            if a[index] % 2 != 0:\n",
    "                a[index] = a[index] * 2\n",
    "            index = index + 1\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processData([1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_inspector(loaded_helper)\n",
    "def find_phone_numbers(text):\n",
    "    \n",
    "    pattern = \"(\\d{3})-\\d{2}-\\d{4}\"\n",
    "\n",
    "    import re\n",
    "\n",
    "    compiled_pattern = re.complie(pattern)\n",
    "\n",
    "    phone_numbers = compiled_pattern.findall(text)\n",
    "    first_number = phone_numbers[0]\n",
    "\n",
    "    print(f\"First found phone number: {first_number}\")\n",
    "    return phone_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_phone_numbers(\"Give us a call at 888-867-5309\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
