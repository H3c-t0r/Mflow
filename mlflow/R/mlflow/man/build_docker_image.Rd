% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/docker-utils.R
\name{build_docker_image}
\alias{build_docker_image}
\title{Build a MLflow Docker image}
\usage{
build_docker_image(
  image_name,
  model_uri,
  port = 8090,
  mlflow_version = utils::packageVersion("mlflow"),
  custom_setup_steps_hook = NULL
)
}
\arguments{
\item{image_name}{Name of the Docker image}

\item{model_uri}{The location, in URI format, of the MLflow model.}

\item{port}{Port for serving the model (default: 8090)}

\item{mlflow_version}{(Optional) Ignored if `mlflow_home` is specified,
otherwise build the image with the  version of MLflow specified by
`mlflow_version` (default: `packageVersion("mlflow")`)}

\item{custom_setup_steps_hook}{(Optional) single-argument function accepting
the dockerfile context directory as input and returning additional
Dockerfile commands to run during the image build step as output.}
}
\description{
Build a MLflow Docker image that will an RFunc MLflow model
}
\details{
The URI scheme must be supported by MLflow - i.e. there has to be an MLflow artifact
         repository corresponding to the scheme of the URI. The content is expected to point to a
         directory containing MLmodel. The following are examples of valid model uris:

                 - ``file:///absolute/path/to/local/model``
                 - ``file:relative/path/to/local/model``
                 - ``s3://my_bucket/path/to/model``
                 - ``runs:/<mlflow_run_id>/run-relative/path/to/model``
                 - ``models:/<model_name>/<model_version>``
                 - ``models:/<model_name>/<stage>``

 For more information about supported URI schemes, see the Artifacts Documentation at
 https://www.mlflow.org/docs/latest/tracking.html#artifact-stores.
}
\examples{
\dontrun{

library(mlflow)
library(carrier)

# build a model and save it locally
model <- lm(Sepal.Width ~ Sepal.Length + Petal.Width, iris)
fn <- crate(~ stats::predict(model, .x), model = model)

mlflow_save_model(fn, path = "/tmp/model")

# now build a self-contained Docker image that can serve that model

build_docker_image(
  image_name = "mlflow_hello_world",
  model_uri = "file:///tmp/model",
  port = 8090,
  mlflow_version = "1.12.1"
)

# Now one can, for example, run `docker run -p 9123:8090 mlflow_hello_world`
# to launch the docker image above with port 8090 of the container binding to
# port 9123 of the host

}

}
