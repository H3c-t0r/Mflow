{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/11 17:47:26 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/11 17:47:26 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/01/11 17:47:26 WARNING mlflow.models.evaluation.default_evaluator: Did not log metric 'custom_metric_4' at index 0 in the `extra_metrics` parameter because it returned None.\n",
      "2024/01/11 17:47:26 WARNING mlflow.models.evaluation.default_evaluator: Did not log metric 'custom_metric_4' at index 0 in the `extra_metrics` parameter because it returned None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metric/avg': 15, 'custom_metric_2': 225, 'custom_metric_3': 205}\n"
     ]
    }
   ],
   "source": [
    "from mlflow.metrics import make_metric, MetricValue\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "def custom_metric_fn(predictions, targets, metrics, random):\n",
    "    return MetricValue(scores=[15] * len(predictions), justifications=[\"hi\"] * len(predictions), aggregate_results={\"avg\": 15})\n",
    "custom_metric = make_metric(name=\"custom_metric\", eval_fn=custom_metric_fn, greater_is_better=True)\n",
    "\n",
    "def custom_metric_fn_2(predictions, metrics, different_params, something_random, custom_metric):\n",
    "    return custom_metric.aggregate_results[\"avg\"] * 15\n",
    "custom_metric_2 = make_metric(name=\"custom_metric_2\", eval_fn=custom_metric_fn_2, greater_is_better=True)\n",
    "\n",
    "def custom_metric_fn_3(predictions, targets, custom_metric_2):\n",
    "    return custom_metric_2.aggregate_results[\"custom_metric_2\"] - 20\n",
    "custom_metric_3 = make_metric(name=\"custom_metric_3\", eval_fn=custom_metric_fn_3, greater_is_better=True)\n",
    "\n",
    "def custom_metric_fn_4(predictions, targets, custom_metric, custom_metric_3):\n",
    "    return None\n",
    "    return custom_metric.aggregate_results[\"avg\"] + custom_metric_3.aggregate_results[\"custom_metric_3\"]\n",
    "custom_metric_4 = make_metric(name=\"custom_metric_4\", eval_fn=custom_metric_fn_4, greater_is_better=True)\n",
    "\n",
    "# Create a pandas dataframe with columns 'inputs', 'predictions', 'context'\n",
    "eval_df = pd.DataFrame([\n",
    "    {'inputs': 'What is the capital of France?', 'predictions': 'Paris', 'targets': 'France is a country in Western Europe', 'something_random': 'blah blah', 'more_cols': 'woohoo', 'another_col': '1'},\n",
    "    {'inputs': 'What is the capital of Germany?', 'predictions': 'Berlin', 'targets': 'Germany is a country in West', 'something_random': 'blah blah', 'more_cols': 'yay', 'another_col': '2'}])\n",
    "\n",
    "eval_results = mlflow.evaluate(\n",
    "    data = eval_df, # evaluation data\n",
    "    evaluators=\"default\",\n",
    "    predictions=\"predictions\", # prediction column_name from eval_df\n",
    "    targets=\"targets\",\n",
    "    extra_metrics=[custom_metric_4, custom_metric_2, custom_metric, custom_metric_3],\n",
    "    evaluator_config={\n",
    "      \"col_mapping\": {\"different_params\": \"more_cols\", \"random\": \"another_col\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(eval_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
