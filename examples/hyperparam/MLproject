name: HyperparameterSearch

conda_env: conda.yaml

entry_points:
  # train Keras DL model
  train:
    parameters:
      training_data: {type: string, default: "../sklearn_elasticnet_wine/wine-quality.csv"}
      epochs: {type: int, default: 32}
      batch_size: {type: int, default: 16}
      learning_rate: {type: float, default: 1e-1}
      momentum: {type: float, default: .0}
      seed: {type: int, default: 97531}
    command: "python train.py {training_data}
                                    --batch-size {batch_size}
                                    --epochs {epochs}
                                    --learning-rate {learning_rate}
                                    --momentum {momentum}"

  train-mnist:
    parameters:
      training_data: {type: string, default: "mnist_train.amat"}
      test_data: {type: string, default: "mnist_test.amat"}
      epochs: {type: int, default: 1}
      batch_size: {type: int, default: 16}
      optimizer: {stype: string, default: "SGD()"}
      pooling: {type: string, default: "MaxPooling2D()"}
      conv_kernel_size: {type: string, default: "(3, 3)"}
      conv_layer_sizes: {stype: string, default: "(32, 64)"}
      conv_l1: {stype: float, default: 1e-4}
      conv_l2: {stype: float, default: 1e-5}
      dense_layer_sizes: {type: string, default: "(1024, 128)"}
      dense_l1: {stype: float, default: 1e-4}
      dense_l2: {stype: float, default: 1e-5}
      seed: {type: int, default: 97531}

    command: "python train_mnist.py {training_data} {test_data}
                                    --batch-size {batch_size}
                                    --epochs {epochs}
                                    --optimizer {optimizer}
                                    --convolution-kernel-size {conv_kernel_size}
                                    --convolution-layer-sizes {conv_layer_sizes}
                                    --convolution-l1 {conv_l1}
                                    --convolution-l2 {conv_l2}
                                    --dense-layer-sizes {dense_layer_sizes}
                                    --dense-l1 {dense_l1}
                                    --dense-l2 {dense_l2}
                                    --seed {seed}"

  hyperopt-mnist:
    parameters:
      training_data: {type: string, default: "mnist_train.amat"}
      test_data: {type: string, default: "mnist_test.amat"}
      max_runs: {type: int, default: 12}
      epochs: {type: int, default: 32}
      metric: {type: string, default: "accuracy"}
      algo: {type: string, default: "tpe.suggest"}
      seed: {type: int, default: 97531}
      training_experiment_id: {type: int, default: "-1"}
    command: "python -O search_hyperopt_mnist.py {training_data}
                                                 {test_data}
                                                 --max-runs {max_runs}
                                                 --epochs {epochs}
                                                 --metric {metric}
                                                 --algo {algo}
                                                 --seed {seed}
                                                 --training-experiment-id {training_experiment_id}"


  # Use random search to optimize hyperparams of the train entry_point.
  random:
    parameters:
      training_data: {type: string, default: "../sklearn_elasticnet_wine/wine-quality.csv"}
      max_runs: {type: int, default: 8}
      max_p: {type: int, default: 2}
      epochs: {type: int, default: 32}
      metric: {type: string, default: "rmse"}
      seed: {type: int, default: 97531}
      training_experiment_id: {type: int, default: "-1"}
    command: "python search_random.py  {training_data}
                                             --max-runs {max_runs}
                                             --max-p {max_p}
                                             --epochs {epochs}
                                             --metric {metric}
                                             --seed {seed}
                                             --training-experiment-id {training_experiment_id}"


  # Use GPyOpt to optimize hyperparams of the train entry_point.
  gpyopt:
    parameters:
      training_data: {type: string, default: "../sklearn_elasticnet_wine/wine-quality.csv"}
      max_runs: {type: int, default: 8}
      batch_size: {type: int, default: 2}
      max_p: {type: int, default: 2}
      epochs: {type: int, default: 32}
      metric: {type: string, default: "rmse"}
      gpy_model: {type: string, default: "GP"}
      gpy_acquisition: {type: string, default: "EI"}
      initial_design: {type: string, default: "random"}
      seed: {type: int, default: 97531}
      training_experiment_id: {type: int, default: "-1"}

    command: "python search_gpyopt.py  {training_data}
                                             --max-runs {max_runs}
                                             --batch-size {batch_size}
                                             --max-p {max_p}
                                             --epochs {epochs}
                                             --metric {metric}
                                             --gpy-model {gpy_model}
                                             --gpy-acquisition {gpy_acquisition}
                                             --initial-design {initial_design}
                                             --seed {seed}
                                             --training-experiment-id {training_experiment_id}"

  # Use Hyperopt to optimize hyperparams of the train entry_point.
  hyperopt:
    parameters:
      training_data: {type: string, default: "../sklearn_elasticnet_wine/wine-quality.csv"}
      max_runs: {type: int, default: 12}
      epochs: {type: int, default: 32}
      metric: {type: string, default: "rmse"}
      algo: {type: string, default: "tpe.suggest"}
      seed: {type: int, default: 97531}
      training_experiment_id: {type: int, default: "-1"}
    command: "python -O search_hyperopt.py {training_data}
                                                 --max-runs {max_runs}
                                                 --epochs {epochs}
                                                 --metric {metric}
                                                 --algo {algo}
                                                 --seed {seed}
                                                 --training-experiment-id {training_experiment_id}"





