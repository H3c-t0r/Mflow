{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "from queue import Queue, Empty\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from cuml.metrics.accuracy import accuracy_score\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "from cuml.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull sample airline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -N https://rapidsai-cloud-ml-sample-data.s3-us-west-2.amazonaws.com/airline_small.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data loader, using cuDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fpath):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by CPU/GPU models.\n",
    "\n",
    "    :param fpath: Path to the data to be ingested\n",
    "    :return: DataFrame wrapping the data at [fpath]. Data will be in either a Pandas or RAPIDS (cuDF) DataFrame\n",
    "    \"\"\"\n",
    "    import cudf\n",
    "\n",
    "    df = cudf.read_parquet(fpath)\n",
    "    X = df.drop([\"ArrDelayBinary\"], axis=1)\n",
    "    y = df[\"ArrDelayBinary\"].astype('int32')\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our training routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fpath, max_detph, max_features, n_estimators):\n",
    "    \"\"\"\n",
    "    :param fpath: Path or URL for the training data used with the model.\n",
    "    :max_detph: int Max tree depth\n",
    "    :max_features: float percentage of features to use in classification\n",
    "    :n_estimators: int number of trees to create\n",
    "    :return: Trained Model\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = load_data(fpath)\n",
    "    mod = RandomForestClassifier(max_depth=max_depth, max_features=max_features, n_estimators=n_estimators)\n",
    "    acc_scorer = accuracy_score\n",
    "\n",
    "    mod.fit(X_train, y_train)\n",
    "    preds = mod.predict(X_test)\n",
    "    acc = acc_scorer(y_test, preds)\n",
    "\n",
    "    mlparams = {\"max_depth\": str(max_depth),\n",
    "                \"max_features\": str(max_features),\n",
    "                \"n_estimators\": str(n_estimators),\n",
    "                }\n",
    "    mlflow.log_params(mlparams)\n",
    "\n",
    "    mlmetrics = {\"accuracy\": acc}\n",
    "    mlflow.log_metrics(mlmetrics)\n",
    "\n",
    "    return mod, infer_signature(X_train.to_pandas(), y_train.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement our MLFlow training loop, and save our best model to the tracking server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mlruns/1/9cc03cf9902e4caf88624663b7bc3cb6/artifacts/Airline-Demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'rapids-mlflow-notebook' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'rapids-mlflow-notebook'.\n"
     ]
    }
   ],
   "source": [
    "conda_env = f'conda.yaml'\n",
    "fpath     = f'airline_small.parquet'\n",
    "\n",
    "max_depth = 10\n",
    "max_features = 0.75\n",
    "n_estimators = 500\n",
    "\n",
    "artifact_path = \"Airline-Demo\"\n",
    "artifact_uri = None\n",
    "experiment_name = \"RAPIDS-Notebook\"\n",
    "experiment_id = None\n",
    "\n",
    "mlflow.set_tracking_uri(uri='sqlite:////tmp/mlflow-db.sqlite')\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"mlflow.runName\", \"(Notebook) RAPIDS-MLFlow\")\n",
    "    \n",
    "    model, signature = train(fpath, max_depth, max_features, n_estimators)\n",
    "        \n",
    "    mlflow.sklearn.log_model(model,\n",
    "                             signature=signature,\n",
    "                             artifact_path=artifact_path,\n",
    "                             registered_model_name=\"rapids-mlflow-notebook\",\n",
    "                             conda_env='conda.yaml')\n",
    "    \n",
    "    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n",
    "print(artifact_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper to track our server output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def queue_descriptor_output(out, queue):\n",
    "    for line in iter(out.readline, b''):\n",
    "        queue.put(line)\n",
    "    out.close()\n",
    "\n",
    "def follow_subprocess(cmd, timeout=1000, line_timeout=60.00):\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    q = Queue()\n",
    "    t = threading.Thread(target=queue_descriptor_output, args=(p.stdout, q))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "    elapsed = 0\n",
    "    line_elapsed = 0\n",
    "    last_line_time = time.perf_counter()\n",
    "    while (p.poll() is None and elapsed < timeout and line_elapsed < line_timeout):\n",
    "        try:\n",
    "            time.sleep(2)\n",
    "            elapsed += 2\n",
    "            while (True):\n",
    "                line = q.get(timeout=0.1)\n",
    "                line_elapsed = 0\n",
    "                last_line_time = time.perf_counter()\n",
    "                sys.stdout.write(line.decode())\n",
    "\n",
    "        except Empty:\n",
    "            line_elapsed = (time.perf_counter() - last_line_time)\n",
    "        except KeyboardInterrupt:\n",
    "            sys.stderr.write(\"\\nCaught ctrl+c, killing subprocess ({})\\n\".format(' '.join(cmd)))\n",
    "            p.kill()\n",
    "            raise\n",
    "\n",
    "    try:\n",
    "        p.kill()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    t.join(2)\n",
    "\n",
    "    ## Drain any remaining text\n",
    "    try:\n",
    "        while (True):\n",
    "            line = q.get(timeout=0.1)\n",
    "            sys.stdout.write(line)\n",
    "\n",
    "    except Empty:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin serving our trained model using MLFlow\n",
    "**Note:** The serving thread will continue to run after cell execution. Select the cell and click 'interrupt the kernel' to stop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 55755\n",
    "host = 'localhost'\n",
    "\n",
    "command = f\"mlflow models serve -m {artifact_uri} -p {port} -h {host}\".split()\n",
    "kwargs = { \"cmd\": command, \"timeout\":float('Inf'), \"line_timeout\": float('Inf') }\n",
    "\n",
    "threading.Thread(target=follow_subprocess, kwargs=kwargs).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Make requests against the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model(artifact_uri)\n",
    "example_info = model.metadata.saved_input_example_info\n",
    "print(example_info)\n",
    "example_path = example_info[artifact_uri] # also has fields type -> dataframe, pandas_orient -> split etc\n",
    "example_df = pd.read_json(example_path, orient = example_info.get(\"pandas_orient\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"format\": \"pandas-split\"\n",
    "}\n",
    "\n",
    "data = { \n",
    "    \"columns\": [\"Year\", \"Month\", \"DayofMonth\", \"DayofWeek\", \"CRSDepTime\", \"CRSArrTime\", \"UniqueCarrier\", \"FlightNum\", \"ActualElapsedTime\", \"Origin\", \"Dest\", \"Distance\", \"Diverted\"],\n",
    "    \"data\": [[1987, 10, 1, 4, 1, 556, 0, 190, 247, 202, 162, 1846, 0]]\n",
    "}\n",
    "\n",
    "## Pause to let server start\n",
    "time.sleep(5)\n",
    "\n",
    "while (True):\n",
    "    try:\n",
    "        resp = requests.post(url=f\"http://{host}:{port}/invocations\", data=json.dumps(data), headers=headers)\n",
    "        print(f'Classification: {\"ON-Time\" if resp.text == \"[0.0]\" else \"LATE\"}')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        errmsg = f\"Caught exception attempting to call model endpoint: {e}\"\n",
    "        print(f\"{errmsg}\", end='')\n",
    "        print(f\"Sleeping\")\n",
    "        time.sleep(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-23e2e95fab38>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mexample_info\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msaved_input_example_info\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexample_info\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mexample_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexample_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0martifact_uri\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;31m# also has fields type -> dataframe, pandas_orient -> split etc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0mexample_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexample_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morient\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexample_info\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"pandas_orient\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"format\": \"pandas-split\"\n",
    "}\n",
    "\n",
    "data = { \n",
    "    \"columns\": [\"Year\", \"Month\", \"DayofMonth\", \"DayofWeek\", \"CRSDepTime\", \"CRSArrTime\", \"UniqueCarrier\", \"FlightNum\", \"ActualElapsedTime\", \"Origin\", \"Dest\", \"Distance\", \"Diverted\"],\n",
    "    \"data\": [[1987, 10, 1, 4, 1, 556, 0, 190, 247, 202, 162, 1846, 0]]\n",
    "}\n",
    "\n",
    "## Pause to let server start\n",
    "time.sleep(5)\n",
    "\n",
    "while (True):\n",
    "    try:\n",
    "        resp = requests.post(url=f\"http://{host}:{port}/invocations\", data=json.dumps(data), headers=headers)\n",
    "        print(f'Classification: {\"ON-Time\" if resp.text == \"[0.0]\" else \"LATE\"}')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        errmsg = f\"Caught exception attempting to call model endpoint: {e}\"\n",
    "        print(f\"{errmsg}\", end='')\n",
    "        print(f\"Sleeping\")\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"format\": \"pandas-split\"\n",
    "}\n",
    "\n",
    "data = { \n",
    "    \"columns\": [\"Year\", \"Month\", \"DayofMonth\", \"DayofWeek\", \"CRSDepTime\", \"CRSArrTime\", \"UniqueCarrier\", \"FlightNum\", \"ActualElapsedTime\", \"Origin\", \"Dest\", \"Distance\", \"Diverted\"],\n",
    "    \"data\": [[1987, 10, 1, 4, 1, 556, 0, 190, 247, 202, 162, 1846, 0]]\n",
    "}\n",
    "\n",
    "## Pause to let server start\n",
    "time.sleep(5)\n",
    "\n",
    "while (True):\n",
    "    try:\n",
    "        resp = requests.post(url=f\"http://{host}:{port}/invocations\", data=json.dumps(data), headers=headers)\n",
    "        print(f'Classification: {\"ON-Time\" if resp.text == \"[0.0]\" else \"LATE\"}')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        errmsg = f\"Caught exception attempting to call model endpoint: {e}\"\n",
    "        print(f\"{errmsg}\", end='')\n",
    "        print(f\"Sleeping\")\n",
    "        time.sleep(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "mlflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}